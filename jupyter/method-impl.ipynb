{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlalchemy\n",
    "import gensim\n",
    "import logging\n",
    "import empath\n",
    "\n",
    "import common\n",
    "import util\n",
    "importlib.reload(common)\n",
    "importlib.reload(util)\n",
    "\n",
    "from common import create_engine\n",
    "from common import display_all\n",
    "from common import figsize\n",
    "from common import save_df, load_df\n",
    "from common import save_session, load_session\n",
    "\n",
    "from util import show_importances\n",
    "from util import split_X_y_all, split_X_y, split_data\n",
    "from util import empty_features, column_feature, str_contains\n",
    "\n",
    "from pbar import Pbar\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "\n",
    "register_matplotlib_converters() # converters e.g. for datetime in plots\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 123\n",
    "np_random = np.random.RandomState(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_df('final_data.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>perex</th>\n",
       "      <th>body</th>\n",
       "      <th>raw_body</th>\n",
       "      <th>published_at</th>\n",
       "      <th>extracted_at</th>\n",
       "      <th>category</th>\n",
       "      <th>other_info</th>\n",
       "      <th>image_count</th>\n",
       "      <th>video_count</th>\n",
       "      <th>...</th>\n",
       "      <th>fb_popularity_ad_6</th>\n",
       "      <th>fb_popularity_ad_7</th>\n",
       "      <th>fb_popularity_ad_8</th>\n",
       "      <th>fb_popularity_ad_9</th>\n",
       "      <th>fb_popularity_ad_10</th>\n",
       "      <th>fb_popularity_ad_11</th>\n",
       "      <th>fb_popularity_ad_12</th>\n",
       "      <th>fb_popularity_ad_13</th>\n",
       "      <th>fb_popularity_ad_14</th>\n",
       "      <th>fb_popularity_ad_15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>428781</th>\n",
       "      <td>Want to Support Immunity? Look to Your Gut</td>\n",
       "      <td>&lt;p&gt;For thousands of years we’ve relied on our ...</td>\n",
       "      <td>For thousands of years we’ve relied on our mic...</td>\n",
       "      <td>&lt;p&gt;&lt;span data-contrast=\"auto\"&gt;For thousands of...</td>\n",
       "      <td>2019-10-10 00:04:42</td>\n",
       "      <td>2019-10-10 07:13:11.637640</td>\n",
       "      <td>[gut health]</td>\n",
       "      <td>{'tags': ['gut health', 'immune system', 'immu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428783</th>\n",
       "      <td>NY Judge Denies Stay: Children Locked Out of S...</td>\n",
       "      <td></td>\n",
       "      <td>\\n  \\n</td>\n",
       "      <td>&lt;p&gt;&lt;a class=\"asset-img-link\" href=\"https://www...</td>\n",
       "      <td>2019-10-10 01:01:32</td>\n",
       "      <td>2019-10-10 07:13:17.715180</td>\n",
       "      <td>None</td>\n",
       "      <td>{'tags': None, 'updated_at': '2019-10-09 23:01...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428831</th>\n",
       "      <td>Cucumber + Turmeric = Gorgeous Skin and Your F...</td>\n",
       "      <td>&lt;p&gt;Face masks – the best means of expressing c...</td>\n",
       "      <td>Face masks – the best means of expressing care...</td>\n",
       "      <td>\\n&lt;p&gt;Face masks – the best means of expressing...</td>\n",
       "      <td>2019-10-10 02:21:28</td>\n",
       "      <td>2019-10-10 09:24:06.693998</td>\n",
       "      <td>[Beauty]</td>\n",
       "      <td>{'tags': [], 'updated_at': '2019-10-10T02:30:54'}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428832</th>\n",
       "      <td>‘Sesame Street’ launches initiative to help ex...</td>\n",
       "      <td>In a new initiative, “Sesame Street” is addres...</td>\n",
       "      <td>“Sesame Street” is introducing a new storyline...</td>\n",
       "      <td>&lt;p&gt;Parents and kids who are fans of &amp;#x201C;Se...</td>\n",
       "      <td>2019-10-10 10:40:22</td>\n",
       "      <td>2019-10-10 12:02:48.264837</td>\n",
       "      <td>[Health]</td>\n",
       "      <td>{'tags': ['pediatrics', 'addiction'], 'keyword...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428833</th>\n",
       "      <td>Silicosis outbreak highlights the 'malignant n...</td>\n",
       "      <td>Fourteen U.S. workers are killed on the job ev...</td>\n",
       "      <td>Cutting or polishing the quartz-based composit...</td>\n",
       "      <td>&lt;p&gt;Across the United States, workers are suffe...</td>\n",
       "      <td>2019-10-10 10:35:03</td>\n",
       "      <td>2019-10-10 12:02:48.419273</td>\n",
       "      <td>[First Opinion]</td>\n",
       "      <td>{'tags': ['public health', 'government agencie...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  \\\n",
       "id                                                          \n",
       "428781         Want to Support Immunity? Look to Your Gut   \n",
       "428783  NY Judge Denies Stay: Children Locked Out of S...   \n",
       "428831  Cucumber + Turmeric = Gorgeous Skin and Your F...   \n",
       "428832  ‘Sesame Street’ launches initiative to help ex...   \n",
       "428833  Silicosis outbreak highlights the 'malignant n...   \n",
       "\n",
       "                                                    perex  \\\n",
       "id                                                          \n",
       "428781  <p>For thousands of years we’ve relied on our ...   \n",
       "428783                                                      \n",
       "428831  <p>Face masks – the best means of expressing c...   \n",
       "428832  In a new initiative, “Sesame Street” is addres...   \n",
       "428833  Fourteen U.S. workers are killed on the job ev...   \n",
       "\n",
       "                                                     body  \\\n",
       "id                                                          \n",
       "428781  For thousands of years we’ve relied on our mic...   \n",
       "428783                                             \\n  \\n   \n",
       "428831  Face masks – the best means of expressing care...   \n",
       "428832  “Sesame Street” is introducing a new storyline...   \n",
       "428833  Cutting or polishing the quartz-based composit...   \n",
       "\n",
       "                                                 raw_body        published_at  \\\n",
       "id                                                                              \n",
       "428781  <p><span data-contrast=\"auto\">For thousands of... 2019-10-10 00:04:42   \n",
       "428783  <p><a class=\"asset-img-link\" href=\"https://www... 2019-10-10 01:01:32   \n",
       "428831  \\n<p>Face masks – the best means of expressing... 2019-10-10 02:21:28   \n",
       "428832  <p>Parents and kids who are fans of &#x201C;Se... 2019-10-10 10:40:22   \n",
       "428833  <p>Across the United States, workers are suffe... 2019-10-10 10:35:03   \n",
       "\n",
       "                     extracted_at         category  \\\n",
       "id                                                   \n",
       "428781 2019-10-10 07:13:11.637640     [gut health]   \n",
       "428783 2019-10-10 07:13:17.715180             None   \n",
       "428831 2019-10-10 09:24:06.693998         [Beauty]   \n",
       "428832 2019-10-10 12:02:48.264837         [Health]   \n",
       "428833 2019-10-10 12:02:48.419273  [First Opinion]   \n",
       "\n",
       "                                               other_info  image_count  \\\n",
       "id                                                                       \n",
       "428781  {'tags': ['gut health', 'immune system', 'immu...            0   \n",
       "428783  {'tags': None, 'updated_at': '2019-10-09 23:01...            0   \n",
       "428831  {'tags': [], 'updated_at': '2019-10-10T02:30:54'}            1   \n",
       "428832  {'tags': ['pediatrics', 'addiction'], 'keyword...            1   \n",
       "428833  {'tags': ['public health', 'government agencie...            1   \n",
       "\n",
       "        video_count  ... fb_popularity_ad_6  fb_popularity_ad_7  \\\n",
       "id                   ...                                          \n",
       "428781            0  ...                0.0                 0.0   \n",
       "428783            0  ...                0.0                 0.0   \n",
       "428831            0  ...                0.0                 0.0   \n",
       "428832            0  ...                0.0                 0.0   \n",
       "428833            0  ...                0.0                 0.0   \n",
       "\n",
       "       fb_popularity_ad_8 fb_popularity_ad_9 fb_popularity_ad_10  \\\n",
       "id                                                                 \n",
       "428781                0.0                0.0                 0.0   \n",
       "428783                0.0                0.0                 0.0   \n",
       "428831                0.0                0.0                 0.0   \n",
       "428832                0.0                0.0                 0.0   \n",
       "428833                0.0                0.0                 0.0   \n",
       "\n",
       "        fb_popularity_ad_11 fb_popularity_ad_12  fb_popularity_ad_13  \\\n",
       "id                                                                     \n",
       "428781                  0.0                 0.0                  0.0   \n",
       "428783                  0.0                 0.0                  0.0   \n",
       "428831                  0.0                 0.0                  0.0   \n",
       "428832                  0.0                 0.0                  0.0   \n",
       "428833                  0.0                 0.0                  0.0   \n",
       "\n",
       "        fb_popularity_ad_14  fb_popularity_ad_15  \n",
       "id                                                \n",
       "428781                  0.0                  0.0  \n",
       "428783                  0.0                  0.0  \n",
       "428831                  0.0                  0.0  \n",
       "428832                  0.0                  0.0  \n",
       "428833                  0.0                  0.0  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20280 entries, 428781 to 812426\n",
      "Data columns (total 86 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   title                    20280 non-null  object        \n",
      " 1   perex                    16137 non-null  object        \n",
      " 2   body                     20246 non-null  object        \n",
      " 3   published_at             20280 non-null  datetime64[ns]\n",
      " 4   extracted_at             20280 non-null  datetime64[ns]\n",
      " 5   category                 13716 non-null  object        \n",
      " 6   other_info               20276 non-null  object        \n",
      " 7   image_count              20280 non-null  int64         \n",
      " 8   video_count              20280 non-null  int64         \n",
      " 9   author_name              20280 non-null  object        \n",
      " 10  source_id                20280 non-null  int64         \n",
      " 11  source_name              20280 non-null  object        \n",
      " 12  source_url               20280 non-null  object        \n",
      " 13  source_type              20280 non-null  object        \n",
      " 14  source_is_reliable       20280 non-null  int64         \n",
      " 15  av_veracity              4254 non-null   object        \n",
      " 16  av_claims_false          20280 non-null  int64         \n",
      " 17  av_claims_mostly_false   20280 non-null  int64         \n",
      " 18  av_claims_mixture        20280 non-null  int64         \n",
      " 19  av_claims_mostly_true    20280 non-null  int64         \n",
      " 20  av_claims_true           20280 non-null  int64         \n",
      " 21  av_claims_unknown        20280 non-null  int64         \n",
      " 22  fb_ad_0_comment_count    9389 non-null   float64       \n",
      " 23  fb_ad_1_comment_count    14407 non-null  float64       \n",
      " 24  fb_ad_2_comment_count    15363 non-null  float64       \n",
      " 25  fb_ad_3_comment_count    16059 non-null  float64       \n",
      " 26  fb_ad_4_comment_count    16531 non-null  float64       \n",
      " 27  fb_ad_5_comment_count    16527 non-null  float64       \n",
      " 28  fb_ad_6_comment_count    16534 non-null  float64       \n",
      " 29  fb_ad_7_comment_count    16476 non-null  float64       \n",
      " 30  fb_ad_8_comment_count    16163 non-null  float64       \n",
      " 31  fb_ad_9_comment_count    16232 non-null  float64       \n",
      " 32  fb_ad_10_comment_count   16482 non-null  float64       \n",
      " 33  fb_ad_11_comment_count   16673 non-null  float64       \n",
      " 34  fb_ad_12_comment_count   16567 non-null  float64       \n",
      " 35  fb_ad_13_comment_count   16266 non-null  float64       \n",
      " 36  fb_ad_14_comment_count   16050 non-null  float64       \n",
      " 37  fb_ad_15_comment_count   15934 non-null  float64       \n",
      " 38  fb_ad_0_reaction_count   9389 non-null   float64       \n",
      " 39  fb_ad_1_reaction_count   14407 non-null  float64       \n",
      " 40  fb_ad_2_reaction_count   15363 non-null  float64       \n",
      " 41  fb_ad_3_reaction_count   16059 non-null  float64       \n",
      " 42  fb_ad_4_reaction_count   16531 non-null  float64       \n",
      " 43  fb_ad_5_reaction_count   16527 non-null  float64       \n",
      " 44  fb_ad_6_reaction_count   16534 non-null  float64       \n",
      " 45  fb_ad_7_reaction_count   16476 non-null  float64       \n",
      " 46  fb_ad_8_reaction_count   16163 non-null  float64       \n",
      " 47  fb_ad_9_reaction_count   16232 non-null  float64       \n",
      " 48  fb_ad_10_reaction_count  16482 non-null  float64       \n",
      " 49  fb_ad_11_reaction_count  16673 non-null  float64       \n",
      " 50  fb_ad_12_reaction_count  16567 non-null  float64       \n",
      " 51  fb_ad_13_reaction_count  16266 non-null  float64       \n",
      " 52  fb_ad_14_reaction_count  16050 non-null  float64       \n",
      " 53  fb_ad_15_reaction_count  15934 non-null  float64       \n",
      " 54  fb_ad_0_share_count      9389 non-null   float64       \n",
      " 55  fb_ad_1_share_count      14407 non-null  float64       \n",
      " 56  fb_ad_2_share_count      15363 non-null  float64       \n",
      " 57  fb_ad_3_share_count      16059 non-null  float64       \n",
      " 58  fb_ad_4_share_count      16531 non-null  float64       \n",
      " 59  fb_ad_5_share_count      16527 non-null  float64       \n",
      " 60  fb_ad_6_share_count      16534 non-null  float64       \n",
      " 61  fb_ad_7_share_count      16476 non-null  float64       \n",
      " 62  fb_ad_8_share_count      16163 non-null  float64       \n",
      " 63  fb_ad_9_share_count      16232 non-null  float64       \n",
      " 64  fb_ad_10_share_count     16482 non-null  float64       \n",
      " 65  fb_ad_11_share_count     16673 non-null  float64       \n",
      " 66  fb_ad_12_share_count     16567 non-null  float64       \n",
      " 67  fb_ad_13_share_count     16266 non-null  float64       \n",
      " 68  fb_ad_14_share_count     16050 non-null  float64       \n",
      " 69  fb_ad_15_share_count     15934 non-null  float64       \n",
      " 70  fb_popularity_ad_0       20280 non-null  float64       \n",
      " 71  fb_popularity_ad_1       20280 non-null  float64       \n",
      " 72  fb_popularity_ad_2       20280 non-null  float64       \n",
      " 73  fb_popularity_ad_3       20280 non-null  float64       \n",
      " 74  fb_popularity_ad_4       20280 non-null  float64       \n",
      " 75  fb_popularity_ad_5       20280 non-null  float64       \n",
      " 76  fb_popularity_ad_6       20280 non-null  float64       \n",
      " 77  fb_popularity_ad_7       20280 non-null  float64       \n",
      " 78  fb_popularity_ad_8       20280 non-null  float64       \n",
      " 79  fb_popularity_ad_9       20280 non-null  float64       \n",
      " 80  fb_popularity_ad_10      20280 non-null  float64       \n",
      " 81  fb_popularity_ad_11      20280 non-null  float64       \n",
      " 82  fb_popularity_ad_12      20280 non-null  float64       \n",
      " 83  fb_popularity_ad_13      20280 non-null  float64       \n",
      " 84  fb_popularity_ad_14      20280 non-null  float64       \n",
      " 85  fb_popularity_ad_15      20280 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(64), int64(10), object(10)\n",
      "memory usage: 13.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rozdelenie hodnot popularity do 5 skupin\n",
    "\n",
    "- `0 - 0.5`\n",
    "- `0.5 - 0.75`\n",
    "- `0.75 - 0.9`\n",
    "- `0.9 - 0.95`\n",
    "- `0.95 - 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_labels(df, quantiles, column='fb_popularity_ad_15'):\n",
    "    df = df.copy()\n",
    "    label_str = f'{column}_label'\n",
    "    \n",
    "    df[label_str] = -1\n",
    "    \n",
    "    label = 1    \n",
    "    for i in range(len(quantiles) - 1):\n",
    "        low = df[column].quantile(quantiles[i])\n",
    "        high = df[column].quantile(quantiles[i + 1])\n",
    "        \n",
    "        df.loc[(low <= df[column]) & (df[column] <= high), label_str] = int(label)\n",
    "        \n",
    "        label += 1\n",
    "    df = df.drop(columns=[column])    \n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00          0.0\n",
      "0.50         27.0\n",
      "0.75        336.0\n",
      "0.90       1875.0\n",
      "0.95       5344.7\n",
      "1.00    1369290.0\n",
      "Name: fb_ad_15_reaction_count, dtype: float64\n",
      "0.00         0.00\n",
      "0.50         4.00\n",
      "0.75        72.00\n",
      "0.90       482.70\n",
      "0.95      1356.05\n",
      "1.00    898615.00\n",
      "Name: fb_ad_15_comment_count, dtype: float64\n",
      "0.00         0.00\n",
      "0.50        30.00\n",
      "0.75       159.00\n",
      "0.90       684.40\n",
      "0.95      1754.35\n",
      "1.00    404542.00\n",
      "Name: fb_ad_15_share_count, dtype: float64\n",
      "0.00          0.0\n",
      "0.50         17.0\n",
      "0.75        336.0\n",
      "0.90       2112.5\n",
      "0.95       6159.1\n",
      "1.00    2566473.0\n",
      "Name: fb_popularity_ad_15, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "quantiles = [\n",
    "    0,\n",
    "    .50,\n",
    "    .75,\n",
    "    .90,\n",
    "    .95,\n",
    "    1\n",
    "]\n",
    "\n",
    "cols = [\n",
    "    'fb_ad_15_reaction_count',\n",
    "    'fb_ad_15_comment_count',\n",
    "    'fb_ad_15_share_count',\n",
    "    'fb_popularity_ad_15'\n",
    "]\n",
    "\n",
    "for i in cols:\n",
    "    print(df[i].quantile(quantiles))\n",
    "    df = add_labels(df, quantiles, column=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pri jednotlivych zlozkach sme pri tomto rozdeleni nasli len 4 skupiny (lebo 1 == 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jednoducha heuristika: ak je zdroj nedoveryhodny tak aj clanok je nedoveryhodny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_fake_news_label'] = df.source_is_reliable.replace({0:1, 1:0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = list(filter(lambda x: x.endswith('_label'), df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ln in label_names:\n",
    "    df[ln] = pd.to_numeric(df[ln])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labely\n",
    "labels_df = pd.concat([labels_df] + [df[label_name] for label_name in label_names], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20246 entries, 428781 to 812426\n",
      "Data columns (total 87 columns):\n",
      " #   Column                         Non-Null Count  Dtype         \n",
      "---  ------                         --------------  -----         \n",
      " 0   title                          20246 non-null  object        \n",
      " 1   perex                          20246 non-null  object        \n",
      " 2   body                           20246 non-null  object        \n",
      " 3   published_at                   20246 non-null  datetime64[ns]\n",
      " 4   extracted_at                   20246 non-null  datetime64[ns]\n",
      " 5   category                       13685 non-null  object        \n",
      " 6   other_info                     20242 non-null  object        \n",
      " 7   image_count                    20246 non-null  int64         \n",
      " 8   video_count                    20246 non-null  int64         \n",
      " 9   author_name                    20246 non-null  object        \n",
      " 10  source_id                      20246 non-null  int64         \n",
      " 11  source_name                    20246 non-null  object        \n",
      " 12  source_url                     20246 non-null  object        \n",
      " 13  source_type                    20246 non-null  object        \n",
      " 14  source_is_reliable             20246 non-null  int64         \n",
      " 15  av_veracity                    4249 non-null   object        \n",
      " 16  av_claims_false                20246 non-null  int64         \n",
      " 17  av_claims_mostly_false         20246 non-null  int64         \n",
      " 18  av_claims_mixture              20246 non-null  int64         \n",
      " 19  av_claims_mostly_true          20246 non-null  int64         \n",
      " 20  av_claims_true                 20246 non-null  int64         \n",
      " 21  av_claims_unknown              20246 non-null  int64         \n",
      " 22  fb_ad_0_comment_count          9371 non-null   float64       \n",
      " 23  fb_ad_1_comment_count          14380 non-null  float64       \n",
      " 24  fb_ad_2_comment_count          15336 non-null  float64       \n",
      " 25  fb_ad_3_comment_count          16029 non-null  float64       \n",
      " 26  fb_ad_4_comment_count          16502 non-null  float64       \n",
      " 27  fb_ad_5_comment_count          16498 non-null  float64       \n",
      " 28  fb_ad_6_comment_count          16508 non-null  float64       \n",
      " 29  fb_ad_7_comment_count          16453 non-null  float64       \n",
      " 30  fb_ad_8_comment_count          16140 non-null  float64       \n",
      " 31  fb_ad_9_comment_count          16209 non-null  float64       \n",
      " 32  fb_ad_10_comment_count         16459 non-null  float64       \n",
      " 33  fb_ad_11_comment_count         16646 non-null  float64       \n",
      " 34  fb_ad_12_comment_count         16541 non-null  float64       \n",
      " 35  fb_ad_13_comment_count         16240 non-null  float64       \n",
      " 36  fb_ad_14_comment_count         16024 non-null  float64       \n",
      " 37  fb_ad_0_reaction_count         9371 non-null   float64       \n",
      " 38  fb_ad_1_reaction_count         14380 non-null  float64       \n",
      " 39  fb_ad_2_reaction_count         15336 non-null  float64       \n",
      " 40  fb_ad_3_reaction_count         16029 non-null  float64       \n",
      " 41  fb_ad_4_reaction_count         16502 non-null  float64       \n",
      " 42  fb_ad_5_reaction_count         16498 non-null  float64       \n",
      " 43  fb_ad_6_reaction_count         16508 non-null  float64       \n",
      " 44  fb_ad_7_reaction_count         16453 non-null  float64       \n",
      " 45  fb_ad_8_reaction_count         16140 non-null  float64       \n",
      " 46  fb_ad_9_reaction_count         16209 non-null  float64       \n",
      " 47  fb_ad_10_reaction_count        16459 non-null  float64       \n",
      " 48  fb_ad_11_reaction_count        16646 non-null  float64       \n",
      " 49  fb_ad_12_reaction_count        16541 non-null  float64       \n",
      " 50  fb_ad_13_reaction_count        16240 non-null  float64       \n",
      " 51  fb_ad_14_reaction_count        16024 non-null  float64       \n",
      " 52  fb_ad_0_share_count            9371 non-null   float64       \n",
      " 53  fb_ad_1_share_count            14380 non-null  float64       \n",
      " 54  fb_ad_2_share_count            15336 non-null  float64       \n",
      " 55  fb_ad_3_share_count            16029 non-null  float64       \n",
      " 56  fb_ad_4_share_count            16502 non-null  float64       \n",
      " 57  fb_ad_5_share_count            16498 non-null  float64       \n",
      " 58  fb_ad_6_share_count            16508 non-null  float64       \n",
      " 59  fb_ad_7_share_count            16453 non-null  float64       \n",
      " 60  fb_ad_8_share_count            16140 non-null  float64       \n",
      " 61  fb_ad_9_share_count            16209 non-null  float64       \n",
      " 62  fb_ad_10_share_count           16459 non-null  float64       \n",
      " 63  fb_ad_11_share_count           16646 non-null  float64       \n",
      " 64  fb_ad_12_share_count           16541 non-null  float64       \n",
      " 65  fb_ad_13_share_count           16240 non-null  float64       \n",
      " 66  fb_ad_14_share_count           16024 non-null  float64       \n",
      " 67  fb_popularity_ad_0             20246 non-null  float64       \n",
      " 68  fb_popularity_ad_1             20246 non-null  float64       \n",
      " 69  fb_popularity_ad_2             20246 non-null  float64       \n",
      " 70  fb_popularity_ad_3             20246 non-null  float64       \n",
      " 71  fb_popularity_ad_4             20246 non-null  float64       \n",
      " 72  fb_popularity_ad_5             20246 non-null  float64       \n",
      " 73  fb_popularity_ad_6             20246 non-null  float64       \n",
      " 74  fb_popularity_ad_7             20246 non-null  float64       \n",
      " 75  fb_popularity_ad_8             20246 non-null  float64       \n",
      " 76  fb_popularity_ad_9             20246 non-null  float64       \n",
      " 77  fb_popularity_ad_10            20246 non-null  float64       \n",
      " 78  fb_popularity_ad_11            20246 non-null  float64       \n",
      " 79  fb_popularity_ad_12            20246 non-null  float64       \n",
      " 80  fb_popularity_ad_13            20246 non-null  float64       \n",
      " 81  fb_popularity_ad_14            20246 non-null  float64       \n",
      " 82  fb_ad_15_reaction_count_label  20246 non-null  int64         \n",
      " 83  fb_ad_15_comment_count_label   20246 non-null  int64         \n",
      " 84  fb_ad_15_share_count_label     20246 non-null  int64         \n",
      " 85  fb_popularity_ad_15_label      20246 non-null  int64         \n",
      " 86  is_fake_news_label             20246 non-null  int64         \n",
      "dtypes: datetime64[ns](2), float64(60), int64(15), object(10)\n",
      "memory usage: 13.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rozdelenie dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, validation = tuple(split_data(df, sizes=[2, 2, 1], shuffle=True, np_random=np_random))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8099, 8098, 4049]\n"
     ]
    }
   ],
   "source": [
    "print([len(i) for i in [train,test,validation]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fb_ad_15_reaction_count_label',\n",
       " 'fb_ad_15_comment_count_label',\n",
       " 'fb_ad_15_share_count_label',\n",
       " 'fb_popularity_ad_15_label',\n",
       " 'is_fake_news_label']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from textblob import TextBlob\n",
    "import textstat\n",
    "\n",
    "import spacy\n",
    "importlib.reload(spacy)\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    doc = nlp(text, disable=['parser', 'tagger', 'ner'])\n",
    "    \n",
    "    res = []\n",
    "    for i in doc:\n",
    "        if i.is_stop:\n",
    "            continue\n",
    "        if i.is_punct:\n",
    "            continue\n",
    "            \n",
    "        res.append(str(i))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# textblob repre\n",
    "\n",
    "# spacy repre\n",
    "\n",
    "# textstat repre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skupina 'forma obsahu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Content:\n",
    "    # title word count\n",
    "    # content word count\n",
    "    \n",
    "    # title length\n",
    "    # content lenth\n",
    "    \n",
    "    # avg word len\n",
    "    # sentences count\n",
    "\n",
    "    # count of words over 5 chars\n",
    "    \n",
    "    # count of ?\n",
    "    # count of !\n",
    "    # count of ...\n",
    "    \n",
    "    # count of media\n",
    "    \n",
    "    # POS tags\n",
    "    # stop words count\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skupina 'metadata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_basic_features(df):\n",
    "    cv = CountVectorizer()\n",
    "    data = cv.fit_transform(df.title)\n",
    "\n",
    "    res = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    res['title_word_count'] = data.sum(axis=1)\n",
    "    res['title_char_length'] = df.title.apply(lambda x: len(x))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perex_basic_features(df):\n",
    "    cv = CountVectorizer()\n",
    "    data = cv.fit_transform(df.perex)\n",
    "\n",
    "    res = pd.DataFrame(index=df.index)    \n",
    "    res['perex_word_count'] = data.sum(axis=1)\n",
    "    res['perex_char_length'] = df.perex.apply(lambda x: len(x))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_basic_features(df):\n",
    "    content_cv = CountVectorizer()\n",
    "    data = content_cv.fit_transform(df.body)\n",
    "\n",
    "    res = pd.DataFrame(index=df.index)    \n",
    "    res['content_word_count'] = data.sum(axis=1)\n",
    "    res['content_char_length'] = df.body.apply(lambda x: len(x))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def media_count_total(df):\n",
    "    res = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    res['media_count_total'] = df['image_count'] + df['video_count']\n",
    "    \n",
    "    return res\n",
    "    \n",
    "def media_count_image(df):\n",
    "    return column_feature(df, 'image_count')\n",
    "\n",
    "def media_count_video(df):\n",
    "    return column_feature(df, 'video_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popularity_features(df):\n",
    "    res = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    \n",
    "    for i in [0,1,3]:\n",
    "        res[f'fb_ad_{i}_reaction_count'] = df[f'fb_ad_{i}_reaction_count']\n",
    "        res[f'fb_ad_{i}_comment_count'] = df[f'fb_ad_{i}_comment_count']\n",
    "        res[f'fb_ad_{i}_share_count'] = df[f'fb_ad_{i}_share_count']\n",
    "        res[f'fb_popularity_ad_{i}'] = df[f'fb_popularity_ad_{i}']\n",
    "        \n",
    "    \n",
    "    res.fillna(res.mean(), inplace=True)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_collective_author(df):\n",
    "    \n",
    "    uniq_source_names = df.source_name.unique()\n",
    "    def make_a_guess(author_name):\n",
    "        return any((\n",
    "                    str_contains(author_name, 'admin', case=False),\n",
    "                    author_name.startswith('Neuroscience News Posts Science Research News Labs Universities Hospitals News Departments Around The World'),\n",
    "                    author_name in ['Neuroscience News',\n",
    "                                    'Wake Up World',\n",
    "                                    'Health Sciences Institute',\n",
    "                                    'REALdeal', \n",
    "                                    'nmheditor',\n",
    "                                    'The Mind Unleashed',\n",
    "                                    'Thinking Moms\\' Revolution',\n",
    "                                    'TheNewsDoctors',\n",
    "                                    'clnews',\n",
    "                                    'Associated Press',\n",
    "                                    'HealthDay',\n",
    "                                    'Infowars',\n",
    "                                    'Natural News Editors',\n",
    "                                    'https://www.facebook.com/WebMD',\n",
    "                                    'naturalnews',\n",
    "                                    'peakconsciousness',\n",
    "                                    'HealingwithoutHurting',\n",
    "                                    'HealthNutNews.com',\n",
    "                                   ],\n",
    "                    author_name.startswith('The Associated Press'),\n",
    "                    # ' and ' in author_name, # todo: je to kolektivny autor ak ich je len viac?\n",
    "                    author_name in uniq_source_names,   \n",
    "        ))\n",
    "    \n",
    "    res = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    res['is_collective_author'] = df.author_name.map(make_a_guess)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    title_basic_features,\n",
    "    perex_basic_features,\n",
    "    content_basic_features,\n",
    "    \n",
    "    media_count_total,\n",
    "    media_count_image,\n",
    "    media_count_video,\n",
    "    \n",
    "    published_on_day,\n",
    "    is_collective_author,\n",
    "    \n",
    "    claim_counts,\n",
    "    \n",
    "    popularity_features,\n",
    "    readability_features\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df):    \n",
    "    pbar_conf = {\n",
    "        'refresh_rate': 1,\n",
    "        'action_names': [i.__name__ for i in features]\n",
    "    }\n",
    "    \n",
    "    res = pd.DataFrame()\n",
    "    for feature_generator in Pbar(features, **pbar_conf):\n",
    "        res = pd.concat([res, feature_generator(df)], axis=1)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = split_X_y_all(train, test, validation, selected_label='is_fake_news_label', all_labels=label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] -- 10 / 10 -- (finished)\n"
     ]
    }
   ],
   "source": [
    "data.train.features = add_features(data.train.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] -- 10 / 10 -- (finished)\n"
     ]
    }
   ],
   "source": [
    "data.test.features = add_features(data.test.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] -- 10 / 10 -- (finished)\n"
     ]
    }
   ],
   "source": [
    "data.validation.features = add_features(data.validation.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fb_ad_15_reaction_count_label',\n",
       " 'fb_ad_15_comment_count_label',\n",
       " 'fb_ad_15_share_count_label',\n",
       " 'fb_popularity_ad_15_label',\n",
       " 'is_fake_news_label']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_to_file(data, file):\n",
    "    with open(file, 'w', encoding='utf-8') as f:\n",
    "        for i in Pbar(data):\n",
    "            f.write(f\"{' '.join(tokenize(i))}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 12 cores available\n"
     ]
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "print(f'>>> {cores} cores available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] -- 8099 / 8099 -- (finished)\n",
      "[==================================================] -- 8098 / 8098 -- (finished)\n",
      "[==================================================] -- 4049 / 4049 -- (finished)\n"
     ]
    }
   ],
   "source": [
    "tokenize_to_file(data.train.X.body, './data/train_body_tokenized.txt')\n",
    "tokenize_to_file(data.test.X.body, './data/test_body_tokenized.txt')\n",
    "tokenize_to_file(data.validation.X.body, './data/validation_body_tokenized.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-27 11:30:50,863 : INFO : collecting all words and their counts\n",
      "2020-04-27 11:30:50,864 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2020-04-27 11:30:51,711 : INFO : collected 90408 word types and 8099 unique tags from a corpus of 8099 examples and 2789006 words\n",
      "2020-04-27 11:30:51,712 : INFO : Loading a fresh vocabulary\n",
      "2020-04-27 11:30:51,878 : INFO : effective_min_count=2 retains 51892 unique words (57% of original 90408, drops 38516)\n",
      "2020-04-27 11:30:51,878 : INFO : effective_min_count=2 leaves 2750490 word corpus (98% of original 2789006, drops 38516)\n",
      "2020-04-27 11:30:52,056 : INFO : deleting the raw counts dictionary of 90408 items\n",
      "2020-04-27 11:30:52,059 : INFO : sample=0.001 downsamples 9 most-common words\n",
      "2020-04-27 11:30:52,060 : INFO : downsampling leaves estimated 2721940 word corpus (99.0% of prior 2750490)\n",
      "2020-04-27 11:30:52,213 : INFO : estimated required memory for 51892 words and 300 dimensions: 160205600 bytes\n",
      "2020-04-27 11:30:52,214 : INFO : resetting layer weights\n",
      "2020-04-27 11:31:05,982 : INFO : training model with 12 workers on 51892 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-27 11:31:08,278 : INFO : EPOCH 1 - PROGRESS: at 8.47% examples, 103718 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-27 11:31:08,279 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-04-27 11:31:08,423 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-04-27 11:31:08,440 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-04-27 11:31:08,451 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-04-27 11:31:08,517 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-27 11:31:08,529 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-27 11:31:08,599 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-27 11:31:08,606 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-27 11:31:08,746 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-27 11:31:08,750 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-27 11:31:08,776 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-27 11:31:08,793 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-27 11:31:08,794 : INFO : EPOCH - 1 : training on 2791076 raw words (2731929 effective words) took 2.7s, 1007789 effective words/s\n",
      "2020-04-27 11:31:10,976 : INFO : EPOCH 2 - PROGRESS: at 8.56% examples, 107446 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-27 11:31:10,978 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-04-27 11:31:10,992 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-04-27 11:31:10,999 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-04-27 11:31:11,070 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-04-27 11:31:11,098 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-27 11:31:11,104 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-27 11:31:11,164 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-27 11:31:11,205 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-27 11:31:11,338 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-27 11:31:11,385 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-27 11:31:11,415 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-27 11:31:11,459 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-27 11:31:11,460 : INFO : EPOCH - 2 : training on 2791076 raw words (2732163 effective words) took 2.6s, 1049396 effective words/s\n",
      "2020-04-27 11:31:13,785 : INFO : EPOCH 3 - PROGRESS: at 8.25% examples, 102454 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-27 11:31:13,787 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-04-27 11:31:13,828 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-04-27 11:31:13,839 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-04-27 11:31:13,886 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-04-27 11:31:13,920 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-27 11:31:13,931 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-27 11:31:13,959 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-27 11:31:13,993 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-27 11:31:14,267 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-27 11:31:14,276 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-27 11:31:14,335 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-27 11:31:14,392 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-27 11:31:14,394 : INFO : EPOCH - 3 : training on 2791076 raw words (2731958 effective words) took 2.8s, 965117 effective words/s\n",
      "2020-04-27 11:31:16,745 : INFO : EPOCH 4 - PROGRESS: at 8.47% examples, 100740 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-27 11:31:16,747 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-04-27 11:31:16,776 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-04-27 11:31:16,817 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-04-27 11:31:16,819 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-04-27 11:31:16,823 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-27 11:31:16,845 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-27 11:31:16,873 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-27 11:31:16,883 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-27 11:31:17,065 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-27 11:31:17,069 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-27 11:31:17,076 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-27 11:31:17,099 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-27 11:31:17,101 : INFO : EPOCH - 4 : training on 2791076 raw words (2732188 effective words) took 2.6s, 1044526 effective words/s\n",
      "2020-04-27 11:31:19,513 : INFO : EPOCH 5 - PROGRESS: at 8.56% examples, 98541 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-27 11:31:19,515 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-04-27 11:31:19,523 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-04-27 11:31:19,526 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-04-27 11:31:19,528 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-04-27 11:31:19,535 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-27 11:31:19,545 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-27 11:31:19,558 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-27 11:31:19,574 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-27 11:31:19,595 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-27 11:31:19,632 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-27 11:31:19,633 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-27 11:31:19,635 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-27 11:31:19,636 : INFO : EPOCH - 5 : training on 2791076 raw words (2732257 effective words) took 2.4s, 1123041 effective words/s\n",
      "2020-04-27 11:31:21,866 : INFO : EPOCH 6 - PROGRESS: at 8.36% examples, 105698 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-27 11:31:21,868 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-04-27 11:31:21,890 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-04-27 11:31:21,893 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-04-27 11:31:21,924 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-04-27 11:31:21,936 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-27 11:31:21,959 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-27 11:31:21,989 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-27 11:31:21,992 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-27 11:31:22,012 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-27 11:31:22,025 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-27 11:31:22,058 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-27 11:31:22,063 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-27 11:31:22,064 : INFO : EPOCH - 6 : training on 2791076 raw words (2731884 effective words) took 2.3s, 1162893 effective words/s\n",
      "2020-04-27 11:31:24,237 : INFO : EPOCH 7 - PROGRESS: at 8.42% examples, 108667 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-27 11:31:24,239 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-04-27 11:31:24,273 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-04-27 11:31:24,291 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-04-27 11:31:24,300 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-04-27 11:31:24,324 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-27 11:31:24,342 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-27 11:31:24,376 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-27 11:31:24,389 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-27 11:31:24,413 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-27 11:31:24,447 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-27 11:31:24,464 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-27 11:31:24,484 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-27 11:31:24,485 : INFO : EPOCH - 7 : training on 2791076 raw words (2732281 effective words) took 2.3s, 1166238 effective words/s\n",
      "2020-04-27 11:31:26,611 : INFO : EPOCH 8 - PROGRESS: at 8.25% examples, 111670 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-27 11:31:26,625 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-04-27 11:31:26,646 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-04-27 11:31:26,722 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-04-27 11:31:26,743 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-04-27 11:31:26,784 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-27 11:31:26,803 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-27 11:31:26,821 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-27 11:31:26,879 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-27 11:31:26,894 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-27 11:31:26,913 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-27 11:31:26,961 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-27 11:31:27,006 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-27 11:31:27,007 : INFO : EPOCH - 8 : training on 2791076 raw words (2731976 effective words) took 2.4s, 1119111 effective words/s\n",
      "2020-04-27 11:31:29,208 : INFO : EPOCH 9 - PROGRESS: at 8.47% examples, 107324 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-27 11:31:29,209 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-04-27 11:31:29,241 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-04-27 11:31:29,266 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-04-27 11:31:29,276 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-04-27 11:31:29,329 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-27 11:31:29,341 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-27 11:31:29,361 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-27 11:31:29,370 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-27 11:31:29,393 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-27 11:31:29,394 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-27 11:31:29,405 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-27 11:31:29,411 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-27 11:31:29,412 : INFO : EPOCH - 9 : training on 2791076 raw words (2731958 effective words) took 2.3s, 1174957 effective words/s\n",
      "2020-04-27 11:31:31,538 : INFO : EPOCH 10 - PROGRESS: at 8.47% examples, 113081 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-27 11:31:31,540 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-04-27 11:31:31,612 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-04-27 11:31:31,617 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-04-27 11:31:31,666 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-04-27 11:31:31,689 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-27 11:31:31,726 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-27 11:31:31,731 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-27 11:31:31,761 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-27 11:31:31,785 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-27 11:31:31,815 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-27 11:31:31,822 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-27 11:31:31,827 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-27 11:31:31,828 : INFO : EPOCH - 10 : training on 2791076 raw words (2732147 effective words) took 2.3s, 1186417 effective words/s\n",
      "2020-04-27 11:31:33,949 : INFO : EPOCH 11 - PROGRESS: at 8.36% examples, 110530 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-27 11:31:33,951 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-04-27 11:31:33,970 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-04-27 11:31:33,974 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-04-27 11:31:33,976 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-04-27 11:31:33,987 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-27 11:31:33,998 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-27 11:31:34,008 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-27 11:31:34,029 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-27 11:31:34,062 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-27 11:31:34,086 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-27 11:31:34,137 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-27 11:31:34,142 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-27 11:31:34,143 : INFO : EPOCH - 11 : training on 2791076 raw words (2732012 effective words) took 2.3s, 1212748 effective words/s\n",
      "2020-04-27 11:31:36,266 : INFO : EPOCH 12 - PROGRESS: at 8.25% examples, 110123 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-27 11:31:36,268 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-04-27 11:31:36,323 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-04-27 11:31:36,327 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-04-27 11:31:36,343 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-04-27 11:31:36,363 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-27 11:31:36,371 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-27 11:31:36,394 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-27 11:31:36,412 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-27 11:31:36,424 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-27 11:31:36,425 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-27 11:31:36,437 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-27 11:31:36,462 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-27 11:31:36,463 : INFO : EPOCH - 12 : training on 2791076 raw words (2731918 effective words) took 2.3s, 1206476 effective words/s\n",
      "2020-04-27 11:31:38,636 : INFO : EPOCH 13 - PROGRESS: at 8.36% examples, 108699 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-27 11:31:38,637 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-04-27 11:31:38,657 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-04-27 11:31:38,672 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-04-27 11:31:38,674 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-04-27 11:31:38,692 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-27 11:31:38,693 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-27 11:31:38,723 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-27 11:31:38,735 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-27 11:31:38,743 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-27 11:31:38,745 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-27 11:31:38,780 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-27 11:31:38,814 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-27 11:31:38,816 : INFO : EPOCH - 13 : training on 2791076 raw words (2731646 effective words) took 2.3s, 1202229 effective words/s\n",
      "2020-04-27 11:31:40,886 : INFO : EPOCH 14 - PROGRESS: at 8.47% examples, 115056 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-27 11:31:40,888 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-04-27 11:31:40,900 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-04-27 11:31:40,930 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-04-27 11:31:40,950 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-04-27 11:31:40,962 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-27 11:31:41,003 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-27 11:31:41,012 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-27 11:31:41,067 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-27 11:31:41,103 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-27 11:31:41,128 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-27 11:31:41,142 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-27 11:31:41,156 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-27 11:31:41,157 : INFO : EPOCH - 14 : training on 2791076 raw words (2731746 effective words) took 2.2s, 1214307 effective words/s\n",
      "2020-04-27 11:31:43,316 : INFO : EPOCH 15 - PROGRESS: at 8.24% examples, 109124 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-27 11:31:43,318 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-04-27 11:31:43,364 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-04-27 11:31:43,366 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-04-27 11:31:43,378 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-04-27 11:31:43,399 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-27 11:31:43,411 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-27 11:31:43,466 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-27 11:31:43,473 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-27 11:31:43,591 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-27 11:31:43,608 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-27 11:31:43,624 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-27 11:31:43,625 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-27 11:31:43,625 : INFO : EPOCH - 15 : training on 2791076 raw words (2732309 effective words) took 2.4s, 1141712 effective words/s\n",
      "2020-04-27 11:31:43,630 : INFO : training on a 41866140 raw words (40980372 effective words) took 37.6s, 1088564 effective words/s\n"
     ]
    }
   ],
   "source": [
    "d2v = Doc2Vec(corpus_file='./data/train_body_tokenized.txt', vector_size=300, min_count=2, epochs=15, workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_d2v(d2v_model, data_file):\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    with open(data_file, 'r', encoding='utf-8') as f:\n",
    "        for i in Pbar(f.readlines()):\n",
    "            res.append(d2v_model.infer_vector(i.split(' '), steps=20, alpha=0.025)) \n",
    "    \n",
    "    return res\n",
    "\n",
    "def infer_for_df(df, d2v_model, data_file):\n",
    "    lst = infer_d2v(d2v_model, data_file)\n",
    "    d2v_df = pd.DataFrame(lst, index=df.index, columns=[f'd2v_{i}' for i in range(1, 301)] )\n",
    "    \n",
    "    return pd.concat([df, d2v_df], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] -- 8099 / 8099 -- (finished)\n"
     ]
    }
   ],
   "source": [
    "data.train.features = infer_for_df(data.train.features, d2v, './data/train_body_tokenized.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] -- 8098 / 8098 -- (finished)\n"
     ]
    }
   ],
   "source": [
    "data.test.features = infer_for_df(data.test.features, d2v, './data/test_body_tokenized.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(clf, data):\n",
    "    clf.fit(data.train.features, data.train.y)\n",
    "    return clf.predict(data.test.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fb_ad_15_reaction_count_label',\n",
       " 'fb_ad_15_comment_count_label',\n",
       " 'fb_ad_15_share_count_label',\n",
       " 'fb_popularity_ad_15_label',\n",
       " 'is_fake_news_label']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train.switch_label('is_fake_news_label')\n",
    "data.test.switch_label('is_fake_news_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train.features['media_count_total'] = pd.to_numeric(data.train.features['media_count_total'])\n",
    "data.train.features['image_count'] = pd.to_numeric(data.train.features['image_count'])\n",
    "data.train.features['video_count'] = pd.to_numeric(data.train.features['video_count'])\n",
    "\n",
    "data.test.features['media_count_total'] = pd.to_numeric(data.test.features['media_count_total'])\n",
    "data.test.features['image_count'] = pd.to_numeric(data.test.features['image_count'])\n",
    "data.test.features['video_count'] = pd.to_numeric(data.test.features['video_count'])\n",
    "\n",
    "data.train.features['av_claims_false'] = pd.to_numeric(data.train.features['av_claims_false'])\n",
    "data.train.features['av_claims_mostly_false'] = pd.to_numeric(data.train.features['av_claims_mostly_false'])\n",
    "data.train.features['av_claims_mixture'] = pd.to_numeric(data.train.features['av_claims_mixture'])\n",
    "data.train.features['av_claims_mostly_true'] = pd.to_numeric(data.train.features['av_claims_mostly_true'])\n",
    "data.train.features['av_claims_true'] = pd.to_numeric(data.train.features['av_claims_true'])\n",
    "data.train.features['av_claims_unknown'] = pd.to_numeric(data.train.features['av_claims_unknown'])\n",
    "\n",
    "\n",
    "data.test.features['av_claims_false'] = pd.to_numeric(data.test.features['av_claims_false'])\n",
    "data.test.features['av_claims_mostly_false'] = pd.to_numeric(data.test.features['av_claims_mostly_false'])\n",
    "data.test.features['av_claims_mixture'] = pd.to_numeric(data.test.features['av_claims_mixture'])\n",
    "data.test.features['av_claims_mostly_true'] = pd.to_numeric(data.test.features['av_claims_mostly_true'])\n",
    "data.test.features['av_claims_true'] = pd.to_numeric(data.test.features['av_claims_true'])\n",
    "data.test.features['av_claims_unknown'] = pd.to_numeric(data.test.features['av_claims_unknown'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train.features.drop(columns=['perex_word_count', 'perex_char_length'], inplace=True)\n",
    "data.test.features.drop(columns=['perex_word_count', 'perex_char_length'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train.y = pd.to_numeric(data.train.y)\n",
    "data.test.y = pd.to_numeric(data.test.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=======================================             ] (processing: LogisticRegression) -- 3 / 4"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================================================] -- 4 / 4 -- (finished)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      4838\n",
      "           1       0.93      0.81      0.87      3260\n",
      "\n",
      "    accuracy                           0.90      8098\n",
      "   macro avg       0.90      0.88      0.89      8098\n",
      "weighted avg       0.90      0.90      0.90      8098\n",
      "\n",
      "------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92      4838\n",
      "           1       0.91      0.84      0.87      3260\n",
      "\n",
      "    accuracy                           0.90      8098\n",
      "   macro avg       0.90      0.89      0.90      8098\n",
      "weighted avg       0.90      0.90      0.90      8098\n",
      "\n",
      "------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.88      0.82      4838\n",
      "           1       0.77      0.61      0.68      3260\n",
      "\n",
      "    accuracy                           0.77      8098\n",
      "   macro avg       0.77      0.74      0.75      8098\n",
      "weighted avg       0.77      0.77      0.76      8098\n",
      "\n",
      "------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73      4838\n",
      "           1       0.61      0.75      0.67      3260\n",
      "\n",
      "    accuracy                           0.70      8098\n",
      "   macro avg       0.70      0.71      0.70      8098\n",
      "weighted avg       0.72      0.70      0.71      8098\n",
      "\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=cores),\n",
    "    XGBClassifier(n_jobs=cores, seed=RANDOM_STATE),\n",
    "    GaussianNB(),\n",
    "    LogisticRegression()\n",
    "]\n",
    "\n",
    "pbar_conf = {\n",
    "    'refresh_rate': 1,\n",
    "    'length': len(classifiers), \n",
    "    'pbar_width': 52,\n",
    "    'action_names': [i.__class__.__name__ for i in classifiers]\n",
    "}\n",
    "\n",
    "predictions = list(Pbar((fit_predict(clf, data) for clf in classifiers), **pbar_conf))\n",
    "\n",
    "for p in predictions:\n",
    "    print(classification_report(data.test.y, p))\n",
    "    print('-' * 54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[====================================================] -- 2 / 2 -- (finished)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.89      0.96      0.92      4838\n",
    "           1       0.92      0.82      0.87      3260\n",
    "\n",
    "    accuracy                           0.90      8098\n",
    "   macro avg       0.91      0.89      0.89      8098\n",
    "weighted avg       0.90      0.90      0.90      8098\n",
    "\n",
    "------------------------------------------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.90      0.94      0.92      4838\n",
    "           1       0.90      0.84      0.87      3260\n",
    "\n",
    "    accuracy                           0.90      8098\n",
    "   macro avg       0.90      0.89      0.89      8098\n",
    "weighted avg       0.90      0.90      0.90      8098\n",
    "\n",
    "------------------------------------------------------\n",
    "\n",
    "[====================================================] -- 2 / 2 -- (finished)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.83      0.88      0.85      4838\n",
    "           1       0.80      0.73      0.76      3260\n",
    "\n",
    "    accuracy                           0.82      8098\n",
    "   macro avg       0.81      0.80      0.81      8098\n",
    "weighted avg       0.82      0.82      0.82      8098\n",
    "\n",
    "------------------------------------------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.82      0.88      0.85      4838\n",
    "           1       0.81      0.72      0.76      3260\n",
    "\n",
    "    accuracy                           0.82      8098\n",
    "   macro avg       0.82      0.80      0.81      8098\n",
    "weighted avg       0.82      0.82      0.82      8098\n",
    "\n",
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fb_ad_0_share_count</th>\n",
       "      <td>0.037344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb_ad_0_reaction_count</th>\n",
       "      <td>0.032782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_char_length</th>\n",
       "      <td>0.030757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb_ad_0_comment_count</th>\n",
       "      <td>0.026981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content_word_count</th>\n",
       "      <td>0.025531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb_popularity_ad_0</th>\n",
       "      <td>0.024881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_word_count</th>\n",
       "      <td>0.021971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>media_count_total</th>\n",
       "      <td>0.021888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_count</th>\n",
       "      <td>0.021173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb_ad_1_reaction_count</th>\n",
       "      <td>0.020109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content_char_length</th>\n",
       "      <td>0.019831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb_ad_1_share_count</th>\n",
       "      <td>0.019254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb_ad_1_comment_count</th>\n",
       "      <td>0.016520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_collective_author</th>\n",
       "      <td>0.014032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_187</th>\n",
       "      <td>0.013095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_65</th>\n",
       "      <td>0.012808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb_ad_3_share_count</th>\n",
       "      <td>0.011319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb_ad_3_reaction_count</th>\n",
       "      <td>0.009092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb_ad_3_comment_count</th>\n",
       "      <td>0.007162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_272</th>\n",
       "      <td>0.006980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_57</th>\n",
       "      <td>0.006657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_232</th>\n",
       "      <td>0.006600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_119</th>\n",
       "      <td>0.006544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_287</th>\n",
       "      <td>0.006314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_285</th>\n",
       "      <td>0.005826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_4</th>\n",
       "      <td>0.005797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_72</th>\n",
       "      <td>0.005489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_135</th>\n",
       "      <td>0.005329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_44</th>\n",
       "      <td>0.005037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_169</th>\n",
       "      <td>0.004770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_33</th>\n",
       "      <td>0.004689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_12</th>\n",
       "      <td>0.004671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_20</th>\n",
       "      <td>0.004647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_191</th>\n",
       "      <td>0.004597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_276</th>\n",
       "      <td>0.004386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_66</th>\n",
       "      <td>0.004103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_77</th>\n",
       "      <td>0.003998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_200</th>\n",
       "      <td>0.003792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_122</th>\n",
       "      <td>0.003702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb_popularity_ad_1</th>\n",
       "      <td>0.003615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb_popularity_ad_3</th>\n",
       "      <td>0.003585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_104</th>\n",
       "      <td>0.003569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_39</th>\n",
       "      <td>0.003528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_125</th>\n",
       "      <td>0.003473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_40</th>\n",
       "      <td>0.003463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_176</th>\n",
       "      <td>0.003434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_259</th>\n",
       "      <td>0.003307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_177</th>\n",
       "      <td>0.003279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_110</th>\n",
       "      <td>0.003170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_26</th>\n",
       "      <td>0.003168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_214</th>\n",
       "      <td>0.003146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_261</th>\n",
       "      <td>0.003088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_283</th>\n",
       "      <td>0.003056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_69</th>\n",
       "      <td>0.003025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_222</th>\n",
       "      <td>0.002953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_129</th>\n",
       "      <td>0.002939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_265</th>\n",
       "      <td>0.002912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_263</th>\n",
       "      <td>0.002907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_24</th>\n",
       "      <td>0.002895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_152</th>\n",
       "      <td>0.002888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_51</th>\n",
       "      <td>0.002874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_82</th>\n",
       "      <td>0.002862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_258</th>\n",
       "      <td>0.002848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_195</th>\n",
       "      <td>0.002826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_34</th>\n",
       "      <td>0.002759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_227</th>\n",
       "      <td>0.002698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_254</th>\n",
       "      <td>0.002694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_11</th>\n",
       "      <td>0.002687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_203</th>\n",
       "      <td>0.002657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_207</th>\n",
       "      <td>0.002654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_25</th>\n",
       "      <td>0.002558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_233</th>\n",
       "      <td>0.002554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_168</th>\n",
       "      <td>0.002539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_161</th>\n",
       "      <td>0.002534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_88</th>\n",
       "      <td>0.002523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_23</th>\n",
       "      <td>0.002520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_209</th>\n",
       "      <td>0.002519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_147</th>\n",
       "      <td>0.002508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_138</th>\n",
       "      <td>0.002498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_108</th>\n",
       "      <td>0.002481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_131</th>\n",
       "      <td>0.002413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_30</th>\n",
       "      <td>0.002400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_196</th>\n",
       "      <td>0.002397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_268</th>\n",
       "      <td>0.002375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_275</th>\n",
       "      <td>0.002366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_229</th>\n",
       "      <td>0.002349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_99</th>\n",
       "      <td>0.002317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_294</th>\n",
       "      <td>0.002316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_85</th>\n",
       "      <td>0.002300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_141</th>\n",
       "      <td>0.002293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_38</th>\n",
       "      <td>0.002290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_36</th>\n",
       "      <td>0.002275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_163</th>\n",
       "      <td>0.002264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_216</th>\n",
       "      <td>0.002257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_197</th>\n",
       "      <td>0.002245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_288</th>\n",
       "      <td>0.002189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_242</th>\n",
       "      <td>0.002183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_56</th>\n",
       "      <td>0.002160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_134</th>\n",
       "      <td>0.002149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_208</th>\n",
       "      <td>0.002139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_230</th>\n",
       "      <td>0.002138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_84</th>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_15</th>\n",
       "      <td>0.002113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_67</th>\n",
       "      <td>0.002113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_80</th>\n",
       "      <td>0.002105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_94</th>\n",
       "      <td>0.002075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_226</th>\n",
       "      <td>0.002074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_86</th>\n",
       "      <td>0.002063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_92</th>\n",
       "      <td>0.002062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_68</th>\n",
       "      <td>0.002044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_106</th>\n",
       "      <td>0.002039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_269</th>\n",
       "      <td>0.002038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_250</th>\n",
       "      <td>0.002035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_146</th>\n",
       "      <td>0.002011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_54</th>\n",
       "      <td>0.002011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_185</th>\n",
       "      <td>0.002008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_180</th>\n",
       "      <td>0.002007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_2</th>\n",
       "      <td>0.001993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_274</th>\n",
       "      <td>0.001976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_234</th>\n",
       "      <td>0.001976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_18</th>\n",
       "      <td>0.001939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_63</th>\n",
       "      <td>0.001918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_22</th>\n",
       "      <td>0.001917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_281</th>\n",
       "      <td>0.001914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_53</th>\n",
       "      <td>0.001909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_123</th>\n",
       "      <td>0.001908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_280</th>\n",
       "      <td>0.001895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_217</th>\n",
       "      <td>0.001894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_76</th>\n",
       "      <td>0.001887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_1</th>\n",
       "      <td>0.001877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_102</th>\n",
       "      <td>0.001874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_140</th>\n",
       "      <td>0.001867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_205</th>\n",
       "      <td>0.001865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_291</th>\n",
       "      <td>0.001862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_29</th>\n",
       "      <td>0.001858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_50</th>\n",
       "      <td>0.001856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_87</th>\n",
       "      <td>0.001833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_183</th>\n",
       "      <td>0.001821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_31</th>\n",
       "      <td>0.001819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_247</th>\n",
       "      <td>0.001809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_253</th>\n",
       "      <td>0.001804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_111</th>\n",
       "      <td>0.001800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_107</th>\n",
       "      <td>0.001794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_167</th>\n",
       "      <td>0.001791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_192</th>\n",
       "      <td>0.001789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_41</th>\n",
       "      <td>0.001772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_121</th>\n",
       "      <td>0.001760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_115</th>\n",
       "      <td>0.001756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_103</th>\n",
       "      <td>0.001756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_251</th>\n",
       "      <td>0.001739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_188</th>\n",
       "      <td>0.001736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_145</th>\n",
       "      <td>0.001732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_178</th>\n",
       "      <td>0.001732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_100</th>\n",
       "      <td>0.001729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_83</th>\n",
       "      <td>0.001725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_262</th>\n",
       "      <td>0.001724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_165</th>\n",
       "      <td>0.001723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_201</th>\n",
       "      <td>0.001717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_237</th>\n",
       "      <td>0.001712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_42</th>\n",
       "      <td>0.001711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_5</th>\n",
       "      <td>0.001710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_43</th>\n",
       "      <td>0.001702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_136</th>\n",
       "      <td>0.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_249</th>\n",
       "      <td>0.001697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_290</th>\n",
       "      <td>0.001695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_159</th>\n",
       "      <td>0.001691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_170</th>\n",
       "      <td>0.001691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_244</th>\n",
       "      <td>0.001681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_219</th>\n",
       "      <td>0.001673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_133</th>\n",
       "      <td>0.001664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_120</th>\n",
       "      <td>0.001664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_179</th>\n",
       "      <td>0.001660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_61</th>\n",
       "      <td>0.001659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_199</th>\n",
       "      <td>0.001654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_60</th>\n",
       "      <td>0.001646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_295</th>\n",
       "      <td>0.001645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_128</th>\n",
       "      <td>0.001642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_90</th>\n",
       "      <td>0.001639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_257</th>\n",
       "      <td>0.001636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_289</th>\n",
       "      <td>0.001630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_95</th>\n",
       "      <td>0.001630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_35</th>\n",
       "      <td>0.001628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_79</th>\n",
       "      <td>0.001628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_81</th>\n",
       "      <td>0.001625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_137</th>\n",
       "      <td>0.001619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_144</th>\n",
       "      <td>0.001614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_150</th>\n",
       "      <td>0.001611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_89</th>\n",
       "      <td>0.001607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_270</th>\n",
       "      <td>0.001606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_220</th>\n",
       "      <td>0.001598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_19</th>\n",
       "      <td>0.001598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_194</th>\n",
       "      <td>0.001592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_296</th>\n",
       "      <td>0.001590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_155</th>\n",
       "      <td>0.001588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_105</th>\n",
       "      <td>0.001587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_17</th>\n",
       "      <td>0.001583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_228</th>\n",
       "      <td>0.001581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_151</th>\n",
       "      <td>0.001569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_21</th>\n",
       "      <td>0.001565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_271</th>\n",
       "      <td>0.001558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_218</th>\n",
       "      <td>0.001553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_239</th>\n",
       "      <td>0.001550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_255</th>\n",
       "      <td>0.001546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_13</th>\n",
       "      <td>0.001537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_238</th>\n",
       "      <td>0.001533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_298</th>\n",
       "      <td>0.001531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_78</th>\n",
       "      <td>0.001531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_300</th>\n",
       "      <td>0.001530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_224</th>\n",
       "      <td>0.001530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_240</th>\n",
       "      <td>0.001529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_71</th>\n",
       "      <td>0.001527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_279</th>\n",
       "      <td>0.001526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_70</th>\n",
       "      <td>0.001524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_32</th>\n",
       "      <td>0.001521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_212</th>\n",
       "      <td>0.001520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_45</th>\n",
       "      <td>0.001510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_172</th>\n",
       "      <td>0.001502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_171</th>\n",
       "      <td>0.001499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_160</th>\n",
       "      <td>0.001497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_27</th>\n",
       "      <td>0.001496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_55</th>\n",
       "      <td>0.001492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_153</th>\n",
       "      <td>0.001491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_264</th>\n",
       "      <td>0.001487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_93</th>\n",
       "      <td>0.001485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_62</th>\n",
       "      <td>0.001480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_293</th>\n",
       "      <td>0.001475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_277</th>\n",
       "      <td>0.001474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_96</th>\n",
       "      <td>0.001468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_9</th>\n",
       "      <td>0.001467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_124</th>\n",
       "      <td>0.001461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_184</th>\n",
       "      <td>0.001456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_158</th>\n",
       "      <td>0.001451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_260</th>\n",
       "      <td>0.001451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_118</th>\n",
       "      <td>0.001448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_127</th>\n",
       "      <td>0.001438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_52</th>\n",
       "      <td>0.001437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_204</th>\n",
       "      <td>0.001434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_113</th>\n",
       "      <td>0.001432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_130</th>\n",
       "      <td>0.001424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_98</th>\n",
       "      <td>0.001420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_286</th>\n",
       "      <td>0.001419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_156</th>\n",
       "      <td>0.001419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_16</th>\n",
       "      <td>0.001417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_182</th>\n",
       "      <td>0.001410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_73</th>\n",
       "      <td>0.001409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_132</th>\n",
       "      <td>0.001408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_8</th>\n",
       "      <td>0.001407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_112</th>\n",
       "      <td>0.001406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_28</th>\n",
       "      <td>0.001404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_59</th>\n",
       "      <td>0.001402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_109</th>\n",
       "      <td>0.001401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_174</th>\n",
       "      <td>0.001398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_241</th>\n",
       "      <td>0.001398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_193</th>\n",
       "      <td>0.001397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_273</th>\n",
       "      <td>0.001394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_282</th>\n",
       "      <td>0.001393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_10</th>\n",
       "      <td>0.001389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_6</th>\n",
       "      <td>0.001386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_49</th>\n",
       "      <td>0.001384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_246</th>\n",
       "      <td>0.001383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_116</th>\n",
       "      <td>0.001380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_223</th>\n",
       "      <td>0.001374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_266</th>\n",
       "      <td>0.001371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_91</th>\n",
       "      <td>0.001371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_252</th>\n",
       "      <td>0.001371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_166</th>\n",
       "      <td>0.001370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_245</th>\n",
       "      <td>0.001370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_46</th>\n",
       "      <td>0.001364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_243</th>\n",
       "      <td>0.001363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_154</th>\n",
       "      <td>0.001361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_175</th>\n",
       "      <td>0.001355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_139</th>\n",
       "      <td>0.001355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_143</th>\n",
       "      <td>0.001354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_267</th>\n",
       "      <td>0.001351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_213</th>\n",
       "      <td>0.001351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_235</th>\n",
       "      <td>0.001350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_126</th>\n",
       "      <td>0.001349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_157</th>\n",
       "      <td>0.001340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_114</th>\n",
       "      <td>0.001339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_14</th>\n",
       "      <td>0.001331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_206</th>\n",
       "      <td>0.001330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_173</th>\n",
       "      <td>0.001325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_297</th>\n",
       "      <td>0.001321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_37</th>\n",
       "      <td>0.001317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_3</th>\n",
       "      <td>0.001314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_117</th>\n",
       "      <td>0.001314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_164</th>\n",
       "      <td>0.001310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_75</th>\n",
       "      <td>0.001305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_189</th>\n",
       "      <td>0.001302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_278</th>\n",
       "      <td>0.001302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_48</th>\n",
       "      <td>0.001289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_7</th>\n",
       "      <td>0.001278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_299</th>\n",
       "      <td>0.001272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_101</th>\n",
       "      <td>0.001270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_284</th>\n",
       "      <td>0.001264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_248</th>\n",
       "      <td>0.001257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_210</th>\n",
       "      <td>0.001255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_190</th>\n",
       "      <td>0.001254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_202</th>\n",
       "      <td>0.001249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_58</th>\n",
       "      <td>0.001249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_47</th>\n",
       "      <td>0.001244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_74</th>\n",
       "      <td>0.001241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_97</th>\n",
       "      <td>0.001227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_198</th>\n",
       "      <td>0.001222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_162</th>\n",
       "      <td>0.001209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_225</th>\n",
       "      <td>0.001189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_215</th>\n",
       "      <td>0.001185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_231</th>\n",
       "      <td>0.001182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_292</th>\n",
       "      <td>0.001181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_149</th>\n",
       "      <td>0.001169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_148</th>\n",
       "      <td>0.001160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_211</th>\n",
       "      <td>0.001135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_256</th>\n",
       "      <td>0.001133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_142</th>\n",
       "      <td>0.001128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_64</th>\n",
       "      <td>0.001127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_236</th>\n",
       "      <td>0.001105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_221</th>\n",
       "      <td>0.001097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_186</th>\n",
       "      <td>0.001083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_181</th>\n",
       "      <td>0.001074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>published_on_day</th>\n",
       "      <td>0.000913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>av_claims_unknown</th>\n",
       "      <td>0.000564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video_count</th>\n",
       "      <td>0.000215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>av_claims_false</th>\n",
       "      <td>0.000202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>av_claims_true</th>\n",
       "      <td>0.000173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>av_claims_mixture</th>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>av_claims_mostly_true</th>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>av_claims_mostly_false</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        importance\n",
       "fb_ad_0_share_count       0.037344\n",
       "fb_ad_0_reaction_count    0.032782\n",
       "title_char_length         0.030757\n",
       "fb_ad_0_comment_count     0.026981\n",
       "content_word_count        0.025531\n",
       "fb_popularity_ad_0        0.024881\n",
       "title_word_count          0.021971\n",
       "media_count_total         0.021888\n",
       "image_count               0.021173\n",
       "fb_ad_1_reaction_count    0.020109\n",
       "content_char_length       0.019831\n",
       "fb_ad_1_share_count       0.019254\n",
       "fb_ad_1_comment_count     0.016520\n",
       "is_collective_author      0.014032\n",
       "d2v_187                   0.013095\n",
       "d2v_65                    0.012808\n",
       "fb_ad_3_share_count       0.011319\n",
       "fb_ad_3_reaction_count    0.009092\n",
       "fb_ad_3_comment_count     0.007162\n",
       "d2v_272                   0.006980\n",
       "d2v_57                    0.006657\n",
       "d2v_232                   0.006600\n",
       "d2v_119                   0.006544\n",
       "d2v_287                   0.006314\n",
       "d2v_285                   0.005826\n",
       "d2v_4                     0.005797\n",
       "d2v_72                    0.005489\n",
       "d2v_135                   0.005329\n",
       "d2v_44                    0.005037\n",
       "d2v_169                   0.004770\n",
       "d2v_33                    0.004689\n",
       "d2v_12                    0.004671\n",
       "d2v_20                    0.004647\n",
       "d2v_191                   0.004597\n",
       "d2v_276                   0.004386\n",
       "d2v_66                    0.004103\n",
       "d2v_77                    0.003998\n",
       "d2v_200                   0.003792\n",
       "d2v_122                   0.003702\n",
       "fb_popularity_ad_1        0.003615\n",
       "fb_popularity_ad_3        0.003585\n",
       "d2v_104                   0.003569\n",
       "d2v_39                    0.003528\n",
       "d2v_125                   0.003473\n",
       "d2v_40                    0.003463\n",
       "d2v_176                   0.003434\n",
       "d2v_259                   0.003307\n",
       "d2v_177                   0.003279\n",
       "d2v_110                   0.003170\n",
       "d2v_26                    0.003168\n",
       "d2v_214                   0.003146\n",
       "d2v_261                   0.003088\n",
       "d2v_283                   0.003056\n",
       "d2v_69                    0.003025\n",
       "d2v_222                   0.002953\n",
       "d2v_129                   0.002939\n",
       "d2v_265                   0.002912\n",
       "d2v_263                   0.002907\n",
       "d2v_24                    0.002895\n",
       "d2v_152                   0.002888\n",
       "d2v_51                    0.002874\n",
       "d2v_82                    0.002862\n",
       "d2v_258                   0.002848\n",
       "d2v_195                   0.002826\n",
       "d2v_34                    0.002759\n",
       "d2v_227                   0.002698\n",
       "d2v_254                   0.002694\n",
       "d2v_11                    0.002687\n",
       "d2v_203                   0.002657\n",
       "d2v_207                   0.002654\n",
       "d2v_25                    0.002558\n",
       "d2v_233                   0.002554\n",
       "d2v_168                   0.002539\n",
       "d2v_161                   0.002534\n",
       "d2v_88                    0.002523\n",
       "d2v_23                    0.002520\n",
       "d2v_209                   0.002519\n",
       "d2v_147                   0.002508\n",
       "d2v_138                   0.002498\n",
       "d2v_108                   0.002481\n",
       "d2v_131                   0.002413\n",
       "d2v_30                    0.002400\n",
       "d2v_196                   0.002397\n",
       "d2v_268                   0.002375\n",
       "d2v_275                   0.002366\n",
       "d2v_229                   0.002349\n",
       "d2v_99                    0.002317\n",
       "d2v_294                   0.002316\n",
       "d2v_85                    0.002300\n",
       "d2v_141                   0.002293\n",
       "d2v_38                    0.002290\n",
       "d2v_36                    0.002275\n",
       "d2v_163                   0.002264\n",
       "d2v_216                   0.002257\n",
       "d2v_197                   0.002245\n",
       "d2v_288                   0.002189\n",
       "d2v_242                   0.002183\n",
       "d2v_56                    0.002160\n",
       "d2v_134                   0.002149\n",
       "d2v_208                   0.002139\n",
       "d2v_230                   0.002138\n",
       "d2v_84                    0.002114\n",
       "d2v_15                    0.002113\n",
       "d2v_67                    0.002113\n",
       "d2v_80                    0.002105\n",
       "d2v_94                    0.002075\n",
       "d2v_226                   0.002074\n",
       "d2v_86                    0.002063\n",
       "d2v_92                    0.002062\n",
       "d2v_68                    0.002044\n",
       "d2v_106                   0.002039\n",
       "d2v_269                   0.002038\n",
       "d2v_250                   0.002035\n",
       "d2v_146                   0.002011\n",
       "d2v_54                    0.002011\n",
       "d2v_185                   0.002008\n",
       "d2v_180                   0.002007\n",
       "d2v_2                     0.001993\n",
       "d2v_274                   0.001976\n",
       "d2v_234                   0.001976\n",
       "d2v_18                    0.001939\n",
       "d2v_63                    0.001918\n",
       "d2v_22                    0.001917\n",
       "d2v_281                   0.001914\n",
       "d2v_53                    0.001909\n",
       "d2v_123                   0.001908\n",
       "d2v_280                   0.001895\n",
       "d2v_217                   0.001894\n",
       "d2v_76                    0.001887\n",
       "d2v_1                     0.001877\n",
       "d2v_102                   0.001874\n",
       "d2v_140                   0.001867\n",
       "d2v_205                   0.001865\n",
       "d2v_291                   0.001862\n",
       "d2v_29                    0.001858\n",
       "d2v_50                    0.001856\n",
       "d2v_87                    0.001833\n",
       "d2v_183                   0.001821\n",
       "d2v_31                    0.001819\n",
       "d2v_247                   0.001809\n",
       "d2v_253                   0.001804\n",
       "d2v_111                   0.001800\n",
       "d2v_107                   0.001794\n",
       "d2v_167                   0.001791\n",
       "d2v_192                   0.001789\n",
       "d2v_41                    0.001772\n",
       "d2v_121                   0.001760\n",
       "d2v_115                   0.001756\n",
       "d2v_103                   0.001756\n",
       "d2v_251                   0.001739\n",
       "d2v_188                   0.001736\n",
       "d2v_145                   0.001732\n",
       "d2v_178                   0.001732\n",
       "d2v_100                   0.001729\n",
       "d2v_83                    0.001725\n",
       "d2v_262                   0.001724\n",
       "d2v_165                   0.001723\n",
       "d2v_201                   0.001717\n",
       "d2v_237                   0.001712\n",
       "d2v_42                    0.001711\n",
       "d2v_5                     0.001710\n",
       "d2v_43                    0.001702\n",
       "d2v_136                   0.001700\n",
       "d2v_249                   0.001697\n",
       "d2v_290                   0.001695\n",
       "d2v_159                   0.001691\n",
       "d2v_170                   0.001691\n",
       "d2v_244                   0.001681\n",
       "d2v_219                   0.001673\n",
       "d2v_133                   0.001664\n",
       "d2v_120                   0.001664\n",
       "d2v_179                   0.001660\n",
       "d2v_61                    0.001659\n",
       "d2v_199                   0.001654\n",
       "d2v_60                    0.001646\n",
       "d2v_295                   0.001645\n",
       "d2v_128                   0.001642\n",
       "d2v_90                    0.001639\n",
       "d2v_257                   0.001636\n",
       "d2v_289                   0.001630\n",
       "d2v_95                    0.001630\n",
       "d2v_35                    0.001628\n",
       "d2v_79                    0.001628\n",
       "d2v_81                    0.001625\n",
       "d2v_137                   0.001619\n",
       "d2v_144                   0.001614\n",
       "d2v_150                   0.001611\n",
       "d2v_89                    0.001607\n",
       "d2v_270                   0.001606\n",
       "d2v_220                   0.001598\n",
       "d2v_19                    0.001598\n",
       "d2v_194                   0.001592\n",
       "d2v_296                   0.001590\n",
       "d2v_155                   0.001588\n",
       "d2v_105                   0.001587\n",
       "d2v_17                    0.001583\n",
       "d2v_228                   0.001581\n",
       "d2v_151                   0.001569\n",
       "d2v_21                    0.001565\n",
       "d2v_271                   0.001558\n",
       "d2v_218                   0.001553\n",
       "d2v_239                   0.001550\n",
       "d2v_255                   0.001546\n",
       "d2v_13                    0.001537\n",
       "d2v_238                   0.001533\n",
       "d2v_298                   0.001531\n",
       "d2v_78                    0.001531\n",
       "d2v_300                   0.001530\n",
       "d2v_224                   0.001530\n",
       "d2v_240                   0.001529\n",
       "d2v_71                    0.001527\n",
       "d2v_279                   0.001526\n",
       "d2v_70                    0.001524\n",
       "d2v_32                    0.001521\n",
       "d2v_212                   0.001520\n",
       "d2v_45                    0.001510\n",
       "d2v_172                   0.001502\n",
       "d2v_171                   0.001499\n",
       "d2v_160                   0.001497\n",
       "d2v_27                    0.001496\n",
       "d2v_55                    0.001492\n",
       "d2v_153                   0.001491\n",
       "d2v_264                   0.001487\n",
       "d2v_93                    0.001485\n",
       "d2v_62                    0.001480\n",
       "d2v_293                   0.001475\n",
       "d2v_277                   0.001474\n",
       "d2v_96                    0.001468\n",
       "d2v_9                     0.001467\n",
       "d2v_124                   0.001461\n",
       "d2v_184                   0.001456\n",
       "d2v_158                   0.001451\n",
       "d2v_260                   0.001451\n",
       "d2v_118                   0.001448\n",
       "d2v_127                   0.001438\n",
       "d2v_52                    0.001437\n",
       "d2v_204                   0.001434\n",
       "d2v_113                   0.001432\n",
       "d2v_130                   0.001424\n",
       "d2v_98                    0.001420\n",
       "d2v_286                   0.001419\n",
       "d2v_156                   0.001419\n",
       "d2v_16                    0.001417\n",
       "d2v_182                   0.001410\n",
       "d2v_73                    0.001409\n",
       "d2v_132                   0.001408\n",
       "d2v_8                     0.001407\n",
       "d2v_112                   0.001406\n",
       "d2v_28                    0.001404\n",
       "d2v_59                    0.001402\n",
       "d2v_109                   0.001401\n",
       "d2v_174                   0.001398\n",
       "d2v_241                   0.001398\n",
       "d2v_193                   0.001397\n",
       "d2v_273                   0.001394\n",
       "d2v_282                   0.001393\n",
       "d2v_10                    0.001389\n",
       "d2v_6                     0.001386\n",
       "d2v_49                    0.001384\n",
       "d2v_246                   0.001383\n",
       "d2v_116                   0.001380\n",
       "d2v_223                   0.001374\n",
       "d2v_266                   0.001371\n",
       "d2v_91                    0.001371\n",
       "d2v_252                   0.001371\n",
       "d2v_166                   0.001370\n",
       "d2v_245                   0.001370\n",
       "d2v_46                    0.001364\n",
       "d2v_243                   0.001363\n",
       "d2v_154                   0.001361\n",
       "d2v_175                   0.001355\n",
       "d2v_139                   0.001355\n",
       "d2v_143                   0.001354\n",
       "d2v_267                   0.001351\n",
       "d2v_213                   0.001351\n",
       "d2v_235                   0.001350\n",
       "d2v_126                   0.001349\n",
       "d2v_157                   0.001340\n",
       "d2v_114                   0.001339\n",
       "d2v_14                    0.001331\n",
       "d2v_206                   0.001330\n",
       "d2v_173                   0.001325\n",
       "d2v_297                   0.001321\n",
       "d2v_37                    0.001317\n",
       "d2v_3                     0.001314\n",
       "d2v_117                   0.001314\n",
       "d2v_164                   0.001310\n",
       "d2v_75                    0.001305\n",
       "d2v_189                   0.001302\n",
       "d2v_278                   0.001302\n",
       "d2v_48                    0.001289\n",
       "d2v_7                     0.001278\n",
       "d2v_299                   0.001272\n",
       "d2v_101                   0.001270\n",
       "d2v_284                   0.001264\n",
       "d2v_248                   0.001257\n",
       "d2v_210                   0.001255\n",
       "d2v_190                   0.001254\n",
       "d2v_202                   0.001249\n",
       "d2v_58                    0.001249\n",
       "d2v_47                    0.001244\n",
       "d2v_74                    0.001241\n",
       "d2v_97                    0.001227\n",
       "d2v_198                   0.001222\n",
       "d2v_162                   0.001209\n",
       "d2v_225                   0.001189\n",
       "d2v_215                   0.001185\n",
       "d2v_231                   0.001182\n",
       "d2v_292                   0.001181\n",
       "d2v_149                   0.001169\n",
       "d2v_148                   0.001160\n",
       "d2v_211                   0.001135\n",
       "d2v_256                   0.001133\n",
       "d2v_142                   0.001128\n",
       "d2v_64                    0.001127\n",
       "d2v_236                   0.001105\n",
       "d2v_221                   0.001097\n",
       "d2v_186                   0.001083\n",
       "d2v_181                   0.001074\n",
       "published_on_day          0.000913\n",
       "av_claims_unknown         0.000564\n",
       "video_count               0.000215\n",
       "av_claims_false           0.000202\n",
       "av_claims_true            0.000173\n",
       "av_claims_mixture         0.000010\n",
       "av_claims_mostly_true     0.000006\n",
       "av_claims_mostly_false    0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_all(pd.DataFrame((i for i in classifiers[0].feature_importances_), index=data.train.features.columns, columns=['importance']).sort_values(by=['importance'], ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train.y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
