{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlalchemy\n",
    "import gensim\n",
    "import logging\n",
    "\n",
    "import common\n",
    "import util\n",
    "importlib.reload(common)\n",
    "importlib.reload(util)\n",
    "\n",
    "from common import create_engine\n",
    "from common import display_all\n",
    "from common import figsize\n",
    "from common import save_df, load_df\n",
    "from common import save_session, load_session\n",
    "\n",
    "from util import show_importances\n",
    "from util import split_X_y_all, split_X_y, split_data\n",
    "from util import empty_features, column_feature, str_contains\n",
    "\n",
    "from pbar import Pbar\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "\n",
    "register_matplotlib_converters() # converters e.g. for datetime in plots\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 123\n",
    "np_random = np.random.RandomState(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_df('final_data.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>perex</th>\n",
       "      <th>body</th>\n",
       "      <th>published_at</th>\n",
       "      <th>extracted_at</th>\n",
       "      <th>source_id</th>\n",
       "      <th>category</th>\n",
       "      <th>other_info</th>\n",
       "      <th>image_count</th>\n",
       "      <th>video_count</th>\n",
       "      <th>...</th>\n",
       "      <th>fb_popularity_ad_6</th>\n",
       "      <th>fb_popularity_ad_7</th>\n",
       "      <th>fb_popularity_ad_8</th>\n",
       "      <th>fb_popularity_ad_9</th>\n",
       "      <th>fb_popularity_ad_10</th>\n",
       "      <th>fb_popularity_ad_11</th>\n",
       "      <th>fb_popularity_ad_12</th>\n",
       "      <th>fb_popularity_ad_13</th>\n",
       "      <th>fb_popularity_ad_14</th>\n",
       "      <th>fb_popularity_ad_15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>428781</td>\n",
       "      <td>Want to Support Immunity? Look to Your Gut</td>\n",
       "      <td>&lt;p&gt;For thousands of years we’ve relied on our ...</td>\n",
       "      <td>For thousands of years we’ve relied on our mic...</td>\n",
       "      <td>2019-10-10 00:04:42</td>\n",
       "      <td>2019-10-10 07:13:11.637640</td>\n",
       "      <td>146</td>\n",
       "      <td>[gut health]</td>\n",
       "      <td>{'tags': ['gut health', 'immune system', 'immu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>428783</td>\n",
       "      <td>NY Judge Denies Stay: Children Locked Out of S...</td>\n",
       "      <td></td>\n",
       "      <td>\\n  \\n</td>\n",
       "      <td>2019-10-10 01:01:32</td>\n",
       "      <td>2019-10-10 07:13:17.715180</td>\n",
       "      <td>148</td>\n",
       "      <td>None</td>\n",
       "      <td>{'tags': None, 'updated_at': '2019-10-09 23:01...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>428831</td>\n",
       "      <td>Cucumber + Turmeric = Gorgeous Skin and Your F...</td>\n",
       "      <td>&lt;p&gt;Face masks – the best means of expressing c...</td>\n",
       "      <td>Face masks – the best means of expressing care...</td>\n",
       "      <td>2019-10-10 02:21:28</td>\n",
       "      <td>2019-10-10 09:24:06.693998</td>\n",
       "      <td>227</td>\n",
       "      <td>[Beauty]</td>\n",
       "      <td>{'tags': [], 'updated_at': '2019-10-10T02:30:54'}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>428832</td>\n",
       "      <td>‘Sesame Street’ launches initiative to help ex...</td>\n",
       "      <td>In a new initiative, “Sesame Street” is addres...</td>\n",
       "      <td>“Sesame Street” is introducing a new storyline...</td>\n",
       "      <td>2019-10-10 10:40:22</td>\n",
       "      <td>2019-10-10 12:02:48.264837</td>\n",
       "      <td>165</td>\n",
       "      <td>[Health]</td>\n",
       "      <td>{'tags': ['pediatrics', 'addiction'], 'keyword...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>428833</td>\n",
       "      <td>Silicosis outbreak highlights the 'malignant n...</td>\n",
       "      <td>Fourteen U.S. workers are killed on the job ev...</td>\n",
       "      <td>Cutting or polishing the quartz-based composit...</td>\n",
       "      <td>2019-10-10 10:35:03</td>\n",
       "      <td>2019-10-10 12:02:48.419273</td>\n",
       "      <td>165</td>\n",
       "      <td>[First Opinion]</td>\n",
       "      <td>{'tags': ['public health', 'government agencie...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  \\\n",
       "id                                                          \n",
       "428781         Want to Support Immunity? Look to Your Gut   \n",
       "428783  NY Judge Denies Stay: Children Locked Out of S...   \n",
       "428831  Cucumber + Turmeric = Gorgeous Skin and Your F...   \n",
       "428832  ‘Sesame Street’ launches initiative to help ex...   \n",
       "428833  Silicosis outbreak highlights the 'malignant n...   \n",
       "\n",
       "                                                    perex  \\\n",
       "id                                                          \n",
       "428781  <p>For thousands of years we’ve relied on our ...   \n",
       "428783                                                      \n",
       "428831  <p>Face masks – the best means of expressing c...   \n",
       "428832  In a new initiative, “Sesame Street” is addres...   \n",
       "428833  Fourteen U.S. workers are killed on the job ev...   \n",
       "\n",
       "                                                     body        published_at  \\\n",
       "id                                                                              \n",
       "428781  For thousands of years we’ve relied on our mic... 2019-10-10 00:04:42   \n",
       "428783                                             \\n  \\n 2019-10-10 01:01:32   \n",
       "428831  Face masks – the best means of expressing care... 2019-10-10 02:21:28   \n",
       "428832  “Sesame Street” is introducing a new storyline... 2019-10-10 10:40:22   \n",
       "428833  Cutting or polishing the quartz-based composit... 2019-10-10 10:35:03   \n",
       "\n",
       "                     extracted_at  source_id         category  \\\n",
       "id                                                              \n",
       "428781 2019-10-10 07:13:11.637640        146     [gut health]   \n",
       "428783 2019-10-10 07:13:17.715180        148             None   \n",
       "428831 2019-10-10 09:24:06.693998        227         [Beauty]   \n",
       "428832 2019-10-10 12:02:48.264837        165         [Health]   \n",
       "428833 2019-10-10 12:02:48.419273        165  [First Opinion]   \n",
       "\n",
       "                                               other_info  image_count  \\\n",
       "id                                                                       \n",
       "428781  {'tags': ['gut health', 'immune system', 'immu...            0   \n",
       "428783  {'tags': None, 'updated_at': '2019-10-09 23:01...            0   \n",
       "428831  {'tags': [], 'updated_at': '2019-10-10T02:30:54'}            1   \n",
       "428832  {'tags': ['pediatrics', 'addiction'], 'keyword...            1   \n",
       "428833  {'tags': ['public health', 'government agencie...            1   \n",
       "\n",
       "        video_count  ... fb_popularity_ad_6  fb_popularity_ad_7  \\\n",
       "id                   ...                                          \n",
       "428781            0  ...                0.0                 0.0   \n",
       "428783            0  ...                0.0                 0.0   \n",
       "428831            0  ...                0.0                 0.0   \n",
       "428832            0  ...                0.0                 0.0   \n",
       "428833            0  ...                0.0                 0.0   \n",
       "\n",
       "       fb_popularity_ad_8 fb_popularity_ad_9 fb_popularity_ad_10  \\\n",
       "id                                                                 \n",
       "428781                0.0                0.0                 0.0   \n",
       "428783                0.0                0.0                 0.0   \n",
       "428831                0.0                0.0                 0.0   \n",
       "428832                0.0                0.0                 0.0   \n",
       "428833                0.0                0.0                 0.0   \n",
       "\n",
       "        fb_popularity_ad_11  fb_popularity_ad_12  fb_popularity_ad_13  \\\n",
       "id                                                                      \n",
       "428781                  0.0                  0.0                  0.0   \n",
       "428783                  0.0                  0.0                  0.0   \n",
       "428831                  0.0                  0.0                  0.0   \n",
       "428832                  0.0                  0.0                  0.0   \n",
       "428833                  0.0                  0.0                  0.0   \n",
       "\n",
       "        fb_popularity_ad_14  fb_popularity_ad_15  \n",
       "id                                                \n",
       "428781                  0.0                  0.0  \n",
       "428783                  0.0                  0.0  \n",
       "428831                  0.0                  0.0  \n",
       "428832                  0.0                  0.0  \n",
       "428833                  0.0                  0.0  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18556 entries, 428781 to 808421\n",
      "Data columns (total 80 columns):\n",
      "title                      18556 non-null object\n",
      "perex                      14772 non-null object\n",
      "body                       18523 non-null object\n",
      "published_at               18556 non-null datetime64[ns]\n",
      "extracted_at               18556 non-null datetime64[ns]\n",
      "source_id                  18556 non-null int64\n",
      "category                   12426 non-null object\n",
      "other_info                 18552 non-null object\n",
      "image_count                18556 non-null int64\n",
      "video_count                18556 non-null int64\n",
      "author_name                18556 non-null object\n",
      "source_id                  18556 non-null int64\n",
      "source_name                18556 non-null object\n",
      "source_url                 18556 non-null object\n",
      "source_type                18556 non-null object\n",
      "source_is_reliable         18556 non-null int64\n",
      "fb_ad_0_comment_count      8282 non-null float64\n",
      "fb_ad_1_comment_count      12906 non-null float64\n",
      "fb_ad_2_comment_count      13951 non-null float64\n",
      "fb_ad_3_comment_count      14603 non-null float64\n",
      "fb_ad_4_comment_count      14921 non-null float64\n",
      "fb_ad_5_comment_count      14860 non-null float64\n",
      "fb_ad_6_comment_count      14888 non-null float64\n",
      "fb_ad_7_comment_count      14861 non-null float64\n",
      "fb_ad_8_comment_count      14810 non-null float64\n",
      "fb_ad_9_comment_count      14955 non-null float64\n",
      "fb_ad_10_comment_count     15143 non-null float64\n",
      "fb_ad_11_comment_count     15190 non-null float64\n",
      "fb_ad_12_comment_count     15018 non-null float64\n",
      "fb_ad_13_comment_count     14843 non-null float64\n",
      "fb_ad_14_comment_count     14696 non-null float64\n",
      "fb_ad_15_comment_count     14608 non-null float64\n",
      "fb_ad_0_reaction_count     8282 non-null float64\n",
      "fb_ad_1_reaction_count     12906 non-null float64\n",
      "fb_ad_2_reaction_count     13951 non-null float64\n",
      "fb_ad_3_reaction_count     14603 non-null float64\n",
      "fb_ad_4_reaction_count     14921 non-null float64\n",
      "fb_ad_5_reaction_count     14860 non-null float64\n",
      "fb_ad_6_reaction_count     14888 non-null float64\n",
      "fb_ad_7_reaction_count     14861 non-null float64\n",
      "fb_ad_8_reaction_count     14810 non-null float64\n",
      "fb_ad_9_reaction_count     14955 non-null float64\n",
      "fb_ad_10_reaction_count    15143 non-null float64\n",
      "fb_ad_11_reaction_count    15190 non-null float64\n",
      "fb_ad_12_reaction_count    15018 non-null float64\n",
      "fb_ad_13_reaction_count    14843 non-null float64\n",
      "fb_ad_14_reaction_count    14696 non-null float64\n",
      "fb_ad_15_reaction_count    14608 non-null float64\n",
      "fb_ad_0_share_count        8282 non-null float64\n",
      "fb_ad_1_share_count        12906 non-null float64\n",
      "fb_ad_2_share_count        13951 non-null float64\n",
      "fb_ad_3_share_count        14603 non-null float64\n",
      "fb_ad_4_share_count        14921 non-null float64\n",
      "fb_ad_5_share_count        14860 non-null float64\n",
      "fb_ad_6_share_count        14888 non-null float64\n",
      "fb_ad_7_share_count        14861 non-null float64\n",
      "fb_ad_8_share_count        14810 non-null float64\n",
      "fb_ad_9_share_count        14955 non-null float64\n",
      "fb_ad_10_share_count       15143 non-null float64\n",
      "fb_ad_11_share_count       15190 non-null float64\n",
      "fb_ad_12_share_count       15018 non-null float64\n",
      "fb_ad_13_share_count       14843 non-null float64\n",
      "fb_ad_14_share_count       14696 non-null float64\n",
      "fb_ad_15_share_count       14608 non-null float64\n",
      "fb_popularity_ad_0         18556 non-null float64\n",
      "fb_popularity_ad_1         18556 non-null float64\n",
      "fb_popularity_ad_2         18556 non-null float64\n",
      "fb_popularity_ad_3         18556 non-null float64\n",
      "fb_popularity_ad_4         18556 non-null float64\n",
      "fb_popularity_ad_5         18556 non-null float64\n",
      "fb_popularity_ad_6         18556 non-null float64\n",
      "fb_popularity_ad_7         18556 non-null float64\n",
      "fb_popularity_ad_8         18556 non-null float64\n",
      "fb_popularity_ad_9         18556 non-null float64\n",
      "fb_popularity_ad_10        18556 non-null float64\n",
      "fb_popularity_ad_11        18556 non-null float64\n",
      "fb_popularity_ad_12        18556 non-null float64\n",
      "fb_popularity_ad_13        18556 non-null float64\n",
      "fb_popularity_ad_14        18556 non-null float64\n",
      "fb_popularity_ad_15        18556 non-null float64\n",
      "dtypes: datetime64[ns](2), float64(64), int64(5), object(9)\n",
      "memory usage: 11.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rozdelenie hodnot popularity do 5 skupin\n",
    "\n",
    "- `0 - 0.5`\n",
    "- `0.5 - 0.75`\n",
    "- `0.75 - 0.9`\n",
    "- `0.9 - 0.95`\n",
    "- `0.95 - 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_labels(df, quantiles, column='fb_popularity_ad_15'):\n",
    "    df = df.copy()\n",
    "    label_str = f'{column}_label'\n",
    "    \n",
    "    df[label_str] = -1\n",
    "    \n",
    "    label = 1    \n",
    "    for i in range(len(quantiles) - 1):\n",
    "        low = df[column].quantile(quantiles[i])\n",
    "        high = df[column].quantile(quantiles[i + 1])\n",
    "        \n",
    "        df.loc[(low <= df[column]) & (df[column] <= high), label_str] = int(label)\n",
    "        \n",
    "        label += 1\n",
    "    df = df.drop(columns=[column])    \n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00          0.0\n",
      "0.50         26.0\n",
      "0.75        319.0\n",
      "0.90       1755.3\n",
      "0.95       4988.5\n",
      "1.00    1369290.0\n",
      "Name: fb_ad_15_reaction_count, dtype: float64\n",
      "0.00         0.00\n",
      "0.50         4.00\n",
      "0.75        67.00\n",
      "0.90       445.60\n",
      "0.95      1273.65\n",
      "1.00    898615.00\n",
      "Name: fb_ad_15_comment_count, dtype: float64\n",
      "0.00         0.00\n",
      "0.50        29.00\n",
      "0.75       153.00\n",
      "0.90       645.00\n",
      "0.95      1604.55\n",
      "1.00    404542.00\n",
      "Name: fb_ad_15_share_count, dtype: float64\n",
      "0.00          0.0\n",
      "0.50         17.0\n",
      "0.75        321.0\n",
      "0.90       1983.0\n",
      "0.95       5843.0\n",
      "1.00    2566473.0\n",
      "Name: fb_popularity_ad_15, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "quantiles = [\n",
    "    0,\n",
    "    .50,\n",
    "    .75,\n",
    "    .90,\n",
    "    .95,\n",
    "    1\n",
    "]\n",
    "\n",
    "cols = [\n",
    "    'fb_ad_15_reaction_count',\n",
    "    'fb_ad_15_comment_count',\n",
    "    'fb_ad_15_share_count',\n",
    "    'fb_popularity_ad_15'\n",
    "]\n",
    "\n",
    "for i in cols:\n",
    "    print(df[i].quantile(quantiles))\n",
    "    df = add_labels(df, quantiles, column=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pri jednotlivych zlozkach sme pri tomto rozdeleni nasli len 4 skupiny (lebo 1 == 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jednoducha heuristika: ak je zdroj nedoveryhodny tak aj clanok je nedoveryhodny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_fake_news_label'] = df.source_is_reliable.replace({0:1, 1:0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear body, perex, etc from html...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows without body\n",
    "df = df[~df.body.isnull()]\n",
    "df = df[~df.title.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "\n",
    "def clear_text(text):\n",
    "    if text is None:\n",
    "        return ''\n",
    "\n",
    "    text = BeautifulSoup(text, features='html.parser').text\n",
    "    text = text.lower()\n",
    "    text = text.replace('\\r', '')\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = unicodedata.normalize('NFKD', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def clear_column(df, column):\n",
    "    df[column] = df[column].apply(clear_text)\n",
    "\n",
    "def clear_columns(df, columns):\n",
    "    pbar_conf = {\n",
    "        'refresh_rate': 1,\n",
    "        'action_names': columns\n",
    "    }\n",
    "        \n",
    "    for c in Pbar(columns, **pbar_conf):\n",
    "        clear_column(df, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] -- 3 / 3 -- (finished)2 / 33\n"
     ]
    }
   ],
   "source": [
    "clear_columns(df, ['title', 'perex', 'body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = list(filter(lambda x: x.endswith('_label'), df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ln in label_names:\n",
    "    df[ln] = pd.to_numeric(df[ln])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labely\n",
    "labels_df = pd.concat([labels_df] + [df[label_name] for label_name in label_names], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18523 entries, 428781 to 808421\n",
      "Data columns (total 81 columns):\n",
      "title                            18523 non-null object\n",
      "perex                            18523 non-null object\n",
      "body                             18523 non-null object\n",
      "published_at                     18523 non-null datetime64[ns]\n",
      "extracted_at                     18523 non-null datetime64[ns]\n",
      "source_id                        18523 non-null int64\n",
      "category                         12396 non-null object\n",
      "other_info                       18519 non-null object\n",
      "image_count                      18523 non-null int64\n",
      "video_count                      18523 non-null int64\n",
      "author_name                      18523 non-null object\n",
      "source_id                        18523 non-null int64\n",
      "source_name                      18523 non-null object\n",
      "source_url                       18523 non-null object\n",
      "source_type                      18523 non-null object\n",
      "source_is_reliable               18523 non-null int64\n",
      "fb_ad_0_comment_count            8264 non-null float64\n",
      "fb_ad_1_comment_count            12879 non-null float64\n",
      "fb_ad_2_comment_count            13924 non-null float64\n",
      "fb_ad_3_comment_count            14574 non-null float64\n",
      "fb_ad_4_comment_count            14893 non-null float64\n",
      "fb_ad_5_comment_count            14832 non-null float64\n",
      "fb_ad_6_comment_count            14863 non-null float64\n",
      "fb_ad_7_comment_count            14839 non-null float64\n",
      "fb_ad_8_comment_count            14788 non-null float64\n",
      "fb_ad_9_comment_count            14933 non-null float64\n",
      "fb_ad_10_comment_count           15121 non-null float64\n",
      "fb_ad_11_comment_count           15164 non-null float64\n",
      "fb_ad_12_comment_count           14992 non-null float64\n",
      "fb_ad_13_comment_count           14817 non-null float64\n",
      "fb_ad_14_comment_count           14670 non-null float64\n",
      "fb_ad_0_reaction_count           8264 non-null float64\n",
      "fb_ad_1_reaction_count           12879 non-null float64\n",
      "fb_ad_2_reaction_count           13924 non-null float64\n",
      "fb_ad_3_reaction_count           14574 non-null float64\n",
      "fb_ad_4_reaction_count           14893 non-null float64\n",
      "fb_ad_5_reaction_count           14832 non-null float64\n",
      "fb_ad_6_reaction_count           14863 non-null float64\n",
      "fb_ad_7_reaction_count           14839 non-null float64\n",
      "fb_ad_8_reaction_count           14788 non-null float64\n",
      "fb_ad_9_reaction_count           14933 non-null float64\n",
      "fb_ad_10_reaction_count          15121 non-null float64\n",
      "fb_ad_11_reaction_count          15164 non-null float64\n",
      "fb_ad_12_reaction_count          14992 non-null float64\n",
      "fb_ad_13_reaction_count          14817 non-null float64\n",
      "fb_ad_14_reaction_count          14670 non-null float64\n",
      "fb_ad_0_share_count              8264 non-null float64\n",
      "fb_ad_1_share_count              12879 non-null float64\n",
      "fb_ad_2_share_count              13924 non-null float64\n",
      "fb_ad_3_share_count              14574 non-null float64\n",
      "fb_ad_4_share_count              14893 non-null float64\n",
      "fb_ad_5_share_count              14832 non-null float64\n",
      "fb_ad_6_share_count              14863 non-null float64\n",
      "fb_ad_7_share_count              14839 non-null float64\n",
      "fb_ad_8_share_count              14788 non-null float64\n",
      "fb_ad_9_share_count              14933 non-null float64\n",
      "fb_ad_10_share_count             15121 non-null float64\n",
      "fb_ad_11_share_count             15164 non-null float64\n",
      "fb_ad_12_share_count             14992 non-null float64\n",
      "fb_ad_13_share_count             14817 non-null float64\n",
      "fb_ad_14_share_count             14670 non-null float64\n",
      "fb_popularity_ad_0               18523 non-null float64\n",
      "fb_popularity_ad_1               18523 non-null float64\n",
      "fb_popularity_ad_2               18523 non-null float64\n",
      "fb_popularity_ad_3               18523 non-null float64\n",
      "fb_popularity_ad_4               18523 non-null float64\n",
      "fb_popularity_ad_5               18523 non-null float64\n",
      "fb_popularity_ad_6               18523 non-null float64\n",
      "fb_popularity_ad_7               18523 non-null float64\n",
      "fb_popularity_ad_8               18523 non-null float64\n",
      "fb_popularity_ad_9               18523 non-null float64\n",
      "fb_popularity_ad_10              18523 non-null float64\n",
      "fb_popularity_ad_11              18523 non-null float64\n",
      "fb_popularity_ad_12              18523 non-null float64\n",
      "fb_popularity_ad_13              18523 non-null float64\n",
      "fb_popularity_ad_14              18523 non-null float64\n",
      "fb_ad_15_reaction_count_label    18523 non-null int64\n",
      "fb_ad_15_comment_count_label     18523 non-null int64\n",
      "fb_ad_15_share_count_label       18523 non-null int64\n",
      "fb_popularity_ad_15_label        18523 non-null int64\n",
      "is_fake_news_label               18523 non-null int64\n",
      "dtypes: datetime64[ns](2), float64(60), int64(10), object(9)\n",
      "memory usage: 11.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rozdelenie dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, validation = tuple(split_data(df, sizes=[2, 2, 1], shuffle=True, np_random=np_random))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7410, 7409, 3704]\n"
     ]
    }
   ],
   "source": [
    "print([len(i) for i in [train,test,validation]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fb_ad_15_reaction_count_label',\n",
       " 'fb_ad_15_comment_count_label',\n",
       " 'fb_ad_15_share_count_label',\n",
       " 'fb_popularity_ad_15_label',\n",
       " 'is_fake_news_label']"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from textblob import TextBlob\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    doc = nlp(text, disable=['parser', 'tagger', 'ner'])\n",
    "    \n",
    "    res = []\n",
    "    for i in doc:\n",
    "        if i.is_stop:\n",
    "            continue\n",
    "        if i.is_punct:\n",
    "            continue\n",
    "            \n",
    "        res.append(str(i))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_basic_features(df):\n",
    "    cv = CountVectorizer()\n",
    "    data = cv.fit_transform(df.title)\n",
    "\n",
    "    res = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    res['title_word_count'] = data.sum(axis=1)\n",
    "    res['title_char_length'] = df.title.apply(lambda x: len(x))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perex_basic_features(df):\n",
    "    cv = CountVectorizer()\n",
    "    data = cv.fit_transform(df.perex)\n",
    "\n",
    "    res = pd.DataFrame(index=df.index)    \n",
    "    res['perex_word_count'] = data.sum(axis=1)\n",
    "    res['perex_char_length'] = df.perex.apply(lambda x: len(x))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_basic_features(df):\n",
    "    content_cv = CountVectorizer()\n",
    "    data = content_cv.fit_transform(df.body)\n",
    "\n",
    "    res = pd.DataFrame(index=df.index)    \n",
    "    res['content_word_count'] = data.sum(axis=1)\n",
    "    res['content_char_length'] = df.body.apply(lambda x: len(x))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def media_count_total(df):\n",
    "    res = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    res['media_count_total'] = df['image_count'] + df['video_count']\n",
    "    \n",
    "    return res\n",
    "    \n",
    "def media_count_image(df):\n",
    "    return column_feature(df, 'image_count')\n",
    "\n",
    "def media_count_video(df):\n",
    "    return column_feature(df, 'video_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def published_on_day(df):\n",
    "    res = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    res['published_on_day'] = df.published_at.dt.weekday + 1\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popularity_features(df):\n",
    "    res = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    \n",
    "    for i in [0,1,3]:\n",
    "        res[f'fb_ad_{i}_reaction_count'] = df[f'fb_ad_{i}_reaction_count']\n",
    "        res[f'fb_ad_{i}_comment_count'] = df[f'fb_ad_{i}_comment_count']\n",
    "        res[f'fb_ad_{i}_share_count'] = df[f'fb_ad_{i}_share_count']\n",
    "        res[f'fb_popularity_ad_{i}'] = df[f'fb_popularity_ad_{i}']\n",
    "        \n",
    "    \n",
    "    res.fillna(res.mean(), inplace=True)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_collective_author(df):\n",
    "    \n",
    "    uniq_source_names = df.source_name.unique()\n",
    "    def make_a_guess(author_name):\n",
    "\n",
    "        return any((\n",
    "                    str_contains(author_name, 'admin', case=False),\n",
    "                    author_name.startswith('Neuroscience News Posts Science Research News Labs Universities Hospitals News Departments Around The World'),\n",
    "                    author_name in ['Neuroscience News',\n",
    "                                    'Wake Up World',\n",
    "                                    'Health Sciences Institute',\n",
    "                                    'REALdeal', \n",
    "                                    'nmheditor',\n",
    "                                    'The Mind Unleashed',\n",
    "                                    'Thinking Moms\\' Revolution',\n",
    "                                    'TheNewsDoctors',\n",
    "                                    'clnews',\n",
    "                                    'Associated Press',\n",
    "                                    'HealthDay',\n",
    "                                    'Infowars',\n",
    "                                    'Natural News Editors',\n",
    "                                    'https://www.facebook.com/WebMD',\n",
    "                                    'naturalnews', 'peakconsciousness', 'HealingwithoutHurting',\n",
    "                                    'HealthNutNews.com',\n",
    "                                   ],\n",
    "                    author_name.startswith('The Associated Press'),\n",
    "                    # ' and ' in author_name, # todo: je to kolektivny autor ak ich je len viac?\n",
    "                    author_name in uniq_source_names,   \n",
    "        ))\n",
    "    \n",
    "    res = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    res['is_collective_author'] = df.author_name.map(make_a_guess)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 gut health\n",
       "1                                       None\n",
       "2                                     Beauty\n",
       "3                                     Health\n",
       "4                              First Opinion\n",
       "                        ...                 \n",
       "1504    fc1580e2-2ac1-532a-bd5c-b5adeffb1c25\n",
       "1505                                 Liberty\n",
       "1506    6790bd7e-8e3f-5c8e-b184-17a7c91417fd\n",
       "1507    3d59c851-2266-5959-85f7-6cdd51d6e939\n",
       "1508    92972df9-7135-5d2f-9116-d4d0fd37393d\n",
       "Length: 1509, dtype: object"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(df.category.explode().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    title_basic_features,\n",
    "    perex_basic_features,\n",
    "    content_basic_features,\n",
    "    \n",
    "    media_count_total,\n",
    "    media_count_image,\n",
    "    media_count_video,\n",
    "    \n",
    "    published_on_day,\n",
    "    is_collective_author,\n",
    "    \n",
    "    popularity_features\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df):    \n",
    "    pbar_conf = {\n",
    "        'refresh_rate': 1,\n",
    "        'action_names': [i.__name__ for i in features]\n",
    "    }\n",
    "    \n",
    "    res = pd.DataFrame()\n",
    "    for feature_generator in Pbar(features, **pbar_conf):\n",
    "        res = pd.concat([res, feature_generator(df)], axis=1)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = split_X_y_all(train, test, validation, selected_label='is_fake_news_label', all_labels=label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] -- 9 / 9 -- (finished)y_features) -- 8 / 99 9\n"
     ]
    }
   ],
   "source": [
    "data.train.features = add_features(data.train.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] -- 9 / 9 -- (finished)y_features) -- 8 / 99 9\n"
     ]
    }
   ],
   "source": [
    "data.test.features = add_features(data.test.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] -- 9 / 9 -- (finished)y_features) -- 8 / 99 9\n"
     ]
    }
   ],
   "source": [
    "data.validation.features = add_features(data.validation.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fb_ad_15_reaction_count_label',\n",
       " 'fb_ad_15_comment_count_label',\n",
       " 'fb_ad_15_share_count_label',\n",
       " 'fb_popularity_ad_15_label',\n",
       " 'is_fake_news_label']"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_to_file(data, file):\n",
    "    with open(file, 'w', encoding='utf-8') as f:\n",
    "        for i in Pbar(data):\n",
    "            f.write(f\"{' '.join(tokenize(i))}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 8 cores available\n"
     ]
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "print(f'>>> {cores} cores available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] -- 7410 / 7410 -- (finished)\n",
      "[==================================================] -- 7409 / 7409 -- (finished)\n",
      "[==================================================] -- 3704 / 3704 -- (finished)\n"
     ]
    }
   ],
   "source": [
    "tokenize_to_file(data.train.X.body, './data/train_body_tokenized.txt')\n",
    "tokenize_to_file(data.test.X.body, './data/test_body_tokenized.txt')\n",
    "tokenize_to_file(data.validation.X.body, './data/validation_body_tokenized.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-03 01:26:15,098 : INFO : collecting all words and their counts\n",
      "2020-04-03 01:26:15,100 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2020-04-03 01:26:15,845 : INFO : collected 86257 word types and 7410 unique tags from a corpus of 7410 examples and 2531878 words\n",
      "2020-04-03 01:26:15,845 : INFO : Loading a fresh vocabulary\n",
      "2020-04-03 01:26:15,957 : INFO : effective_min_count=2 retains 49575 unique words (57% of original 86257, drops 36682)\n",
      "2020-04-03 01:26:15,958 : INFO : effective_min_count=2 leaves 2495196 word corpus (98% of original 2531878, drops 36682)\n",
      "2020-04-03 01:26:16,132 : INFO : deleting the raw counts dictionary of 86257 items\n",
      "2020-04-03 01:26:16,134 : INFO : sample=0.001 downsamples 9 most-common words\n",
      "2020-04-03 01:26:16,135 : INFO : downsampling leaves estimated 2470425 word corpus (99.0% of prior 2495196)\n",
      "2020-04-03 01:26:16,303 : INFO : estimated required memory for 49575 words and 300 dimensions: 152659500 bytes\n",
      "2020-04-03 01:26:16,305 : INFO : resetting layer weights\n",
      "2020-04-03 01:26:17,071 : INFO : training model with 8 workers on 49575 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-03 01:26:19,333 : INFO : EPOCH 1 - PROGRESS: at 12.55% examples, 143047 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-03 01:26:19,334 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-03 01:26:19,385 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-03 01:26:19,400 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-03 01:26:19,422 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-03 01:26:19,425 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-03 01:26:19,428 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-03 01:26:19,438 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-03 01:26:19,447 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-03 01:26:19,448 : INFO : EPOCH - 1 : training on 2535052 raw words (2480919 effective words) took 2.3s, 1086905 effective words/s\n",
      "2020-04-03 01:26:21,713 : INFO : EPOCH 2 - PROGRESS: at 12.52% examples, 143468 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-03 01:26:21,714 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-03 01:26:21,744 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-03 01:26:21,746 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-03 01:26:21,803 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-03 01:26:21,921 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-03 01:26:21,967 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-03 01:26:21,970 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-03 01:26:21,986 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-03 01:26:21,988 : INFO : EPOCH - 2 : training on 2535052 raw words (2481043 effective words) took 2.4s, 1019811 effective words/s\n",
      "2020-04-03 01:26:24,433 : INFO : EPOCH 3 - PROGRESS: at 12.55% examples, 131063 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-03 01:26:24,435 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-03 01:26:24,437 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-03 01:26:24,484 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-03 01:26:24,486 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-03 01:26:24,511 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-03 01:26:24,538 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-03 01:26:24,564 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-03 01:26:24,600 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-03 01:26:24,602 : INFO : EPOCH - 3 : training on 2535052 raw words (2480841 effective words) took 2.5s, 978843 effective words/s\n",
      "2020-04-03 01:26:27,402 : INFO : EPOCH 4 - PROGRESS: at 12.67% examples, 114145 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-03 01:26:27,404 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-03 01:26:27,412 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-03 01:26:27,448 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-03 01:26:27,470 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-03 01:26:27,473 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-03 01:26:27,476 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-03 01:26:27,491 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-03 01:26:27,524 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-03 01:26:27,525 : INFO : EPOCH - 4 : training on 2535052 raw words (2480899 effective words) took 2.8s, 873361 effective words/s\n",
      "2020-04-03 01:26:30,219 : INFO : EPOCH 5 - PROGRESS: at 12.94% examples, 119129 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-03 01:26:30,221 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-03 01:26:30,252 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-03 01:26:30,263 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-03 01:26:30,296 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-03 01:26:30,315 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-03 01:26:30,319 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-03 01:26:30,323 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-03 01:26:30,344 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-03 01:26:30,345 : INFO : EPOCH - 5 : training on 2535052 raw words (2480895 effective words) took 2.7s, 907675 effective words/s\n",
      "2020-04-03 01:26:32,904 : INFO : EPOCH 6 - PROGRESS: at 12.05% examples, 124222 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-03 01:26:32,906 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-03 01:26:32,940 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-03 01:26:32,976 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-03 01:26:32,984 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-03 01:26:32,989 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-03 01:26:32,993 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-03 01:26:33,003 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-03 01:26:33,010 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-03 01:26:33,011 : INFO : EPOCH - 6 : training on 2535052 raw words (2480896 effective words) took 2.6s, 953502 effective words/s\n",
      "2020-04-03 01:26:35,615 : INFO : EPOCH 7 - PROGRESS: at 12.31% examples, 121875 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-03 01:26:35,617 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-03 01:26:35,652 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-03 01:26:35,660 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-03 01:26:35,668 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-03 01:26:35,671 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-03 01:26:35,673 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-03 01:26:35,689 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-03 01:26:35,696 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-03 01:26:35,697 : INFO : EPOCH - 7 : training on 2535052 raw words (2480880 effective words) took 2.6s, 944615 effective words/s\n",
      "2020-04-03 01:26:38,283 : INFO : EPOCH 8 - PROGRESS: at 12.67% examples, 122868 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-03 01:26:38,285 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-03 01:26:38,320 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-03 01:26:38,323 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-03 01:26:38,325 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-03 01:26:38,326 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-03 01:26:38,327 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-03 01:26:38,352 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-03 01:26:38,353 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-03 01:26:38,354 : INFO : EPOCH - 8 : training on 2535052 raw words (2480865 effective words) took 2.6s, 956175 effective words/s\n",
      "2020-04-03 01:26:41,048 : INFO : EPOCH 9 - PROGRESS: at 12.52% examples, 117637 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-03 01:26:41,050 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-03 01:26:41,058 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-03 01:26:41,070 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-03 01:26:41,075 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-03 01:26:41,089 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-03 01:26:41,090 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-03 01:26:41,098 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-03 01:26:41,110 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-03 01:26:41,111 : INFO : EPOCH - 9 : training on 2535052 raw words (2480837 effective words) took 2.7s, 920430 effective words/s\n",
      "2020-04-03 01:26:43,637 : INFO : EPOCH 10 - PROGRESS: at 12.52% examples, 125555 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-03 01:26:43,639 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-03 01:26:43,664 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-03 01:26:43,679 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-03 01:26:43,687 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-03 01:26:43,698 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-03 01:26:43,755 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-03 01:26:43,759 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-03 01:26:43,763 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-03 01:26:43,764 : INFO : EPOCH - 10 : training on 2535052 raw words (2480806 effective words) took 2.6s, 956526 effective words/s\n",
      "2020-04-03 01:26:46,355 : INFO : EPOCH 11 - PROGRESS: at 12.52% examples, 122330 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-03 01:26:46,357 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-03 01:26:46,376 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-03 01:26:46,384 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-03 01:26:46,401 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-03 01:26:46,405 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-03 01:26:46,427 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-03 01:26:46,435 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-03 01:26:46,448 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-03 01:26:46,449 : INFO : EPOCH - 11 : training on 2535052 raw words (2480853 effective words) took 2.6s, 945206 effective words/s\n",
      "2020-04-03 01:26:49,054 : INFO : EPOCH 12 - PROGRESS: at 12.52% examples, 122112 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-03 01:26:49,055 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-03 01:26:49,085 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-03 01:26:49,089 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-03 01:26:49,106 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-03 01:26:49,134 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-03 01:26:49,149 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-03 01:26:49,162 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-03 01:26:49,163 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-03 01:26:49,164 : INFO : EPOCH - 12 : training on 2535052 raw words (2480923 effective words) took 2.6s, 937469 effective words/s\n",
      "2020-04-03 01:26:51,903 : INFO : EPOCH 13 - PROGRESS: at 12.40% examples, 116048 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-03 01:26:51,906 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-03 01:26:51,910 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-03 01:26:51,931 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-03 01:26:51,948 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-03 01:26:51,979 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-03 01:26:51,990 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-03 01:26:51,996 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-03 01:26:52,001 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-03 01:26:52,002 : INFO : EPOCH - 13 : training on 2535052 raw words (2480948 effective words) took 2.8s, 893479 effective words/s\n",
      "2020-04-03 01:26:54,631 : INFO : EPOCH 14 - PROGRESS: at 12.05% examples, 120798 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-03 01:26:54,633 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-03 01:26:54,634 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-03 01:26:54,638 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-03 01:26:54,650 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-03 01:26:54,655 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-03 01:26:54,657 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-03 01:26:54,699 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-03 01:26:54,711 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-03 01:26:54,712 : INFO : EPOCH - 14 : training on 2535052 raw words (2481016 effective words) took 2.6s, 937464 effective words/s\n",
      "2020-04-03 01:26:57,800 : INFO : EPOCH 15 - PROGRESS: at 12.05% examples, 103529 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-03 01:26:57,801 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-03 01:26:57,820 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-03 01:26:57,839 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-03 01:26:57,846 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-03 01:26:57,863 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-03 01:26:57,893 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-03 01:26:57,949 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-03 01:26:57,961 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-03 01:26:57,962 : INFO : EPOCH - 15 : training on 2535052 raw words (2480909 effective words) took 3.2s, 785993 effective words/s\n",
      "2020-04-03 01:26:57,968 : INFO : training on a 38025780 raw words (37213530 effective words) took 40.9s, 909950 effective words/s\n"
     ]
    }
   ],
   "source": [
    "d2v = Doc2Vec(corpus_file='./data/train_body_tokenized.txt', vector_size=300, min_count=2, epochs=15, workers=cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_d2v(d2v_model, data_file):\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    with open(data_file, 'r', encoding='utf-8') as f:\n",
    "        for i in Pbar(f.readlines()):\n",
    "            res.append(d2v_model.infer_vector(i.split(' '), steps=20, alpha=0.025)) \n",
    "    \n",
    "    return res\n",
    "\n",
    "def infer_for_df(df, d2v_model, data_file):\n",
    "    lst = infer_d2v(d2v_model, data_file)\n",
    "    d2v_df = pd.DataFrame(lst, index=df.index, columns=[f'd2v_{i}' for i in range(1, 301)] )\n",
    "    \n",
    "    return pd.concat([df, d2v_df], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] -- 7410 / 7410 -- (finished)\n"
     ]
    }
   ],
   "source": [
    "data.train.features = infer_for_df(data.train.features, d2v, './data/train_body_tokenized.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] -- 7409 / 7409 -- (finished)\n"
     ]
    }
   ],
   "source": [
    "data.test.features = infer_for_df(data.test.features, d2v, './data/test_body_tokenized.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(clf, data):\n",
    "    clf.fit(data.train.features, data.train.y)\n",
    "    return clf.predict(data.test.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fb_ad_15_reaction_count_label',\n",
       " 'fb_ad_15_comment_count_label',\n",
       " 'fb_ad_15_share_count_label',\n",
       " 'fb_popularity_ad_15_label',\n",
       " 'is_fake_news_label']"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train.switch_label('is_fake_news_label')\n",
    "data.test.switch_label('is_fake_news_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train.features['media_count_total'] = pd.to_numeric(data.train.features['media_count_total'])\n",
    "data.train.features['image_count'] = pd.to_numeric(data.train.features['image_count'])\n",
    "data.train.features['video_count'] = pd.to_numeric(data.train.features['video_count'])\n",
    "\n",
    "data.test.features['media_count_total'] = pd.to_numeric(data.test.features['media_count_total'])\n",
    "data.test.features['image_count'] = pd.to_numeric(data.test.features['image_count'])\n",
    "data.test.features['video_count'] = pd.to_numeric(data.test.features['video_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train.features.drop(columns=['perex_word_count', 'perex_char_length'], inplace=True)\n",
    "data.test.features.drop(columns=['perex_word_count', 'perex_char_length'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train.y = pd.to_numeric(data.train.y)\n",
    "data.test.y = pd.to_numeric(data.test.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================================================] -- 2 / 2 -- (finished)fier) -- 1 / 2 -- 0 / 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.98      0.90      4333\n",
      "           1       0.95      0.72      0.82      3076\n",
      "\n",
      "    accuracy                           0.87      7409\n",
      "   macro avg       0.89      0.85      0.86      7409\n",
      "weighted avg       0.88      0.87      0.87      7409\n",
      "\n",
      "------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89      4333\n",
      "           1       0.95      0.71      0.81      3076\n",
      "\n",
      "    accuracy                           0.86      7409\n",
      "   macro avg       0.89      0.84      0.85      7409\n",
      "weighted avg       0.88      0.86      0.86      7409\n",
      "\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=cores),\n",
    "    XGBClassifier(n_jobs=cores, seed=RANDOM_STATE),\n",
    "]\n",
    "\n",
    "pbar_conf = {\n",
    "    'refresh_rate': 1,\n",
    "    'length': len(classifiers), \n",
    "    'pbar_width': 52,\n",
    "    'action_names': [i.__class__.__name__ for i in classifiers]\n",
    "}\n",
    "\n",
    "predictions = list(Pbar((fit_predict(clf, data) for clf in classifiers), **pbar_conf))\n",
    "\n",
    "for p in predictions:\n",
    "    print(classification_report(data.test.y, p))\n",
    "    print('-' * 54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>fb_ad_0_reaction_count</td>\n",
       "      <td>0.035345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fb_ad_0_share_count</td>\n",
       "      <td>0.033777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fb_ad_0_comment_count</td>\n",
       "      <td>0.031055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>title_char_length</td>\n",
       "      <td>0.030491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>media_count_total</td>\n",
       "      <td>0.025735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>title_word_count</td>\n",
       "      <td>0.024622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>content_char_length</td>\n",
       "      <td>0.022564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>content_word_count</td>\n",
       "      <td>0.021474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>image_count</td>\n",
       "      <td>0.021430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fb_popularity_ad_0</td>\n",
       "      <td>0.021361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fb_ad_1_comment_count</td>\n",
       "      <td>0.018166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fb_ad_1_reaction_count</td>\n",
       "      <td>0.014531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fb_ad_1_share_count</td>\n",
       "      <td>0.012283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>is_collective_author</td>\n",
       "      <td>0.011865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_217</td>\n",
       "      <td>0.010847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fb_ad_3_share_count</td>\n",
       "      <td>0.010622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fb_ad_3_reaction_count</td>\n",
       "      <td>0.008825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fb_ad_3_comment_count</td>\n",
       "      <td>0.008269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_172</td>\n",
       "      <td>0.007867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_182</td>\n",
       "      <td>0.007357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_120</td>\n",
       "      <td>0.006785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_124</td>\n",
       "      <td>0.006456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_50</td>\n",
       "      <td>0.006413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_140</td>\n",
       "      <td>0.006332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_149</td>\n",
       "      <td>0.006143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_93</td>\n",
       "      <td>0.006142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_232</td>\n",
       "      <td>0.006065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_250</td>\n",
       "      <td>0.006031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fb_popularity_ad_1</td>\n",
       "      <td>0.005968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_109</td>\n",
       "      <td>0.005869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_282</td>\n",
       "      <td>0.005236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_229</td>\n",
       "      <td>0.005211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_92</td>\n",
       "      <td>0.005129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_24</td>\n",
       "      <td>0.005083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_22</td>\n",
       "      <td>0.005052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_196</td>\n",
       "      <td>0.004946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_154</td>\n",
       "      <td>0.004371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_240</td>\n",
       "      <td>0.004300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_51</td>\n",
       "      <td>0.004274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_25</td>\n",
       "      <td>0.004272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_144</td>\n",
       "      <td>0.004198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_220</td>\n",
       "      <td>0.004040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_216</td>\n",
       "      <td>0.003853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_7</td>\n",
       "      <td>0.003807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_170</td>\n",
       "      <td>0.003806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_147</td>\n",
       "      <td>0.003767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_135</td>\n",
       "      <td>0.003749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_56</td>\n",
       "      <td>0.003589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_103</td>\n",
       "      <td>0.003565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_192</td>\n",
       "      <td>0.003543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fb_popularity_ad_3</td>\n",
       "      <td>0.003500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_96</td>\n",
       "      <td>0.003453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_265</td>\n",
       "      <td>0.003412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_199</td>\n",
       "      <td>0.003404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_244</td>\n",
       "      <td>0.003106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_39</td>\n",
       "      <td>0.003058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_253</td>\n",
       "      <td>0.003003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_126</td>\n",
       "      <td>0.002998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_26</td>\n",
       "      <td>0.002992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_85</td>\n",
       "      <td>0.002984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_68</td>\n",
       "      <td>0.002945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_44</td>\n",
       "      <td>0.002929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_228</td>\n",
       "      <td>0.002842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_277</td>\n",
       "      <td>0.002831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_6</td>\n",
       "      <td>0.002817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_82</td>\n",
       "      <td>0.002816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_180</td>\n",
       "      <td>0.002807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_148</td>\n",
       "      <td>0.002801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_72</td>\n",
       "      <td>0.002777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_163</td>\n",
       "      <td>0.002765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_169</td>\n",
       "      <td>0.002757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_215</td>\n",
       "      <td>0.002685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_194</td>\n",
       "      <td>0.002671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_117</td>\n",
       "      <td>0.002583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_226</td>\n",
       "      <td>0.002547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_37</td>\n",
       "      <td>0.002535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_83</td>\n",
       "      <td>0.002529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_295</td>\n",
       "      <td>0.002495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_197</td>\n",
       "      <td>0.002490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_213</td>\n",
       "      <td>0.002461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_214</td>\n",
       "      <td>0.002437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_90</td>\n",
       "      <td>0.002428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_167</td>\n",
       "      <td>0.002350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_89</td>\n",
       "      <td>0.002336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_157</td>\n",
       "      <td>0.002322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_188</td>\n",
       "      <td>0.002316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_189</td>\n",
       "      <td>0.002304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_123</td>\n",
       "      <td>0.002242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_130</td>\n",
       "      <td>0.002233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_155</td>\n",
       "      <td>0.002232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_261</td>\n",
       "      <td>0.002224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_64</td>\n",
       "      <td>0.002197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_235</td>\n",
       "      <td>0.002196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_178</td>\n",
       "      <td>0.002188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_296</td>\n",
       "      <td>0.002181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_164</td>\n",
       "      <td>0.002168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_10</td>\n",
       "      <td>0.002148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_262</td>\n",
       "      <td>0.002137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_211</td>\n",
       "      <td>0.002129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_238</td>\n",
       "      <td>0.002109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_158</td>\n",
       "      <td>0.002106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_61</td>\n",
       "      <td>0.002094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_185</td>\n",
       "      <td>0.002072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_186</td>\n",
       "      <td>0.002041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_254</td>\n",
       "      <td>0.002012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_111</td>\n",
       "      <td>0.001993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_236</td>\n",
       "      <td>0.001991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_115</td>\n",
       "      <td>0.001970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_67</td>\n",
       "      <td>0.001959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_43</td>\n",
       "      <td>0.001956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_222</td>\n",
       "      <td>0.001950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_119</td>\n",
       "      <td>0.001946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_38</td>\n",
       "      <td>0.001945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_276</td>\n",
       "      <td>0.001945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_127</td>\n",
       "      <td>0.001941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_48</td>\n",
       "      <td>0.001938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_128</td>\n",
       "      <td>0.001937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_55</td>\n",
       "      <td>0.001923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_129</td>\n",
       "      <td>0.001904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_292</td>\n",
       "      <td>0.001902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_101</td>\n",
       "      <td>0.001899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_273</td>\n",
       "      <td>0.001894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_59</td>\n",
       "      <td>0.001893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_23</td>\n",
       "      <td>0.001890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_47</td>\n",
       "      <td>0.001874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_159</td>\n",
       "      <td>0.001871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_4</td>\n",
       "      <td>0.001867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_31</td>\n",
       "      <td>0.001855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_233</td>\n",
       "      <td>0.001842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_86</td>\n",
       "      <td>0.001841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_133</td>\n",
       "      <td>0.001838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_209</td>\n",
       "      <td>0.001831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_152</td>\n",
       "      <td>0.001826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_46</td>\n",
       "      <td>0.001824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_75</td>\n",
       "      <td>0.001818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_1</td>\n",
       "      <td>0.001818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_20</td>\n",
       "      <td>0.001816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_112</td>\n",
       "      <td>0.001808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_136</td>\n",
       "      <td>0.001783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_118</td>\n",
       "      <td>0.001778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_35</td>\n",
       "      <td>0.001772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_106</td>\n",
       "      <td>0.001747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_190</td>\n",
       "      <td>0.001745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_104</td>\n",
       "      <td>0.001742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_284</td>\n",
       "      <td>0.001740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_205</td>\n",
       "      <td>0.001733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_77</td>\n",
       "      <td>0.001733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_107</td>\n",
       "      <td>0.001731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_3</td>\n",
       "      <td>0.001729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_45</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_183</td>\n",
       "      <td>0.001725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_80</td>\n",
       "      <td>0.001723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_114</td>\n",
       "      <td>0.001723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_291</td>\n",
       "      <td>0.001720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_156</td>\n",
       "      <td>0.001713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_153</td>\n",
       "      <td>0.001712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_102</td>\n",
       "      <td>0.001710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_219</td>\n",
       "      <td>0.001706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_17</td>\n",
       "      <td>0.001703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_257</td>\n",
       "      <td>0.001702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_60</td>\n",
       "      <td>0.001697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_142</td>\n",
       "      <td>0.001696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_121</td>\n",
       "      <td>0.001693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_174</td>\n",
       "      <td>0.001683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_81</td>\n",
       "      <td>0.001683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_201</td>\n",
       "      <td>0.001658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_187</td>\n",
       "      <td>0.001657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_272</td>\n",
       "      <td>0.001657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_160</td>\n",
       "      <td>0.001656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_168</td>\n",
       "      <td>0.001655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_87</td>\n",
       "      <td>0.001652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_223</td>\n",
       "      <td>0.001647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_239</td>\n",
       "      <td>0.001646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_141</td>\n",
       "      <td>0.001641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_224</td>\n",
       "      <td>0.001637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_110</td>\n",
       "      <td>0.001632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_79</td>\n",
       "      <td>0.001626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_243</td>\n",
       "      <td>0.001621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_78</td>\n",
       "      <td>0.001621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_34</td>\n",
       "      <td>0.001619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_242</td>\n",
       "      <td>0.001618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_91</td>\n",
       "      <td>0.001614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_202</td>\n",
       "      <td>0.001613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_245</td>\n",
       "      <td>0.001613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_14</td>\n",
       "      <td>0.001604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_62</td>\n",
       "      <td>0.001604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_58</td>\n",
       "      <td>0.001603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_286</td>\n",
       "      <td>0.001601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_279</td>\n",
       "      <td>0.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_193</td>\n",
       "      <td>0.001592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_18</td>\n",
       "      <td>0.001591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_218</td>\n",
       "      <td>0.001588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_271</td>\n",
       "      <td>0.001588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_5</td>\n",
       "      <td>0.001583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_294</td>\n",
       "      <td>0.001580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_231</td>\n",
       "      <td>0.001578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_42</td>\n",
       "      <td>0.001576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_252</td>\n",
       "      <td>0.001573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_137</td>\n",
       "      <td>0.001573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_134</td>\n",
       "      <td>0.001567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_179</td>\n",
       "      <td>0.001567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_65</td>\n",
       "      <td>0.001565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_280</td>\n",
       "      <td>0.001565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_287</td>\n",
       "      <td>0.001565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_2</td>\n",
       "      <td>0.001562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_99</td>\n",
       "      <td>0.001562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_53</td>\n",
       "      <td>0.001562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_204</td>\n",
       "      <td>0.001559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_57</td>\n",
       "      <td>0.001553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_210</td>\n",
       "      <td>0.001547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_173</td>\n",
       "      <td>0.001546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_49</td>\n",
       "      <td>0.001543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_270</td>\n",
       "      <td>0.001539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_267</td>\n",
       "      <td>0.001531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_151</td>\n",
       "      <td>0.001525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_290</td>\n",
       "      <td>0.001525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_208</td>\n",
       "      <td>0.001524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_116</td>\n",
       "      <td>0.001524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_255</td>\n",
       "      <td>0.001523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_122</td>\n",
       "      <td>0.001520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_71</td>\n",
       "      <td>0.001518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_248</td>\n",
       "      <td>0.001514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_76</td>\n",
       "      <td>0.001513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_263</td>\n",
       "      <td>0.001512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_105</td>\n",
       "      <td>0.001509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_264</td>\n",
       "      <td>0.001507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_230</td>\n",
       "      <td>0.001507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_33</td>\n",
       "      <td>0.001505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_275</td>\n",
       "      <td>0.001505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_108</td>\n",
       "      <td>0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_195</td>\n",
       "      <td>0.001498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_289</td>\n",
       "      <td>0.001496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_206</td>\n",
       "      <td>0.001495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_266</td>\n",
       "      <td>0.001495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_285</td>\n",
       "      <td>0.001491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_258</td>\n",
       "      <td>0.001485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_200</td>\n",
       "      <td>0.001483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_234</td>\n",
       "      <td>0.001482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_40</td>\n",
       "      <td>0.001478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_166</td>\n",
       "      <td>0.001477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_246</td>\n",
       "      <td>0.001475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_88</td>\n",
       "      <td>0.001473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_175</td>\n",
       "      <td>0.001471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_19</td>\n",
       "      <td>0.001463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_12</td>\n",
       "      <td>0.001456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_145</td>\n",
       "      <td>0.001451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_132</td>\n",
       "      <td>0.001447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_146</td>\n",
       "      <td>0.001446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_207</td>\n",
       "      <td>0.001439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_278</td>\n",
       "      <td>0.001435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_176</td>\n",
       "      <td>0.001434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_297</td>\n",
       "      <td>0.001434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_299</td>\n",
       "      <td>0.001426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_268</td>\n",
       "      <td>0.001425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_251</td>\n",
       "      <td>0.001424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_28</td>\n",
       "      <td>0.001417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_221</td>\n",
       "      <td>0.001414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_29</td>\n",
       "      <td>0.001409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_288</td>\n",
       "      <td>0.001409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_177</td>\n",
       "      <td>0.001404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_191</td>\n",
       "      <td>0.001404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_66</td>\n",
       "      <td>0.001402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_70</td>\n",
       "      <td>0.001402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_281</td>\n",
       "      <td>0.001400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_237</td>\n",
       "      <td>0.001399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_259</td>\n",
       "      <td>0.001399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_30</td>\n",
       "      <td>0.001397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_27</td>\n",
       "      <td>0.001396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_181</td>\n",
       "      <td>0.001394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_74</td>\n",
       "      <td>0.001394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_113</td>\n",
       "      <td>0.001394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_97</td>\n",
       "      <td>0.001388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_139</td>\n",
       "      <td>0.001385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_100</td>\n",
       "      <td>0.001383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_298</td>\n",
       "      <td>0.001375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_269</td>\n",
       "      <td>0.001362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_300</td>\n",
       "      <td>0.001358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_9</td>\n",
       "      <td>0.001356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_293</td>\n",
       "      <td>0.001354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_260</td>\n",
       "      <td>0.001350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_161</td>\n",
       "      <td>0.001346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_8</td>\n",
       "      <td>0.001339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_165</td>\n",
       "      <td>0.001336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_131</td>\n",
       "      <td>0.001323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_171</td>\n",
       "      <td>0.001322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_36</td>\n",
       "      <td>0.001317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_227</td>\n",
       "      <td>0.001317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_41</td>\n",
       "      <td>0.001316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_98</td>\n",
       "      <td>0.001304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_143</td>\n",
       "      <td>0.001302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_212</td>\n",
       "      <td>0.001292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_15</td>\n",
       "      <td>0.001287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_274</td>\n",
       "      <td>0.001280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_162</td>\n",
       "      <td>0.001279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_52</td>\n",
       "      <td>0.001278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_11</td>\n",
       "      <td>0.001277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_13</td>\n",
       "      <td>0.001275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_54</td>\n",
       "      <td>0.001266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_203</td>\n",
       "      <td>0.001260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_95</td>\n",
       "      <td>0.001254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_241</td>\n",
       "      <td>0.001253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_283</td>\n",
       "      <td>0.001250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_125</td>\n",
       "      <td>0.001243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_73</td>\n",
       "      <td>0.001237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_184</td>\n",
       "      <td>0.001234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_247</td>\n",
       "      <td>0.001232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_63</td>\n",
       "      <td>0.001221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_225</td>\n",
       "      <td>0.001210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_69</td>\n",
       "      <td>0.001209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_32</td>\n",
       "      <td>0.001208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_16</td>\n",
       "      <td>0.001206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_256</td>\n",
       "      <td>0.001194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_84</td>\n",
       "      <td>0.001177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_21</td>\n",
       "      <td>0.001133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_94</td>\n",
       "      <td>0.001127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_138</td>\n",
       "      <td>0.001117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_150</td>\n",
       "      <td>0.001105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_249</td>\n",
       "      <td>0.001055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>published_on_day</td>\n",
       "      <td>0.001035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_198</td>\n",
       "      <td>0.000937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>video_count</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        importance\n",
       "fb_ad_0_reaction_count    0.035345\n",
       "fb_ad_0_share_count       0.033777\n",
       "fb_ad_0_comment_count     0.031055\n",
       "title_char_length         0.030491\n",
       "media_count_total         0.025735\n",
       "title_word_count          0.024622\n",
       "content_char_length       0.022564\n",
       "content_word_count        0.021474\n",
       "image_count               0.021430\n",
       "fb_popularity_ad_0        0.021361\n",
       "fb_ad_1_comment_count     0.018166\n",
       "fb_ad_1_reaction_count    0.014531\n",
       "fb_ad_1_share_count       0.012283\n",
       "is_collective_author      0.011865\n",
       "d2v_217                   0.010847\n",
       "fb_ad_3_share_count       0.010622\n",
       "fb_ad_3_reaction_count    0.008825\n",
       "fb_ad_3_comment_count     0.008269\n",
       "d2v_172                   0.007867\n",
       "d2v_182                   0.007357\n",
       "d2v_120                   0.006785\n",
       "d2v_124                   0.006456\n",
       "d2v_50                    0.006413\n",
       "d2v_140                   0.006332\n",
       "d2v_149                   0.006143\n",
       "d2v_93                    0.006142\n",
       "d2v_232                   0.006065\n",
       "d2v_250                   0.006031\n",
       "fb_popularity_ad_1        0.005968\n",
       "d2v_109                   0.005869\n",
       "d2v_282                   0.005236\n",
       "d2v_229                   0.005211\n",
       "d2v_92                    0.005129\n",
       "d2v_24                    0.005083\n",
       "d2v_22                    0.005052\n",
       "d2v_196                   0.004946\n",
       "d2v_154                   0.004371\n",
       "d2v_240                   0.004300\n",
       "d2v_51                    0.004274\n",
       "d2v_25                    0.004272\n",
       "d2v_144                   0.004198\n",
       "d2v_220                   0.004040\n",
       "d2v_216                   0.003853\n",
       "d2v_7                     0.003807\n",
       "d2v_170                   0.003806\n",
       "d2v_147                   0.003767\n",
       "d2v_135                   0.003749\n",
       "d2v_56                    0.003589\n",
       "d2v_103                   0.003565\n",
       "d2v_192                   0.003543\n",
       "fb_popularity_ad_3        0.003500\n",
       "d2v_96                    0.003453\n",
       "d2v_265                   0.003412\n",
       "d2v_199                   0.003404\n",
       "d2v_244                   0.003106\n",
       "d2v_39                    0.003058\n",
       "d2v_253                   0.003003\n",
       "d2v_126                   0.002998\n",
       "d2v_26                    0.002992\n",
       "d2v_85                    0.002984\n",
       "d2v_68                    0.002945\n",
       "d2v_44                    0.002929\n",
       "d2v_228                   0.002842\n",
       "d2v_277                   0.002831\n",
       "d2v_6                     0.002817\n",
       "d2v_82                    0.002816\n",
       "d2v_180                   0.002807\n",
       "d2v_148                   0.002801\n",
       "d2v_72                    0.002777\n",
       "d2v_163                   0.002765\n",
       "d2v_169                   0.002757\n",
       "d2v_215                   0.002685\n",
       "d2v_194                   0.002671\n",
       "d2v_117                   0.002583\n",
       "d2v_226                   0.002547\n",
       "d2v_37                    0.002535\n",
       "d2v_83                    0.002529\n",
       "d2v_295                   0.002495\n",
       "d2v_197                   0.002490\n",
       "d2v_213                   0.002461\n",
       "d2v_214                   0.002437\n",
       "d2v_90                    0.002428\n",
       "d2v_167                   0.002350\n",
       "d2v_89                    0.002336\n",
       "d2v_157                   0.002322\n",
       "d2v_188                   0.002316\n",
       "d2v_189                   0.002304\n",
       "d2v_123                   0.002242\n",
       "d2v_130                   0.002233\n",
       "d2v_155                   0.002232\n",
       "d2v_261                   0.002224\n",
       "d2v_64                    0.002197\n",
       "d2v_235                   0.002196\n",
       "d2v_178                   0.002188\n",
       "d2v_296                   0.002181\n",
       "d2v_164                   0.002168\n",
       "d2v_10                    0.002148\n",
       "d2v_262                   0.002137\n",
       "d2v_211                   0.002129\n",
       "d2v_238                   0.002109\n",
       "d2v_158                   0.002106\n",
       "d2v_61                    0.002094\n",
       "d2v_185                   0.002072\n",
       "d2v_186                   0.002041\n",
       "d2v_254                   0.002012\n",
       "d2v_111                   0.001993\n",
       "d2v_236                   0.001991\n",
       "d2v_115                   0.001970\n",
       "d2v_67                    0.001959\n",
       "d2v_43                    0.001956\n",
       "d2v_222                   0.001950\n",
       "d2v_119                   0.001946\n",
       "d2v_38                    0.001945\n",
       "d2v_276                   0.001945\n",
       "d2v_127                   0.001941\n",
       "d2v_48                    0.001938\n",
       "d2v_128                   0.001937\n",
       "d2v_55                    0.001923\n",
       "d2v_129                   0.001904\n",
       "d2v_292                   0.001902\n",
       "d2v_101                   0.001899\n",
       "d2v_273                   0.001894\n",
       "d2v_59                    0.001893\n",
       "d2v_23                    0.001890\n",
       "d2v_47                    0.001874\n",
       "d2v_159                   0.001871\n",
       "d2v_4                     0.001867\n",
       "d2v_31                    0.001855\n",
       "d2v_233                   0.001842\n",
       "d2v_86                    0.001841\n",
       "d2v_133                   0.001838\n",
       "d2v_209                   0.001831\n",
       "d2v_152                   0.001826\n",
       "d2v_46                    0.001824\n",
       "d2v_75                    0.001818\n",
       "d2v_1                     0.001818\n",
       "d2v_20                    0.001816\n",
       "d2v_112                   0.001808\n",
       "d2v_136                   0.001783\n",
       "d2v_118                   0.001778\n",
       "d2v_35                    0.001772\n",
       "d2v_106                   0.001747\n",
       "d2v_190                   0.001745\n",
       "d2v_104                   0.001742\n",
       "d2v_284                   0.001740\n",
       "d2v_205                   0.001733\n",
       "d2v_77                    0.001733\n",
       "d2v_107                   0.001731\n",
       "d2v_3                     0.001729\n",
       "d2v_45                    0.001727\n",
       "d2v_183                   0.001725\n",
       "d2v_80                    0.001723\n",
       "d2v_114                   0.001723\n",
       "d2v_291                   0.001720\n",
       "d2v_156                   0.001713\n",
       "d2v_153                   0.001712\n",
       "d2v_102                   0.001710\n",
       "d2v_219                   0.001706\n",
       "d2v_17                    0.001703\n",
       "d2v_257                   0.001702\n",
       "d2v_60                    0.001697\n",
       "d2v_142                   0.001696\n",
       "d2v_121                   0.001693\n",
       "d2v_174                   0.001683\n",
       "d2v_81                    0.001683\n",
       "d2v_201                   0.001658\n",
       "d2v_187                   0.001657\n",
       "d2v_272                   0.001657\n",
       "d2v_160                   0.001656\n",
       "d2v_168                   0.001655\n",
       "d2v_87                    0.001652\n",
       "d2v_223                   0.001647\n",
       "d2v_239                   0.001646\n",
       "d2v_141                   0.001641\n",
       "d2v_224                   0.001637\n",
       "d2v_110                   0.001632\n",
       "d2v_79                    0.001626\n",
       "d2v_243                   0.001621\n",
       "d2v_78                    0.001621\n",
       "d2v_34                    0.001619\n",
       "d2v_242                   0.001618\n",
       "d2v_91                    0.001614\n",
       "d2v_202                   0.001613\n",
       "d2v_245                   0.001613\n",
       "d2v_14                    0.001604\n",
       "d2v_62                    0.001604\n",
       "d2v_58                    0.001603\n",
       "d2v_286                   0.001601\n",
       "d2v_279                   0.001600\n",
       "d2v_193                   0.001592\n",
       "d2v_18                    0.001591\n",
       "d2v_218                   0.001588\n",
       "d2v_271                   0.001588\n",
       "d2v_5                     0.001583\n",
       "d2v_294                   0.001580\n",
       "d2v_231                   0.001578\n",
       "d2v_42                    0.001576\n",
       "d2v_252                   0.001573\n",
       "d2v_137                   0.001573\n",
       "d2v_134                   0.001567\n",
       "d2v_179                   0.001567\n",
       "d2v_65                    0.001565\n",
       "d2v_280                   0.001565\n",
       "d2v_287                   0.001565\n",
       "d2v_2                     0.001562\n",
       "d2v_99                    0.001562\n",
       "d2v_53                    0.001562\n",
       "d2v_204                   0.001559\n",
       "d2v_57                    0.001553\n",
       "d2v_210                   0.001547\n",
       "d2v_173                   0.001546\n",
       "d2v_49                    0.001543\n",
       "d2v_270                   0.001539\n",
       "d2v_267                   0.001531\n",
       "d2v_151                   0.001525\n",
       "d2v_290                   0.001525\n",
       "d2v_208                   0.001524\n",
       "d2v_116                   0.001524\n",
       "d2v_255                   0.001523\n",
       "d2v_122                   0.001520\n",
       "d2v_71                    0.001518\n",
       "d2v_248                   0.001514\n",
       "d2v_76                    0.001513\n",
       "d2v_263                   0.001512\n",
       "d2v_105                   0.001509\n",
       "d2v_264                   0.001507\n",
       "d2v_230                   0.001507\n",
       "d2v_33                    0.001505\n",
       "d2v_275                   0.001505\n",
       "d2v_108                   0.001500\n",
       "d2v_195                   0.001498\n",
       "d2v_289                   0.001496\n",
       "d2v_206                   0.001495\n",
       "d2v_266                   0.001495\n",
       "d2v_285                   0.001491\n",
       "d2v_258                   0.001485\n",
       "d2v_200                   0.001483\n",
       "d2v_234                   0.001482\n",
       "d2v_40                    0.001478\n",
       "d2v_166                   0.001477\n",
       "d2v_246                   0.001475\n",
       "d2v_88                    0.001473\n",
       "d2v_175                   0.001471\n",
       "d2v_19                    0.001463\n",
       "d2v_12                    0.001456\n",
       "d2v_145                   0.001451\n",
       "d2v_132                   0.001447\n",
       "d2v_146                   0.001446\n",
       "d2v_207                   0.001439\n",
       "d2v_278                   0.001435\n",
       "d2v_176                   0.001434\n",
       "d2v_297                   0.001434\n",
       "d2v_299                   0.001426\n",
       "d2v_268                   0.001425\n",
       "d2v_251                   0.001424\n",
       "d2v_28                    0.001417\n",
       "d2v_221                   0.001414\n",
       "d2v_29                    0.001409\n",
       "d2v_288                   0.001409\n",
       "d2v_177                   0.001404\n",
       "d2v_191                   0.001404\n",
       "d2v_66                    0.001402\n",
       "d2v_70                    0.001402\n",
       "d2v_281                   0.001400\n",
       "d2v_237                   0.001399\n",
       "d2v_259                   0.001399\n",
       "d2v_30                    0.001397\n",
       "d2v_27                    0.001396\n",
       "d2v_181                   0.001394\n",
       "d2v_74                    0.001394\n",
       "d2v_113                   0.001394\n",
       "d2v_97                    0.001388\n",
       "d2v_139                   0.001385\n",
       "d2v_100                   0.001383\n",
       "d2v_298                   0.001375\n",
       "d2v_269                   0.001362\n",
       "d2v_300                   0.001358\n",
       "d2v_9                     0.001356\n",
       "d2v_293                   0.001354\n",
       "d2v_260                   0.001350\n",
       "d2v_161                   0.001346\n",
       "d2v_8                     0.001339\n",
       "d2v_165                   0.001336\n",
       "d2v_131                   0.001323\n",
       "d2v_171                   0.001322\n",
       "d2v_36                    0.001317\n",
       "d2v_227                   0.001317\n",
       "d2v_41                    0.001316\n",
       "d2v_98                    0.001304\n",
       "d2v_143                   0.001302\n",
       "d2v_212                   0.001292\n",
       "d2v_15                    0.001287\n",
       "d2v_274                   0.001280\n",
       "d2v_162                   0.001279\n",
       "d2v_52                    0.001278\n",
       "d2v_11                    0.001277\n",
       "d2v_13                    0.001275\n",
       "d2v_54                    0.001266\n",
       "d2v_203                   0.001260\n",
       "d2v_95                    0.001254\n",
       "d2v_241                   0.001253\n",
       "d2v_283                   0.001250\n",
       "d2v_125                   0.001243\n",
       "d2v_73                    0.001237\n",
       "d2v_184                   0.001234\n",
       "d2v_247                   0.001232\n",
       "d2v_63                    0.001221\n",
       "d2v_225                   0.001210\n",
       "d2v_69                    0.001209\n",
       "d2v_32                    0.001208\n",
       "d2v_16                    0.001206\n",
       "d2v_256                   0.001194\n",
       "d2v_84                    0.001177\n",
       "d2v_21                    0.001133\n",
       "d2v_94                    0.001127\n",
       "d2v_138                   0.001117\n",
       "d2v_150                   0.001105\n",
       "d2v_249                   0.001055\n",
       "published_on_day          0.001035\n",
       "d2v_198                   0.000937\n",
       "video_count               0.000114"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_all(pd.DataFrame((i for i in classifiers[0].feature_importances_), index=data.train.features.columns, columns=['importance']).sort_values(by=['importance'], ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train.y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
