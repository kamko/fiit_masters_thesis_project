{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlalchemy\n",
    "import gensim\n",
    "import logging\n",
    "\n",
    "import common\n",
    "import util\n",
    "importlib.reload(common)\n",
    "importlib.reload(util)\n",
    "\n",
    "from common import create_engine\n",
    "from common import display_all\n",
    "from common import figsize\n",
    "from common import save_df, load_df\n",
    "from common import save_session, load_session\n",
    "\n",
    "from util import show_importances\n",
    "from util import split_X_y_all, split_X_y, split_data\n",
    "from util import empty_features, column_feature, str_contains\n",
    "\n",
    "from pbar import Pbar\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "\n",
    "register_matplotlib_converters() # converters e.g. for datetime in plots\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 123\n",
    "np_random = np.random.RandomState(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_df('final_data.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>perex</th>\n",
       "      <th>body</th>\n",
       "      <th>published_at</th>\n",
       "      <th>extracted_at</th>\n",
       "      <th>source_id</th>\n",
       "      <th>category</th>\n",
       "      <th>other_info</th>\n",
       "      <th>image_count</th>\n",
       "      <th>...</th>\n",
       "      <th>fb_ad_5_comment_count</th>\n",
       "      <th>fb_ad_6_comment_count</th>\n",
       "      <th>fb_ad_7_comment_count</th>\n",
       "      <th>fb_ad_8_comment_count</th>\n",
       "      <th>fb_ad_9_comment_count</th>\n",
       "      <th>fb_ad_10_comment_count</th>\n",
       "      <th>fb_ad_11_comment_count</th>\n",
       "      <th>fb_ad_12_comment_count</th>\n",
       "      <th>fb_ad_13_comment_count</th>\n",
       "      <th>fb_ad_14_comment_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>url</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>https://naturalnewsblogs.com/sugar-is-not-sweet/</td>\n",
       "      <td>430166</td>\n",
       "      <td>Sugar is not sweet</td>\n",
       "      <td>&lt;p&gt;Heart disease is the leading cause of death...</td>\n",
       "      <td>Heart disease is the leading cause of death in...</td>\n",
       "      <td>2019-10-14 17:14:23</td>\n",
       "      <td>2019-10-15 03:54:24.343870</td>\n",
       "      <td>142</td>\n",
       "      <td>[Health]</td>\n",
       "      <td>{'tags': [], 'updated_at': '2019-10-14T17:14:24'}</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>https://naturalnewsblogs.com/how-fluoride-a-toxin-got-in-our-water-and-iodine-a-critical-nutrient-disappeared-from-medical-school-textbooks/</td>\n",
       "      <td>430168</td>\n",
       "      <td>How Fluoride (a toxin) got in our water, and I...</td>\n",
       "      <td>&lt;p&gt;If you were a woman with painful, cystic br...</td>\n",
       "      <td>If you were a woman with painful, cystic breas...</td>\n",
       "      <td>2019-10-14 17:46:13</td>\n",
       "      <td>2019-10-15 03:54:24.807962</td>\n",
       "      <td>142</td>\n",
       "      <td>[Health, Science, Videos, Fluoride, Medicine, ...</td>\n",
       "      <td>{'tags': ['\"The Iodine Crisis\"', 'brominated f...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>https://www.healthnutnews.com/vitamin-a-can-save-your-skin/</td>\n",
       "      <td>430178</td>\n",
       "      <td>Vitamin A Can Save Your Skin</td>\n",
       "      <td>&lt;p&gt;Written by Joseph Mercola, D.O., Ph.D. Stor...</td>\n",
       "      <td>\\n\\n\\nWritten by Joseph Mercola, D.O., Ph.D.\\n...</td>\n",
       "      <td>2019-10-14 15:35:19</td>\n",
       "      <td>2019-10-15 05:45:32.471265</td>\n",
       "      <td>176</td>\n",
       "      <td>[Health, Food]</td>\n",
       "      <td>{'tags': ['Astaxanthin', 'dangers of sunscreen...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>https://www.healthnutnews.com/ny-times-in-the-pancreas-common-fungi-may-drive-cancer/</td>\n",
       "      <td>430180</td>\n",
       "      <td>NY Times: In the Pancreas, Common Fungi May Dr...</td>\n",
       "      <td>&lt;p&gt;By now, you&amp;#8217;ve probably heard that yo...</td>\n",
       "      <td>By now, you’ve probably heard that your body i...</td>\n",
       "      <td>2019-10-14 21:49:41</td>\n",
       "      <td>2019-10-15 05:45:35.141698</td>\n",
       "      <td>176</td>\n",
       "      <td>[Health]</td>\n",
       "      <td>{'tags': ['bacteria', 'digestive enzymes', 'fu...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>https://hsionline.com/2019/10/14/federal-crackdown-milk-trick/</td>\n",
       "      <td>430181</td>\n",
       "      <td>Federal CRACKDOWN suppresses mind-sharpening b...</td>\n",
       "      <td>&lt;p&gt;You drive over to one of those “superstores...</td>\n",
       "      <td>You drive over to one of those “superstores”… ...</td>\n",
       "      <td>2019-10-14 18:00:21</td>\n",
       "      <td>2019-10-15 05:58:25.540033</td>\n",
       "      <td>177</td>\n",
       "      <td>[Memory, Facebook, eAlert News]</td>\n",
       "      <td>{'tags': ['Alzheimer’s'], 'updated_at': '2019-...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        id  \\\n",
       "url                                                          \n",
       "https://naturalnewsblogs.com/sugar-is-not-sweet/    430166   \n",
       "https://naturalnewsblogs.com/how-fluoride-a-tox...  430168   \n",
       "https://www.healthnutnews.com/vitamin-a-can-sav...  430178   \n",
       "https://www.healthnutnews.com/ny-times-in-the-p...  430180   \n",
       "https://hsionline.com/2019/10/14/federal-crackd...  430181   \n",
       "\n",
       "                                                                                                title  \\\n",
       "url                                                                                                     \n",
       "https://naturalnewsblogs.com/sugar-is-not-sweet/                                   Sugar is not sweet   \n",
       "https://naturalnewsblogs.com/how-fluoride-a-tox...  How Fluoride (a toxin) got in our water, and I...   \n",
       "https://www.healthnutnews.com/vitamin-a-can-sav...                       Vitamin A Can Save Your Skin   \n",
       "https://www.healthnutnews.com/ny-times-in-the-p...  NY Times: In the Pancreas, Common Fungi May Dr...   \n",
       "https://hsionline.com/2019/10/14/federal-crackd...  Federal CRACKDOWN suppresses mind-sharpening b...   \n",
       "\n",
       "                                                                                                perex  \\\n",
       "url                                                                                                     \n",
       "https://naturalnewsblogs.com/sugar-is-not-sweet/    <p>Heart disease is the leading cause of death...   \n",
       "https://naturalnewsblogs.com/how-fluoride-a-tox...  <p>If you were a woman with painful, cystic br...   \n",
       "https://www.healthnutnews.com/vitamin-a-can-sav...  <p>Written by Joseph Mercola, D.O., Ph.D. Stor...   \n",
       "https://www.healthnutnews.com/ny-times-in-the-p...  <p>By now, you&#8217;ve probably heard that yo...   \n",
       "https://hsionline.com/2019/10/14/federal-crackd...  <p>You drive over to one of those “superstores...   \n",
       "\n",
       "                                                                                                 body  \\\n",
       "url                                                                                                     \n",
       "https://naturalnewsblogs.com/sugar-is-not-sweet/    Heart disease is the leading cause of death in...   \n",
       "https://naturalnewsblogs.com/how-fluoride-a-tox...  If you were a woman with painful, cystic breas...   \n",
       "https://www.healthnutnews.com/vitamin-a-can-sav...  \\n\\n\\nWritten by Joseph Mercola, D.O., Ph.D.\\n...   \n",
       "https://www.healthnutnews.com/ny-times-in-the-p...  By now, you’ve probably heard that your body i...   \n",
       "https://hsionline.com/2019/10/14/federal-crackd...  You drive over to one of those “superstores”… ...   \n",
       "\n",
       "                                                          published_at  \\\n",
       "url                                                                      \n",
       "https://naturalnewsblogs.com/sugar-is-not-sweet/   2019-10-14 17:14:23   \n",
       "https://naturalnewsblogs.com/how-fluoride-a-tox... 2019-10-14 17:46:13   \n",
       "https://www.healthnutnews.com/vitamin-a-can-sav... 2019-10-14 15:35:19   \n",
       "https://www.healthnutnews.com/ny-times-in-the-p... 2019-10-14 21:49:41   \n",
       "https://hsionline.com/2019/10/14/federal-crackd... 2019-10-14 18:00:21   \n",
       "\n",
       "                                                                 extracted_at  \\\n",
       "url                                                                             \n",
       "https://naturalnewsblogs.com/sugar-is-not-sweet/   2019-10-15 03:54:24.343870   \n",
       "https://naturalnewsblogs.com/how-fluoride-a-tox... 2019-10-15 03:54:24.807962   \n",
       "https://www.healthnutnews.com/vitamin-a-can-sav... 2019-10-15 05:45:32.471265   \n",
       "https://www.healthnutnews.com/ny-times-in-the-p... 2019-10-15 05:45:35.141698   \n",
       "https://hsionline.com/2019/10/14/federal-crackd... 2019-10-15 05:58:25.540033   \n",
       "\n",
       "                                                    source_id  \\\n",
       "url                                                             \n",
       "https://naturalnewsblogs.com/sugar-is-not-sweet/          142   \n",
       "https://naturalnewsblogs.com/how-fluoride-a-tox...        142   \n",
       "https://www.healthnutnews.com/vitamin-a-can-sav...        176   \n",
       "https://www.healthnutnews.com/ny-times-in-the-p...        176   \n",
       "https://hsionline.com/2019/10/14/federal-crackd...        177   \n",
       "\n",
       "                                                                                             category  \\\n",
       "url                                                                                                     \n",
       "https://naturalnewsblogs.com/sugar-is-not-sweet/                                             [Health]   \n",
       "https://naturalnewsblogs.com/how-fluoride-a-tox...  [Health, Science, Videos, Fluoride, Medicine, ...   \n",
       "https://www.healthnutnews.com/vitamin-a-can-sav...                                     [Health, Food]   \n",
       "https://www.healthnutnews.com/ny-times-in-the-p...                                           [Health]   \n",
       "https://hsionline.com/2019/10/14/federal-crackd...                    [Memory, Facebook, eAlert News]   \n",
       "\n",
       "                                                                                           other_info  \\\n",
       "url                                                                                                     \n",
       "https://naturalnewsblogs.com/sugar-is-not-sweet/    {'tags': [], 'updated_at': '2019-10-14T17:14:24'}   \n",
       "https://naturalnewsblogs.com/how-fluoride-a-tox...  {'tags': ['\"The Iodine Crisis\"', 'brominated f...   \n",
       "https://www.healthnutnews.com/vitamin-a-can-sav...  {'tags': ['Astaxanthin', 'dangers of sunscreen...   \n",
       "https://www.healthnutnews.com/ny-times-in-the-p...  {'tags': ['bacteria', 'digestive enzymes', 'fu...   \n",
       "https://hsionline.com/2019/10/14/federal-crackd...  {'tags': ['Alzheimer’s'], 'updated_at': '2019-...   \n",
       "\n",
       "                                                    image_count  ...  \\\n",
       "url                                                              ...   \n",
       "https://naturalnewsblogs.com/sugar-is-not-sweet/              1  ...   \n",
       "https://naturalnewsblogs.com/how-fluoride-a-tox...            1  ...   \n",
       "https://www.healthnutnews.com/vitamin-a-can-sav...            1  ...   \n",
       "https://www.healthnutnews.com/ny-times-in-the-p...            1  ...   \n",
       "https://hsionline.com/2019/10/14/federal-crackd...            0  ...   \n",
       "\n",
       "                                                    fb_ad_5_comment_count  \\\n",
       "url                                                                         \n",
       "https://naturalnewsblogs.com/sugar-is-not-sweet/                      NaN   \n",
       "https://naturalnewsblogs.com/how-fluoride-a-tox...                    NaN   \n",
       "https://www.healthnutnews.com/vitamin-a-can-sav...                    NaN   \n",
       "https://www.healthnutnews.com/ny-times-in-the-p...                    NaN   \n",
       "https://hsionline.com/2019/10/14/federal-crackd...                    NaN   \n",
       "\n",
       "                                                   fb_ad_6_comment_count  \\\n",
       "url                                                                        \n",
       "https://naturalnewsblogs.com/sugar-is-not-sweet/                     NaN   \n",
       "https://naturalnewsblogs.com/how-fluoride-a-tox...                   NaN   \n",
       "https://www.healthnutnews.com/vitamin-a-can-sav...                   NaN   \n",
       "https://www.healthnutnews.com/ny-times-in-the-p...                   NaN   \n",
       "https://hsionline.com/2019/10/14/federal-crackd...                   NaN   \n",
       "\n",
       "                                                    fb_ad_7_comment_count  \\\n",
       "url                                                                         \n",
       "https://naturalnewsblogs.com/sugar-is-not-sweet/                      NaN   \n",
       "https://naturalnewsblogs.com/how-fluoride-a-tox...                    NaN   \n",
       "https://www.healthnutnews.com/vitamin-a-can-sav...                    NaN   \n",
       "https://www.healthnutnews.com/ny-times-in-the-p...                    NaN   \n",
       "https://hsionline.com/2019/10/14/federal-crackd...                    NaN   \n",
       "\n",
       "                                                    fb_ad_8_comment_count  \\\n",
       "url                                                                         \n",
       "https://naturalnewsblogs.com/sugar-is-not-sweet/                      NaN   \n",
       "https://naturalnewsblogs.com/how-fluoride-a-tox...                    NaN   \n",
       "https://www.healthnutnews.com/vitamin-a-can-sav...                    NaN   \n",
       "https://www.healthnutnews.com/ny-times-in-the-p...                    NaN   \n",
       "https://hsionline.com/2019/10/14/federal-crackd...                    NaN   \n",
       "\n",
       "                                                    fb_ad_9_comment_count  \\\n",
       "url                                                                         \n",
       "https://naturalnewsblogs.com/sugar-is-not-sweet/                      NaN   \n",
       "https://naturalnewsblogs.com/how-fluoride-a-tox...                    NaN   \n",
       "https://www.healthnutnews.com/vitamin-a-can-sav...                    NaN   \n",
       "https://www.healthnutnews.com/ny-times-in-the-p...                    NaN   \n",
       "https://hsionline.com/2019/10/14/federal-crackd...                    NaN   \n",
       "\n",
       "                                                    fb_ad_10_comment_count  \\\n",
       "url                                                                          \n",
       "https://naturalnewsblogs.com/sugar-is-not-sweet/                       NaN   \n",
       "https://naturalnewsblogs.com/how-fluoride-a-tox...                     NaN   \n",
       "https://www.healthnutnews.com/vitamin-a-can-sav...                     NaN   \n",
       "https://www.healthnutnews.com/ny-times-in-the-p...                     NaN   \n",
       "https://hsionline.com/2019/10/14/federal-crackd...                     NaN   \n",
       "\n",
       "                                                    fb_ad_11_comment_count  \\\n",
       "url                                                                          \n",
       "https://naturalnewsblogs.com/sugar-is-not-sweet/                       NaN   \n",
       "https://naturalnewsblogs.com/how-fluoride-a-tox...                     NaN   \n",
       "https://www.healthnutnews.com/vitamin-a-can-sav...                     NaN   \n",
       "https://www.healthnutnews.com/ny-times-in-the-p...                     NaN   \n",
       "https://hsionline.com/2019/10/14/federal-crackd...                     NaN   \n",
       "\n",
       "                                                    fb_ad_12_comment_count  \\\n",
       "url                                                                          \n",
       "https://naturalnewsblogs.com/sugar-is-not-sweet/                       NaN   \n",
       "https://naturalnewsblogs.com/how-fluoride-a-tox...                     NaN   \n",
       "https://www.healthnutnews.com/vitamin-a-can-sav...                     NaN   \n",
       "https://www.healthnutnews.com/ny-times-in-the-p...                     NaN   \n",
       "https://hsionline.com/2019/10/14/federal-crackd...                     NaN   \n",
       "\n",
       "                                                   fb_ad_13_comment_count  \\\n",
       "url                                                                         \n",
       "https://naturalnewsblogs.com/sugar-is-not-sweet/                      NaN   \n",
       "https://naturalnewsblogs.com/how-fluoride-a-tox...                    NaN   \n",
       "https://www.healthnutnews.com/vitamin-a-can-sav...                    NaN   \n",
       "https://www.healthnutnews.com/ny-times-in-the-p...                    NaN   \n",
       "https://hsionline.com/2019/10/14/federal-crackd...                    NaN   \n",
       "\n",
       "                                                    fb_ad_14_comment_count  \n",
       "url                                                                         \n",
       "https://naturalnewsblogs.com/sugar-is-not-sweet/                       NaN  \n",
       "https://naturalnewsblogs.com/how-fluoride-a-tox...                     NaN  \n",
       "https://www.healthnutnews.com/vitamin-a-can-sav...                     NaN  \n",
       "https://www.healthnutnews.com/ny-times-in-the-p...                     NaN  \n",
       "https://hsionline.com/2019/10/14/federal-crackd...                     NaN  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3435 entries, https://naturalnewsblogs.com/sugar-is-not-sweet/ to https://www.medicaldaily.com/diarrhea-could-be-first-sign-coronavirus-infection-study-says-450722\n",
      "Data columns (total 69 columns):\n",
      "id                         3435 non-null int64\n",
      "title                      3435 non-null object\n",
      "perex                      2646 non-null object\n",
      "body                       3430 non-null object\n",
      "published_at               3435 non-null datetime64[ns]\n",
      "extracted_at               3435 non-null datetime64[ns]\n",
      "source_id                  3435 non-null int64\n",
      "category                   2085 non-null object\n",
      "other_info                 3433 non-null object\n",
      "image_count                3435 non-null int64\n",
      "video_count                3435 non-null int64\n",
      "veracity                   3435 non-null object\n",
      "claims_false               3435 non-null int64\n",
      "claims_mixture             3435 non-null int64\n",
      "claims_mostly_false        3435 non-null int64\n",
      "claims_mostly_true         3435 non-null int64\n",
      "claims_true                3435 non-null int64\n",
      "claims_unknown             3435 non-null int64\n",
      "author_name                3435 non-null object\n",
      "source_id                  3435 non-null int64\n",
      "source_name                3435 non-null object\n",
      "source_url                 3435 non-null object\n",
      "source_type                3435 non-null object\n",
      "source_is_reliable         3435 non-null int64\n",
      "fb_ad_0_reaction_count     1255 non-null float64\n",
      "fb_ad_1_reaction_count     2096 non-null float64\n",
      "fb_ad_2_reaction_count     2348 non-null float64\n",
      "fb_ad_3_reaction_count     2531 non-null float64\n",
      "fb_ad_4_reaction_count     2681 non-null float64\n",
      "fb_ad_5_reaction_count     2746 non-null float64\n",
      "fb_ad_6_reaction_count     2806 non-null float64\n",
      "fb_ad_7_reaction_count     2865 non-null float64\n",
      "fb_ad_8_reaction_count     2905 non-null float64\n",
      "fb_ad_9_reaction_count     2966 non-null float64\n",
      "fb_ad_10_reaction_count    3044 non-null float64\n",
      "fb_ad_11_reaction_count    3114 non-null float64\n",
      "fb_ad_12_reaction_count    3126 non-null float64\n",
      "fb_ad_13_reaction_count    3115 non-null float64\n",
      "fb_ad_14_reaction_count    3114 non-null float64\n",
      "fb_ad_0_share_count        1255 non-null float64\n",
      "fb_ad_1_share_count        2096 non-null float64\n",
      "fb_ad_2_share_count        2348 non-null float64\n",
      "fb_ad_3_share_count        2531 non-null float64\n",
      "fb_ad_4_share_count        2681 non-null float64\n",
      "fb_ad_5_share_count        2746 non-null float64\n",
      "fb_ad_6_share_count        2806 non-null float64\n",
      "fb_ad_7_share_count        2865 non-null float64\n",
      "fb_ad_8_share_count        2905 non-null float64\n",
      "fb_ad_9_share_count        2966 non-null float64\n",
      "fb_ad_10_share_count       3044 non-null float64\n",
      "fb_ad_11_share_count       3114 non-null float64\n",
      "fb_ad_12_share_count       3126 non-null float64\n",
      "fb_ad_13_share_count       3115 non-null float64\n",
      "fb_ad_14_share_count       3114 non-null float64\n",
      "fb_ad_0_comment_count      1255 non-null float64\n",
      "fb_ad_1_comment_count      2096 non-null float64\n",
      "fb_ad_2_comment_count      2348 non-null float64\n",
      "fb_ad_3_comment_count      2531 non-null float64\n",
      "fb_ad_4_comment_count      2681 non-null float64\n",
      "fb_ad_5_comment_count      2746 non-null float64\n",
      "fb_ad_6_comment_count      2806 non-null float64\n",
      "fb_ad_7_comment_count      2865 non-null float64\n",
      "fb_ad_8_comment_count      2905 non-null float64\n",
      "fb_ad_9_comment_count      2966 non-null float64\n",
      "fb_ad_10_comment_count     3044 non-null float64\n",
      "fb_ad_11_comment_count     3114 non-null float64\n",
      "fb_ad_12_comment_count     3126 non-null float64\n",
      "fb_ad_13_comment_count     3115 non-null float64\n",
      "fb_ad_14_comment_count     3114 non-null float64\n",
      "dtypes: datetime64[ns](2), float64(45), int64(12), object(10)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rozdelenie hodnot popularity do 5 skupin\n",
    "\n",
    "- `0 - 0.5`\n",
    "- `0.5 - 0.75`\n",
    "- `0.75 - 0.9`\n",
    "- `0.9 - 0.95`\n",
    "- `0.95 - 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_labels(df, quantiles, column='fb_popularity'):\n",
    "    df = df.copy()\n",
    "    label_str = f'{column}_label'\n",
    "    \n",
    "    df[label_str] = -1\n",
    "    \n",
    "    label = 1    \n",
    "    for i in range(len(quantiles) - 1):\n",
    "        low = df[column].quantile(quantiles[i])\n",
    "        high = df[column].quantile(quantiles[i + 1])\n",
    "        \n",
    "        df.loc[(low <= df[column]) & (df[column] <= high), label_str] = int(label)\n",
    "        \n",
    "        label += 1\n",
    "    df = df.drop(columns=[column])    \n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00         0.0\n",
      "0.50        28.0\n",
      "0.75       227.0\n",
      "0.90       995.0\n",
      "0.95      2392.5\n",
      "1.00    901984.0\n",
      "Name: fb_ad_13_reaction_count, dtype: float64\n",
      "0.00         0.0\n",
      "0.50         3.0\n",
      "0.75        40.0\n",
      "0.90       234.0\n",
      "0.95       648.0\n",
      "1.00    140695.0\n",
      "Name: fb_ad_13_comment_count, dtype: float64\n",
      "0.00         0.0\n",
      "0.50        31.0\n",
      "0.75       132.5\n",
      "0.90       472.0\n",
      "0.95       990.5\n",
      "1.00    168585.0\n",
      "Name: fb_ad_13_share_count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "quantiles = [\n",
    "    0,\n",
    "    .50,\n",
    "    .75,\n",
    "    .90,\n",
    "    .95,\n",
    "    1\n",
    "]\n",
    "\n",
    "cols = [\n",
    "    'fb_ad_13_reaction_count',\n",
    "    'fb_ad_13_comment_count',\n",
    "    'fb_ad_13_share_count'    \n",
    "]\n",
    "\n",
    "for i in cols:\n",
    "    print(df[i].quantile(quantiles))\n",
    "    df = add_labels(df, quantiles, column=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pri jednotlivych zlozkach sme pri tomto rozdeleni nasli len 4 skupiny (lebo 1 == 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jednoducha heuristika: ak je zdroj nedoveryhodny tak aj clanok je nedoveryhodny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_fake_news_label'] = df.source_is_reliable.replace({0:1, 1:0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear body, perex, etc from html...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows without body\n",
    "df = df[~df.body.isnull()]\n",
    "df = df[~df.title.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "\n",
    "def clear_text(text):\n",
    "    if text is None:\n",
    "        return ''\n",
    "\n",
    "    text = BeautifulSoup(text, features='html.parser').text\n",
    "    text = text.lower()\n",
    "    text = text.replace('\\r', '')\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = unicodedata.normalize('NFKD', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def clear_column(df, column):\n",
    "    df[column] = df[column].apply(clear_text)\n",
    "\n",
    "def clear_columns(df, columns):\n",
    "    pbar_conf = {\n",
    "        'refresh_rate': 1,\n",
    "        'action_names': columns\n",
    "    }\n",
    "        \n",
    "    for c in Pbar(columns, **pbar_conf):\n",
    "        clear_column(df, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] -- 3 / 3 -- (finished)2 / 33\n"
     ]
    }
   ],
   "source": [
    "clear_columns(df, ['title', 'perex', 'body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = list(filter(lambda x: x.endswith('_label'), df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ln in label_names:\n",
    "    df[ln] = pd.to_numeric(df[ln])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\j\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# labely\n",
    "labels_df = pd.concat([labels_df] + [df[label_name] for label_name in label_names], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3430 entries, https://naturalnewsblogs.com/sugar-is-not-sweet/ to https://www.medicaldaily.com/diarrhea-could-be-first-sign-coronavirus-infection-study-says-450722\n",
      "Data columns (total 70 columns):\n",
      "id                         3430 non-null int64\n",
      "title                      3430 non-null object\n",
      "perex                      3430 non-null object\n",
      "body                       3430 non-null object\n",
      "published_at               3430 non-null datetime64[ns]\n",
      "extracted_at               3430 non-null datetime64[ns]\n",
      "source_id                  3430 non-null int64\n",
      "category                   2080 non-null object\n",
      "other_info                 3428 non-null object\n",
      "image_count                3430 non-null int64\n",
      "video_count                3430 non-null int64\n",
      "veracity                   3430 non-null object\n",
      "claims_false               3430 non-null int64\n",
      "claims_mixture             3430 non-null int64\n",
      "claims_mostly_false        3430 non-null int64\n",
      "claims_mostly_true         3430 non-null int64\n",
      "claims_true                3430 non-null int64\n",
      "claims_unknown             3430 non-null int64\n",
      "author_name                3430 non-null object\n",
      "source_id                  3430 non-null int64\n",
      "source_name                3430 non-null object\n",
      "source_url                 3430 non-null object\n",
      "source_type                3430 non-null object\n",
      "source_is_reliable         3430 non-null int64\n",
      "fb_ad_0_reaction_count     1252 non-null float64\n",
      "fb_ad_1_reaction_count     2092 non-null float64\n",
      "fb_ad_2_reaction_count     2344 non-null float64\n",
      "fb_ad_3_reaction_count     2527 non-null float64\n",
      "fb_ad_4_reaction_count     2677 non-null float64\n",
      "fb_ad_5_reaction_count     2742 non-null float64\n",
      "fb_ad_6_reaction_count     2802 non-null float64\n",
      "fb_ad_7_reaction_count     2862 non-null float64\n",
      "fb_ad_8_reaction_count     2902 non-null float64\n",
      "fb_ad_9_reaction_count     2963 non-null float64\n",
      "fb_ad_10_reaction_count    3041 non-null float64\n",
      "fb_ad_11_reaction_count    3110 non-null float64\n",
      "fb_ad_12_reaction_count    3122 non-null float64\n",
      "fb_ad_13_reaction_count    3111 non-null float64\n",
      "fb_ad_14_reaction_count    3110 non-null float64\n",
      "fb_ad_0_share_count        1252 non-null float64\n",
      "fb_ad_1_share_count        2092 non-null float64\n",
      "fb_ad_2_share_count        2344 non-null float64\n",
      "fb_ad_3_share_count        2527 non-null float64\n",
      "fb_ad_4_share_count        2677 non-null float64\n",
      "fb_ad_5_share_count        2742 non-null float64\n",
      "fb_ad_6_share_count        2802 non-null float64\n",
      "fb_ad_7_share_count        2862 non-null float64\n",
      "fb_ad_8_share_count        2902 non-null float64\n",
      "fb_ad_9_share_count        2963 non-null float64\n",
      "fb_ad_10_share_count       3041 non-null float64\n",
      "fb_ad_11_share_count       3110 non-null float64\n",
      "fb_ad_12_share_count       3122 non-null float64\n",
      "fb_ad_13_share_count       3111 non-null float64\n",
      "fb_ad_14_share_count       3110 non-null float64\n",
      "fb_ad_0_comment_count      1252 non-null float64\n",
      "fb_ad_1_comment_count      2092 non-null float64\n",
      "fb_ad_2_comment_count      2344 non-null float64\n",
      "fb_ad_3_comment_count      2527 non-null float64\n",
      "fb_ad_4_comment_count      2677 non-null float64\n",
      "fb_ad_5_comment_count      2742 non-null float64\n",
      "fb_ad_6_comment_count      2802 non-null float64\n",
      "fb_ad_7_comment_count      2862 non-null float64\n",
      "fb_ad_8_comment_count      2902 non-null float64\n",
      "fb_ad_9_comment_count      2963 non-null float64\n",
      "fb_ad_10_comment_count     3041 non-null float64\n",
      "fb_ad_11_comment_count     3110 non-null float64\n",
      "fb_ad_12_comment_count     3122 non-null float64\n",
      "fb_ad_13_comment_count     3111 non-null float64\n",
      "fb_ad_14_comment_count     3110 non-null float64\n",
      "is_fake_news_label         3430 non-null int64\n",
      "dtypes: datetime64[ns](2), float64(45), int64(13), object(10)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rozdelenie dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, validation = tuple(split_data(df, sizes=[2, 2, 1], shuffle=True, np_random=np_random))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1372, 1372, 686]\n"
     ]
    }
   ],
   "source": [
    "print([len(i) for i in [train,test,validation]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is_fake_news_label']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from textblob import TextBlob\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    doc = nlp(text, disable=['parser', 'tagger', 'ner'])\n",
    "    \n",
    "    res = []\n",
    "    for i in doc:\n",
    "        if i.is_stop:\n",
    "            continue\n",
    "        if i.is_punct:\n",
    "            continue\n",
    "            \n",
    "        res.append(str(i))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_basic_features(df):\n",
    "    cv = CountVectorizer()\n",
    "    data = cv.fit_transform(df.title)\n",
    "\n",
    "    res = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    res['title_word_count'] = data.sum(axis=1)\n",
    "    res['title_char_length'] = df.title.apply(lambda x: len(x))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perex_basic_features(df):\n",
    "    cv = CountVectorizer()\n",
    "    data = cv.fit_transform(df.perex)\n",
    "\n",
    "    res = pd.DataFrame(index=df.index)    \n",
    "    res['perex_word_count'] = data.sum(axis=1)\n",
    "    res['perex_char_length'] = df.perex.apply(lambda x: len(x))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_basic_features(df):\n",
    "    content_cv = CountVectorizer()\n",
    "    data = content_cv.fit_transform(df.body)\n",
    "\n",
    "    res = pd.DataFrame(index=df.index)    \n",
    "    res['content_word_count'] = data.sum(axis=1)\n",
    "    res['content_char_length'] = df.body.apply(lambda x: len(x))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def media_count_total(df):\n",
    "    res = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    res['media_count_total'] = df['image_count'] + df['video_count']\n",
    "    \n",
    "    return res\n",
    "    \n",
    "def media_count_image(df):\n",
    "    return column_feature(df, 'image_count')\n",
    "\n",
    "def media_count_video(df):\n",
    "    return column_feature(df, 'video_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def published_on_day(df):\n",
    "    res = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    res['published_on_day'] = df.published_at.dt.weekday + 1\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_collective_author(df):\n",
    "    \n",
    "    uniq_source_names = df.source_name.unique()\n",
    "    def make_a_guess(author_name):\n",
    "\n",
    "        return any((\n",
    "                    str_contains(author_name, 'admin', case=False),\n",
    "                    author_name.startswith('Neuroscience News Posts Science Research News Labs Universities Hospitals News Departments Around The World'),\n",
    "                    author_name in ['Neuroscience News',\n",
    "                                    'Wake Up World',\n",
    "                                    'Health Sciences Institute',\n",
    "                                    'REALdeal', \n",
    "                                    'nmheditor',\n",
    "                                    'The Mind Unleashed',\n",
    "                                    'Thinking Moms\\' Revolution',\n",
    "                                    'TheNewsDoctors',\n",
    "                                    'clnews',\n",
    "                                    'Associated Press',\n",
    "                                    'HealthDay',\n",
    "                                    'Infowars',\n",
    "                                    'Natural News Editors',\n",
    "                                    'https://www.facebook.com/WebMD',\n",
    "                                    'naturalnews', 'peakconsciousness', 'HealingwithoutHurting',\n",
    "                                    'HealthNutNews.com',\n",
    "                                   ],\n",
    "                    author_name.startswith('The Associated Press'),\n",
    "                    # ' and ' in author_name, # todo: je to kolektivny autor ak ich je len viac?\n",
    "                    author_name in uniq_source_names,   \n",
    "        ))\n",
    "    \n",
    "    res = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    res['is_collective_author'] = df.author_name.map(make_a_guess)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    Health\n",
       "1                                   Science\n",
       "2                                    Videos\n",
       "3                                  Fluoride\n",
       "4                                  Medicine\n",
       "                       ...                 \n",
       "428    d419034f-f7e3-5029-8dd9-67fd1f5cfeb7\n",
       "429    d258ff11-c795-5fdd-a013-d5c09188ed0f\n",
       "430    7f78d6ae-1132-5d03-a932-f47e31f30167\n",
       "431                         The Sacred Blog\n",
       "432    ddba18a3-9044-5ba1-8bcd-1e2535e604e6\n",
       "Length: 433, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(df.category.explode().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    title_basic_features,\n",
    "    perex_basic_features,\n",
    "    content_basic_features,\n",
    "    \n",
    "    media_count_total,\n",
    "    media_count_image,\n",
    "    media_count_video,\n",
    "    \n",
    "    published_on_day,\n",
    "    is_collective_author,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df):    \n",
    "    pbar_conf = {\n",
    "        'refresh_rate': 1,\n",
    "        'action_names': [i.__name__ for i in features]\n",
    "    }\n",
    "    \n",
    "    res = pd.DataFrame()\n",
    "    for feature_generator in Pbar(features, **pbar_conf):\n",
    "        res = pd.concat([res, feature_generator(df)], axis=1)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = split_X_y_all(train, test, validation, selected_label='is_fake_news_label', all_labels=label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=============                                     ] (processing: content_basic_features) -- 2 / 8"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-31 01:15:39,279 : INFO : NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] -- 8 / 8 -- (finished)tive_author) -- 7 / 8\n"
     ]
    }
   ],
   "source": [
    "data.train.features = add_features(data.train.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] -- 8 / 8 -- (finished)tive_author) -- 7 / 8 8\n"
     ]
    }
   ],
   "source": [
    "data.test.features = add_features(data.test.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] -- 8 / 8 -- (finished)tive_author) -- 7 / 8 8\n"
     ]
    }
   ],
   "source": [
    "data.validation.features = add_features(data.validation.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is_fake_news_label']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_to_file(data, file):\n",
    "    with open(file, 'w', encoding='utf-8') as f:\n",
    "        for i in Pbar(data):\n",
    "            f.write(f\"{' '.join(tokenize(i))}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 8 cores available\n"
     ]
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "print(f'>>> {cores} cores available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] -- 1372 / 1372 -- (finished)\n",
      "[==================================================] -- 1372 / 1372 -- (finished)\n",
      "[==================================================] -- 686 / 686 -- (finished)\n"
     ]
    }
   ],
   "source": [
    "tokenize_to_file(data.train.X.body, './data/train_body_tokenized.txt')\n",
    "tokenize_to_file(data.test.X.body, './data/test_body_tokenized.txt')\n",
    "tokenize_to_file(data.validation.X.body, './data/validation_body_tokenized.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-31 01:16:38,776 : INFO : collecting all words and their counts\n",
      "2020-03-31 01:16:38,778 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2020-03-31 01:16:38,963 : INFO : collected 35938 word types and 1372 unique tags from a corpus of 1372 examples and 619694 words\n",
      "2020-03-31 01:16:38,963 : INFO : Loading a fresh vocabulary\n",
      "2020-03-31 01:16:38,997 : INFO : effective_min_count=2 retains 21095 unique words (58% of original 35938, drops 14843)\n",
      "2020-03-31 01:16:38,998 : INFO : effective_min_count=2 leaves 604851 word corpus (97% of original 619694, drops 14843)\n",
      "2020-03-31 01:16:39,060 : INFO : deleting the raw counts dictionary of 35938 items\n",
      "2020-03-31 01:16:39,062 : INFO : sample=0.001 downsamples 16 most-common words\n",
      "2020-03-31 01:16:39,064 : INFO : downsampling leaves estimated 595804 word corpus (98.5% of prior 604851)\n",
      "2020-03-31 01:16:39,118 : INFO : estimated required memory for 21095 words and 300 dimensions: 62821900 bytes\n",
      "2020-03-31 01:16:39,119 : INFO : resetting layer weights\n",
      "2020-03-31 01:16:39,393 : INFO : training model with 8 workers on 21095 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-03-31 01:16:39,802 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-31 01:16:39,804 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-31 01:16:39,805 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-31 01:16:39,812 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-31 01:16:39,813 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-31 01:16:39,815 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-31 01:16:39,816 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-31 01:16:39,848 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-31 01:16:39,848 : INFO : EPOCH - 1 : training on 621304 raw words (598767 effective words) took 0.4s, 1377808 effective words/s\n",
      "2020-03-31 01:16:40,310 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-31 01:16:40,315 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-31 01:16:40,339 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-31 01:16:40,341 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-31 01:16:40,356 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-31 01:16:40,360 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-31 01:16:40,362 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-31 01:16:40,365 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-31 01:16:40,366 : INFO : EPOCH - 2 : training on 621304 raw words (598733 effective words) took 0.5s, 1294191 effective words/s\n",
      "2020-03-31 01:16:40,820 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-31 01:16:40,862 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-31 01:16:40,893 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-31 01:16:40,900 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-31 01:16:40,963 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-31 01:16:41,012 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-31 01:16:41,022 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-31 01:16:41,026 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-31 01:16:41,027 : INFO : EPOCH - 3 : training on 621304 raw words (598704 effective words) took 0.6s, 1003306 effective words/s\n",
      "2020-03-31 01:16:41,438 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-31 01:16:41,440 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-31 01:16:41,454 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-31 01:16:41,463 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-31 01:16:41,499 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-31 01:16:41,522 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-31 01:16:41,524 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-31 01:16:41,543 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-31 01:16:41,543 : INFO : EPOCH - 4 : training on 621304 raw words (598690 effective words) took 0.5s, 1277772 effective words/s\n",
      "2020-03-31 01:16:41,974 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-31 01:16:41,978 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-31 01:16:41,992 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-31 01:16:42,006 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-31 01:16:42,008 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-31 01:16:42,022 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-31 01:16:42,025 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-31 01:16:42,033 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-31 01:16:42,034 : INFO : EPOCH - 5 : training on 621304 raw words (598787 effective words) took 0.4s, 1358925 effective words/s\n",
      "2020-03-31 01:16:42,513 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-31 01:16:42,521 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-31 01:16:42,531 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-31 01:16:42,548 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-31 01:16:42,550 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-31 01:16:42,558 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-31 01:16:42,563 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-31 01:16:42,571 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-31 01:16:42,572 : INFO : EPOCH - 6 : training on 621304 raw words (598746 effective words) took 0.5s, 1240041 effective words/s\n",
      "2020-03-31 01:16:43,002 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-31 01:16:43,026 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-31 01:16:43,036 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-31 01:16:43,059 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-31 01:16:43,089 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-31 01:16:43,094 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-31 01:16:43,109 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-31 01:16:43,112 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-31 01:16:43,113 : INFO : EPOCH - 7 : training on 621304 raw words (598700 effective words) took 0.5s, 1231985 effective words/s\n",
      "2020-03-31 01:16:43,515 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-31 01:16:43,524 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-31 01:16:43,562 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-31 01:16:43,563 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-31 01:16:43,586 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-31 01:16:43,614 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-31 01:16:43,622 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-31 01:16:43,623 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-31 01:16:43,625 : INFO : EPOCH - 8 : training on 621304 raw words (598668 effective words) took 0.5s, 1317986 effective words/s\n",
      "2020-03-31 01:16:44,170 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-31 01:16:44,173 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-31 01:16:44,177 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-31 01:16:44,268 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-31 01:16:44,270 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-31 01:16:44,271 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-31 01:16:44,273 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-31 01:16:44,297 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-31 01:16:44,299 : INFO : EPOCH - 9 : training on 621304 raw words (598653 effective words) took 0.6s, 1016075 effective words/s\n",
      "2020-03-31 01:16:44,795 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-31 01:16:44,817 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-31 01:16:44,819 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-31 01:16:44,825 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-31 01:16:44,827 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-31 01:16:44,842 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-31 01:16:44,848 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-31 01:16:44,850 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-31 01:16:44,851 : INFO : EPOCH - 10 : training on 621304 raw words (598668 effective words) took 0.5s, 1198829 effective words/s\n",
      "2020-03-31 01:16:45,313 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-31 01:16:45,315 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-31 01:16:45,327 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-31 01:16:45,342 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-31 01:16:45,344 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-31 01:16:45,357 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-31 01:16:45,358 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-31 01:16:45,370 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-31 01:16:45,371 : INFO : EPOCH - 11 : training on 621304 raw words (598550 effective words) took 0.5s, 1206923 effective words/s\n",
      "2020-03-31 01:16:45,809 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-31 01:16:45,833 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-31 01:16:45,850 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-31 01:16:45,853 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-31 01:16:45,862 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-31 01:16:45,863 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-31 01:16:45,878 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-31 01:16:45,892 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-31 01:16:45,893 : INFO : EPOCH - 12 : training on 621304 raw words (598636 effective words) took 0.5s, 1278934 effective words/s\n",
      "2020-03-31 01:16:46,348 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-31 01:16:46,353 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-31 01:16:46,370 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-31 01:16:46,382 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-31 01:16:46,390 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-31 01:16:46,392 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-31 01:16:46,397 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-31 01:16:46,417 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-31 01:16:46,418 : INFO : EPOCH - 13 : training on 621304 raw words (598511 effective words) took 0.5s, 1275461 effective words/s\n",
      "2020-03-31 01:16:46,854 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-31 01:16:46,859 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-31 01:16:46,862 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-31 01:16:46,875 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-31 01:16:46,906 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-31 01:16:46,911 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-31 01:16:46,913 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-31 01:16:46,919 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-31 01:16:46,920 : INFO : EPOCH - 14 : training on 621304 raw words (598621 effective words) took 0.5s, 1325359 effective words/s\n",
      "2020-03-31 01:16:47,378 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-31 01:16:47,390 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-31 01:16:47,392 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-31 01:16:47,442 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-31 01:16:47,448 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-31 01:16:47,453 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-31 01:16:47,457 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-31 01:16:47,459 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-31 01:16:47,460 : INFO : EPOCH - 15 : training on 621304 raw words (598545 effective words) took 0.5s, 1227213 effective words/s\n",
      "2020-03-31 01:16:47,462 : INFO : training on a 9319560 raw words (8979979 effective words) took 8.1s, 1113063 effective words/s\n"
     ]
    }
   ],
   "source": [
    "d2v = Doc2Vec(corpus_file='./data/train_body_tokenized.txt', vector_size=300, min_count=2, epochs=15, workers=cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_d2v(d2v_model, data_file):\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    with open(data_file, 'r', encoding='utf-8') as f:\n",
    "        for i in Pbar(f.readlines()):\n",
    "            res.append(d2v_model.infer_vector(i.split(' '), steps=20, alpha=0.025)) \n",
    "    \n",
    "    return res\n",
    "\n",
    "def infer_for_df(df, d2v_model, data_file):\n",
    "    lst = infer_d2v(d2v_model, data_file)\n",
    "    d2v_df = pd.DataFrame(lst, index=df.index, columns=[f'd2v_{i}' for i in range(1, 301)] )\n",
    "    \n",
    "    return pd.concat([df, d2v_df], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] -- 1372 / 1372 -- (finished)\n"
     ]
    }
   ],
   "source": [
    "data.train.features = infer_for_df(data.train.features, d2v, './data/train_body_tokenized.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] -- 1372 / 1372 -- (finished)\n"
     ]
    }
   ],
   "source": [
    "data.test.features = infer_for_df(data.test.features, d2v, './data/test_body_tokenized.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(clf, data):\n",
    "    clf.fit(data.train.features, data.train.y)\n",
    "    return clf.predict(data.test.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train.features['media_count_total'] = pd.to_numeric(data.train.features['media_count_total'])\n",
    "data.train.features['image_count'] = pd.to_numeric(data.train.features['image_count'])\n",
    "data.train.features['video_count'] = pd.to_numeric(data.train.features['video_count'])\n",
    "\n",
    "data.test.features['media_count_total'] = pd.to_numeric(data.test.features['media_count_total'])\n",
    "data.test.features['image_count'] = pd.to_numeric(data.test.features['image_count'])\n",
    "data.test.features['video_count'] = pd.to_numeric(data.test.features['video_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train.features.drop(columns=['perex_word_count', 'perex_char_length'], inplace=True)\n",
    "data.test.features.drop(columns=['perex_word_count', 'perex_char_length'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train.y = pd.to_numeric(data.train.y)\n",
    "data.test.y = pd.to_numeric(data.test.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================================================] -- 2 / 2 -- (finished)fier) -- 1 / 2 -- 0 / 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.87       750\n",
      "           1       0.84      0.84      0.84       622\n",
      "\n",
      "    accuracy                           0.85      1372\n",
      "   macro avg       0.85      0.85      0.85      1372\n",
      "weighted avg       0.85      0.85      0.85      1372\n",
      "\n",
      "------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86       750\n",
      "           1       0.82      0.86      0.84       622\n",
      "\n",
      "    accuracy                           0.85      1372\n",
      "   macro avg       0.85      0.85      0.85      1372\n",
      "weighted avg       0.85      0.85      0.85      1372\n",
      "\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=cores),\n",
    "    XGBClassifier(n_jobs=cores, seed=RANDOM_STATE),\n",
    "]\n",
    "\n",
    "pbar_conf = {\n",
    "    'refresh_rate': 1,\n",
    "    'length': len(classifiers), \n",
    "    'pbar_width': 52,\n",
    "    'action_names': [i.__class__.__name__ for i in classifiers]\n",
    "}\n",
    "\n",
    "predictions = list(Pbar((fit_predict(clf, data) for clf in classifiers), **pbar_conf))\n",
    "\n",
    "for p in predictions:\n",
    "    print(classification_report(data.test.y, p))\n",
    "    print('-' * 54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[====================================================] -- 2 / 2 -- (finished)fier) -- 1 / 2 -- 0 / 2\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.91      0.89      0.90       750\n",
    "           1       0.87      0.89      0.88       622\n",
    "\n",
    "    accuracy                           0.89      1372\n",
    "   macro avg       0.89      0.89      0.89      1372\n",
    "weighted avg       0.89      0.89      0.89      1372\n",
    "\n",
    "------------------------------------------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.92      0.92      0.92       750\n",
    "           1       0.91      0.90      0.90       622\n",
    "\n",
    "    accuracy                           0.91      1372\n",
    "   macro avg       0.91      0.91      0.91      1372\n",
    "weighted avg       0.91      0.91      0.91      1372\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>title_char_length</td>\n",
       "      <td>0.031636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_82</td>\n",
       "      <td>0.025878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>title_word_count</td>\n",
       "      <td>0.024277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_197</td>\n",
       "      <td>0.022545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_84</td>\n",
       "      <td>0.015678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_288</td>\n",
       "      <td>0.014582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_21</td>\n",
       "      <td>0.014407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>content_word_count</td>\n",
       "      <td>0.014356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_194</td>\n",
       "      <td>0.013666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>content_char_length</td>\n",
       "      <td>0.013029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_45</td>\n",
       "      <td>0.012854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_87</td>\n",
       "      <td>0.011321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_201</td>\n",
       "      <td>0.010774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_30</td>\n",
       "      <td>0.010732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_28</td>\n",
       "      <td>0.010068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_72</td>\n",
       "      <td>0.009292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_256</td>\n",
       "      <td>0.009291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_187</td>\n",
       "      <td>0.008885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_44</td>\n",
       "      <td>0.008051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>image_count</td>\n",
       "      <td>0.007640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_142</td>\n",
       "      <td>0.007554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>media_count_total</td>\n",
       "      <td>0.007080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_51</td>\n",
       "      <td>0.006962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_236</td>\n",
       "      <td>0.006751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_233</td>\n",
       "      <td>0.006410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_210</td>\n",
       "      <td>0.006359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_299</td>\n",
       "      <td>0.006011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_125</td>\n",
       "      <td>0.005817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_4</td>\n",
       "      <td>0.005776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_253</td>\n",
       "      <td>0.005536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_33</td>\n",
       "      <td>0.005508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_16</td>\n",
       "      <td>0.005462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_94</td>\n",
       "      <td>0.005459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_213</td>\n",
       "      <td>0.005055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_296</td>\n",
       "      <td>0.005027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_242</td>\n",
       "      <td>0.004955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_10</td>\n",
       "      <td>0.004776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_15</td>\n",
       "      <td>0.004564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_248</td>\n",
       "      <td>0.004564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_96</td>\n",
       "      <td>0.004377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>is_collective_author</td>\n",
       "      <td>0.004327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_157</td>\n",
       "      <td>0.004295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_112</td>\n",
       "      <td>0.004292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_177</td>\n",
       "      <td>0.004270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_104</td>\n",
       "      <td>0.004269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_240</td>\n",
       "      <td>0.004258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_188</td>\n",
       "      <td>0.004231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_41</td>\n",
       "      <td>0.003953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_46</td>\n",
       "      <td>0.003895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_243</td>\n",
       "      <td>0.003851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_131</td>\n",
       "      <td>0.003801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_40</td>\n",
       "      <td>0.003735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_49</td>\n",
       "      <td>0.003718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_181</td>\n",
       "      <td>0.003676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_13</td>\n",
       "      <td>0.003631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_179</td>\n",
       "      <td>0.003549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_78</td>\n",
       "      <td>0.003469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_231</td>\n",
       "      <td>0.003431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_290</td>\n",
       "      <td>0.003423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_134</td>\n",
       "      <td>0.003415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_26</td>\n",
       "      <td>0.003384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_70</td>\n",
       "      <td>0.003373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_289</td>\n",
       "      <td>0.003371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_266</td>\n",
       "      <td>0.003336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_101</td>\n",
       "      <td>0.003336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_126</td>\n",
       "      <td>0.003331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_174</td>\n",
       "      <td>0.003262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_264</td>\n",
       "      <td>0.003196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_158</td>\n",
       "      <td>0.003092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_3</td>\n",
       "      <td>0.003080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_103</td>\n",
       "      <td>0.003072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_85</td>\n",
       "      <td>0.003060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_65</td>\n",
       "      <td>0.003050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_166</td>\n",
       "      <td>0.003045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_237</td>\n",
       "      <td>0.003040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_132</td>\n",
       "      <td>0.003027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_5</td>\n",
       "      <td>0.003017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_234</td>\n",
       "      <td>0.002983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_52</td>\n",
       "      <td>0.002972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_69</td>\n",
       "      <td>0.002969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_120</td>\n",
       "      <td>0.002936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_106</td>\n",
       "      <td>0.002935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_267</td>\n",
       "      <td>0.002931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_122</td>\n",
       "      <td>0.002923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_205</td>\n",
       "      <td>0.002914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_257</td>\n",
       "      <td>0.002914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_86</td>\n",
       "      <td>0.002895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_156</td>\n",
       "      <td>0.002859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_34</td>\n",
       "      <td>0.002855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_2</td>\n",
       "      <td>0.002828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_247</td>\n",
       "      <td>0.002824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_176</td>\n",
       "      <td>0.002807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_66</td>\n",
       "      <td>0.002803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_145</td>\n",
       "      <td>0.002763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_42</td>\n",
       "      <td>0.002757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_121</td>\n",
       "      <td>0.002754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_81</td>\n",
       "      <td>0.002739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_73</td>\n",
       "      <td>0.002731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_14</td>\n",
       "      <td>0.002675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_232</td>\n",
       "      <td>0.002674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_100</td>\n",
       "      <td>0.002669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_25</td>\n",
       "      <td>0.002658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_155</td>\n",
       "      <td>0.002655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_9</td>\n",
       "      <td>0.002638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_249</td>\n",
       "      <td>0.002634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_143</td>\n",
       "      <td>0.002634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_79</td>\n",
       "      <td>0.002594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_91</td>\n",
       "      <td>0.002582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_298</td>\n",
       "      <td>0.002577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_278</td>\n",
       "      <td>0.002567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_108</td>\n",
       "      <td>0.002561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_124</td>\n",
       "      <td>0.002553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_116</td>\n",
       "      <td>0.002550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_111</td>\n",
       "      <td>0.002549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_62</td>\n",
       "      <td>0.002543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_47</td>\n",
       "      <td>0.002534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_32</td>\n",
       "      <td>0.002531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_193</td>\n",
       "      <td>0.002530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_31</td>\n",
       "      <td>0.002528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_192</td>\n",
       "      <td>0.002523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_285</td>\n",
       "      <td>0.002497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_271</td>\n",
       "      <td>0.002462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_200</td>\n",
       "      <td>0.002433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_146</td>\n",
       "      <td>0.002404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_277</td>\n",
       "      <td>0.002396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_110</td>\n",
       "      <td>0.002393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_169</td>\n",
       "      <td>0.002383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_153</td>\n",
       "      <td>0.002377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_59</td>\n",
       "      <td>0.002364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_139</td>\n",
       "      <td>0.002354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_207</td>\n",
       "      <td>0.002346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_291</td>\n",
       "      <td>0.002344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_204</td>\n",
       "      <td>0.002343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_60</td>\n",
       "      <td>0.002341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_80</td>\n",
       "      <td>0.002329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_186</td>\n",
       "      <td>0.002317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_252</td>\n",
       "      <td>0.002314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_137</td>\n",
       "      <td>0.002307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_270</td>\n",
       "      <td>0.002302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_128</td>\n",
       "      <td>0.002293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_175</td>\n",
       "      <td>0.002291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_8</td>\n",
       "      <td>0.002282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_211</td>\n",
       "      <td>0.002281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_287</td>\n",
       "      <td>0.002280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_83</td>\n",
       "      <td>0.002277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_293</td>\n",
       "      <td>0.002270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_164</td>\n",
       "      <td>0.002268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_141</td>\n",
       "      <td>0.002265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_229</td>\n",
       "      <td>0.002261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_18</td>\n",
       "      <td>0.002255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_214</td>\n",
       "      <td>0.002230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_173</td>\n",
       "      <td>0.002227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_89</td>\n",
       "      <td>0.002210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_136</td>\n",
       "      <td>0.002205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_224</td>\n",
       "      <td>0.002202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_235</td>\n",
       "      <td>0.002199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_300</td>\n",
       "      <td>0.002188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_206</td>\n",
       "      <td>0.002186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_127</td>\n",
       "      <td>0.002180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_20</td>\n",
       "      <td>0.002173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_215</td>\n",
       "      <td>0.002166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_113</td>\n",
       "      <td>0.002158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_217</td>\n",
       "      <td>0.002158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_123</td>\n",
       "      <td>0.002155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_203</td>\n",
       "      <td>0.002151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_88</td>\n",
       "      <td>0.002149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_35</td>\n",
       "      <td>0.002143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_282</td>\n",
       "      <td>0.002140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_77</td>\n",
       "      <td>0.002130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_95</td>\n",
       "      <td>0.002129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_239</td>\n",
       "      <td>0.002126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_54</td>\n",
       "      <td>0.002124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_190</td>\n",
       "      <td>0.002122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_93</td>\n",
       "      <td>0.002112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_114</td>\n",
       "      <td>0.002112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_56</td>\n",
       "      <td>0.002108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_184</td>\n",
       "      <td>0.002099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_61</td>\n",
       "      <td>0.002097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_269</td>\n",
       "      <td>0.002059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_152</td>\n",
       "      <td>0.002057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_74</td>\n",
       "      <td>0.002054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_216</td>\n",
       "      <td>0.002053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_75</td>\n",
       "      <td>0.002049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_167</td>\n",
       "      <td>0.002030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_36</td>\n",
       "      <td>0.002019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_140</td>\n",
       "      <td>0.002016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_180</td>\n",
       "      <td>0.002015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_39</td>\n",
       "      <td>0.002006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_97</td>\n",
       "      <td>0.002002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_221</td>\n",
       "      <td>0.002002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_275</td>\n",
       "      <td>0.001993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_144</td>\n",
       "      <td>0.001989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_258</td>\n",
       "      <td>0.001986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_130</td>\n",
       "      <td>0.001961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_251</td>\n",
       "      <td>0.001952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_227</td>\n",
       "      <td>0.001950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_24</td>\n",
       "      <td>0.001949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_151</td>\n",
       "      <td>0.001948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_273</td>\n",
       "      <td>0.001948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_245</td>\n",
       "      <td>0.001943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_107</td>\n",
       "      <td>0.001941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_43</td>\n",
       "      <td>0.001941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_274</td>\n",
       "      <td>0.001936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_55</td>\n",
       "      <td>0.001933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_38</td>\n",
       "      <td>0.001933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_165</td>\n",
       "      <td>0.001921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_6</td>\n",
       "      <td>0.001914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_191</td>\n",
       "      <td>0.001912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_183</td>\n",
       "      <td>0.001909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_182</td>\n",
       "      <td>0.001906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_286</td>\n",
       "      <td>0.001903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_230</td>\n",
       "      <td>0.001896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_68</td>\n",
       "      <td>0.001877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_58</td>\n",
       "      <td>0.001876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_109</td>\n",
       "      <td>0.001876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_284</td>\n",
       "      <td>0.001867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_129</td>\n",
       "      <td>0.001860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_218</td>\n",
       "      <td>0.001848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_17</td>\n",
       "      <td>0.001842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_223</td>\n",
       "      <td>0.001841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_276</td>\n",
       "      <td>0.001835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_260</td>\n",
       "      <td>0.001835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_53</td>\n",
       "      <td>0.001828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_283</td>\n",
       "      <td>0.001827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_92</td>\n",
       "      <td>0.001823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_238</td>\n",
       "      <td>0.001817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_272</td>\n",
       "      <td>0.001816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_209</td>\n",
       "      <td>0.001806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_150</td>\n",
       "      <td>0.001806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_23</td>\n",
       "      <td>0.001793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_67</td>\n",
       "      <td>0.001793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_262</td>\n",
       "      <td>0.001792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_76</td>\n",
       "      <td>0.001787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_19</td>\n",
       "      <td>0.001781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_241</td>\n",
       "      <td>0.001780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_199</td>\n",
       "      <td>0.001771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_226</td>\n",
       "      <td>0.001768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_295</td>\n",
       "      <td>0.001755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_292</td>\n",
       "      <td>0.001737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_37</td>\n",
       "      <td>0.001734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_195</td>\n",
       "      <td>0.001733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_12</td>\n",
       "      <td>0.001732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_159</td>\n",
       "      <td>0.001731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_189</td>\n",
       "      <td>0.001730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_63</td>\n",
       "      <td>0.001724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_98</td>\n",
       "      <td>0.001722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_225</td>\n",
       "      <td>0.001710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_198</td>\n",
       "      <td>0.001705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_222</td>\n",
       "      <td>0.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_117</td>\n",
       "      <td>0.001698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_29</td>\n",
       "      <td>0.001689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_172</td>\n",
       "      <td>0.001687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_202</td>\n",
       "      <td>0.001683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_7</td>\n",
       "      <td>0.001679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_105</td>\n",
       "      <td>0.001662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_160</td>\n",
       "      <td>0.001656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_163</td>\n",
       "      <td>0.001655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_168</td>\n",
       "      <td>0.001650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_244</td>\n",
       "      <td>0.001647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_171</td>\n",
       "      <td>0.001643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_161</td>\n",
       "      <td>0.001622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_208</td>\n",
       "      <td>0.001622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_50</td>\n",
       "      <td>0.001613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_185</td>\n",
       "      <td>0.001601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_279</td>\n",
       "      <td>0.001598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_254</td>\n",
       "      <td>0.001595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_212</td>\n",
       "      <td>0.001592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_64</td>\n",
       "      <td>0.001584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_22</td>\n",
       "      <td>0.001582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_138</td>\n",
       "      <td>0.001546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_154</td>\n",
       "      <td>0.001541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_57</td>\n",
       "      <td>0.001534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_119</td>\n",
       "      <td>0.001513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_90</td>\n",
       "      <td>0.001513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_265</td>\n",
       "      <td>0.001495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_294</td>\n",
       "      <td>0.001474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_148</td>\n",
       "      <td>0.001462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_162</td>\n",
       "      <td>0.001448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_11</td>\n",
       "      <td>0.001436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_147</td>\n",
       "      <td>0.001434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_1</td>\n",
       "      <td>0.001432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_220</td>\n",
       "      <td>0.001431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_259</td>\n",
       "      <td>0.001419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_246</td>\n",
       "      <td>0.001410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_261</td>\n",
       "      <td>0.001373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_219</td>\n",
       "      <td>0.001356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_135</td>\n",
       "      <td>0.001348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_99</td>\n",
       "      <td>0.001344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_263</td>\n",
       "      <td>0.001338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_115</td>\n",
       "      <td>0.001336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_27</td>\n",
       "      <td>0.001333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_297</td>\n",
       "      <td>0.001329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_281</td>\n",
       "      <td>0.001324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_228</td>\n",
       "      <td>0.001318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_196</td>\n",
       "      <td>0.001306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_255</td>\n",
       "      <td>0.001286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_48</td>\n",
       "      <td>0.001283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_102</td>\n",
       "      <td>0.001272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_250</td>\n",
       "      <td>0.001242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_280</td>\n",
       "      <td>0.001241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_149</td>\n",
       "      <td>0.001239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_268</td>\n",
       "      <td>0.001232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_170</td>\n",
       "      <td>0.001232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_178</td>\n",
       "      <td>0.001213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_71</td>\n",
       "      <td>0.001125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_118</td>\n",
       "      <td>0.001108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_133</td>\n",
       "      <td>0.001064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>published_on_day</td>\n",
       "      <td>0.000554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>video_count</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      importance\n",
       "title_char_length       0.031636\n",
       "d2v_82                  0.025878\n",
       "title_word_count        0.024277\n",
       "d2v_197                 0.022545\n",
       "d2v_84                  0.015678\n",
       "d2v_288                 0.014582\n",
       "d2v_21                  0.014407\n",
       "content_word_count      0.014356\n",
       "d2v_194                 0.013666\n",
       "content_char_length     0.013029\n",
       "d2v_45                  0.012854\n",
       "d2v_87                  0.011321\n",
       "d2v_201                 0.010774\n",
       "d2v_30                  0.010732\n",
       "d2v_28                  0.010068\n",
       "d2v_72                  0.009292\n",
       "d2v_256                 0.009291\n",
       "d2v_187                 0.008885\n",
       "d2v_44                  0.008051\n",
       "image_count             0.007640\n",
       "d2v_142                 0.007554\n",
       "media_count_total       0.007080\n",
       "d2v_51                  0.006962\n",
       "d2v_236                 0.006751\n",
       "d2v_233                 0.006410\n",
       "d2v_210                 0.006359\n",
       "d2v_299                 0.006011\n",
       "d2v_125                 0.005817\n",
       "d2v_4                   0.005776\n",
       "d2v_253                 0.005536\n",
       "d2v_33                  0.005508\n",
       "d2v_16                  0.005462\n",
       "d2v_94                  0.005459\n",
       "d2v_213                 0.005055\n",
       "d2v_296                 0.005027\n",
       "d2v_242                 0.004955\n",
       "d2v_10                  0.004776\n",
       "d2v_15                  0.004564\n",
       "d2v_248                 0.004564\n",
       "d2v_96                  0.004377\n",
       "is_collective_author    0.004327\n",
       "d2v_157                 0.004295\n",
       "d2v_112                 0.004292\n",
       "d2v_177                 0.004270\n",
       "d2v_104                 0.004269\n",
       "d2v_240                 0.004258\n",
       "d2v_188                 0.004231\n",
       "d2v_41                  0.003953\n",
       "d2v_46                  0.003895\n",
       "d2v_243                 0.003851\n",
       "d2v_131                 0.003801\n",
       "d2v_40                  0.003735\n",
       "d2v_49                  0.003718\n",
       "d2v_181                 0.003676\n",
       "d2v_13                  0.003631\n",
       "d2v_179                 0.003549\n",
       "d2v_78                  0.003469\n",
       "d2v_231                 0.003431\n",
       "d2v_290                 0.003423\n",
       "d2v_134                 0.003415\n",
       "d2v_26                  0.003384\n",
       "d2v_70                  0.003373\n",
       "d2v_289                 0.003371\n",
       "d2v_266                 0.003336\n",
       "d2v_101                 0.003336\n",
       "d2v_126                 0.003331\n",
       "d2v_174                 0.003262\n",
       "d2v_264                 0.003196\n",
       "d2v_158                 0.003092\n",
       "d2v_3                   0.003080\n",
       "d2v_103                 0.003072\n",
       "d2v_85                  0.003060\n",
       "d2v_65                  0.003050\n",
       "d2v_166                 0.003045\n",
       "d2v_237                 0.003040\n",
       "d2v_132                 0.003027\n",
       "d2v_5                   0.003017\n",
       "d2v_234                 0.002983\n",
       "d2v_52                  0.002972\n",
       "d2v_69                  0.002969\n",
       "d2v_120                 0.002936\n",
       "d2v_106                 0.002935\n",
       "d2v_267                 0.002931\n",
       "d2v_122                 0.002923\n",
       "d2v_205                 0.002914\n",
       "d2v_257                 0.002914\n",
       "d2v_86                  0.002895\n",
       "d2v_156                 0.002859\n",
       "d2v_34                  0.002855\n",
       "d2v_2                   0.002828\n",
       "d2v_247                 0.002824\n",
       "d2v_176                 0.002807\n",
       "d2v_66                  0.002803\n",
       "d2v_145                 0.002763\n",
       "d2v_42                  0.002757\n",
       "d2v_121                 0.002754\n",
       "d2v_81                  0.002739\n",
       "d2v_73                  0.002731\n",
       "d2v_14                  0.002675\n",
       "d2v_232                 0.002674\n",
       "d2v_100                 0.002669\n",
       "d2v_25                  0.002658\n",
       "d2v_155                 0.002655\n",
       "d2v_9                   0.002638\n",
       "d2v_249                 0.002634\n",
       "d2v_143                 0.002634\n",
       "d2v_79                  0.002594\n",
       "d2v_91                  0.002582\n",
       "d2v_298                 0.002577\n",
       "d2v_278                 0.002567\n",
       "d2v_108                 0.002561\n",
       "d2v_124                 0.002553\n",
       "d2v_116                 0.002550\n",
       "d2v_111                 0.002549\n",
       "d2v_62                  0.002543\n",
       "d2v_47                  0.002534\n",
       "d2v_32                  0.002531\n",
       "d2v_193                 0.002530\n",
       "d2v_31                  0.002528\n",
       "d2v_192                 0.002523\n",
       "d2v_285                 0.002497\n",
       "d2v_271                 0.002462\n",
       "d2v_200                 0.002433\n",
       "d2v_146                 0.002404\n",
       "d2v_277                 0.002396\n",
       "d2v_110                 0.002393\n",
       "d2v_169                 0.002383\n",
       "d2v_153                 0.002377\n",
       "d2v_59                  0.002364\n",
       "d2v_139                 0.002354\n",
       "d2v_207                 0.002346\n",
       "d2v_291                 0.002344\n",
       "d2v_204                 0.002343\n",
       "d2v_60                  0.002341\n",
       "d2v_80                  0.002329\n",
       "d2v_186                 0.002317\n",
       "d2v_252                 0.002314\n",
       "d2v_137                 0.002307\n",
       "d2v_270                 0.002302\n",
       "d2v_128                 0.002293\n",
       "d2v_175                 0.002291\n",
       "d2v_8                   0.002282\n",
       "d2v_211                 0.002281\n",
       "d2v_287                 0.002280\n",
       "d2v_83                  0.002277\n",
       "d2v_293                 0.002270\n",
       "d2v_164                 0.002268\n",
       "d2v_141                 0.002265\n",
       "d2v_229                 0.002261\n",
       "d2v_18                  0.002255\n",
       "d2v_214                 0.002230\n",
       "d2v_173                 0.002227\n",
       "d2v_89                  0.002210\n",
       "d2v_136                 0.002205\n",
       "d2v_224                 0.002202\n",
       "d2v_235                 0.002199\n",
       "d2v_300                 0.002188\n",
       "d2v_206                 0.002186\n",
       "d2v_127                 0.002180\n",
       "d2v_20                  0.002173\n",
       "d2v_215                 0.002166\n",
       "d2v_113                 0.002158\n",
       "d2v_217                 0.002158\n",
       "d2v_123                 0.002155\n",
       "d2v_203                 0.002151\n",
       "d2v_88                  0.002149\n",
       "d2v_35                  0.002143\n",
       "d2v_282                 0.002140\n",
       "d2v_77                  0.002130\n",
       "d2v_95                  0.002129\n",
       "d2v_239                 0.002126\n",
       "d2v_54                  0.002124\n",
       "d2v_190                 0.002122\n",
       "d2v_93                  0.002112\n",
       "d2v_114                 0.002112\n",
       "d2v_56                  0.002108\n",
       "d2v_184                 0.002099\n",
       "d2v_61                  0.002097\n",
       "d2v_269                 0.002059\n",
       "d2v_152                 0.002057\n",
       "d2v_74                  0.002054\n",
       "d2v_216                 0.002053\n",
       "d2v_75                  0.002049\n",
       "d2v_167                 0.002030\n",
       "d2v_36                  0.002019\n",
       "d2v_140                 0.002016\n",
       "d2v_180                 0.002015\n",
       "d2v_39                  0.002006\n",
       "d2v_97                  0.002002\n",
       "d2v_221                 0.002002\n",
       "d2v_275                 0.001993\n",
       "d2v_144                 0.001989\n",
       "d2v_258                 0.001986\n",
       "d2v_130                 0.001961\n",
       "d2v_251                 0.001952\n",
       "d2v_227                 0.001950\n",
       "d2v_24                  0.001949\n",
       "d2v_151                 0.001948\n",
       "d2v_273                 0.001948\n",
       "d2v_245                 0.001943\n",
       "d2v_107                 0.001941\n",
       "d2v_43                  0.001941\n",
       "d2v_274                 0.001936\n",
       "d2v_55                  0.001933\n",
       "d2v_38                  0.001933\n",
       "d2v_165                 0.001921\n",
       "d2v_6                   0.001914\n",
       "d2v_191                 0.001912\n",
       "d2v_183                 0.001909\n",
       "d2v_182                 0.001906\n",
       "d2v_286                 0.001903\n",
       "d2v_230                 0.001896\n",
       "d2v_68                  0.001877\n",
       "d2v_58                  0.001876\n",
       "d2v_109                 0.001876\n",
       "d2v_284                 0.001867\n",
       "d2v_129                 0.001860\n",
       "d2v_218                 0.001848\n",
       "d2v_17                  0.001842\n",
       "d2v_223                 0.001841\n",
       "d2v_276                 0.001835\n",
       "d2v_260                 0.001835\n",
       "d2v_53                  0.001828\n",
       "d2v_283                 0.001827\n",
       "d2v_92                  0.001823\n",
       "d2v_238                 0.001817\n",
       "d2v_272                 0.001816\n",
       "d2v_209                 0.001806\n",
       "d2v_150                 0.001806\n",
       "d2v_23                  0.001793\n",
       "d2v_67                  0.001793\n",
       "d2v_262                 0.001792\n",
       "d2v_76                  0.001787\n",
       "d2v_19                  0.001781\n",
       "d2v_241                 0.001780\n",
       "d2v_199                 0.001771\n",
       "d2v_226                 0.001768\n",
       "d2v_295                 0.001755\n",
       "d2v_292                 0.001737\n",
       "d2v_37                  0.001734\n",
       "d2v_195                 0.001733\n",
       "d2v_12                  0.001732\n",
       "d2v_159                 0.001731\n",
       "d2v_189                 0.001730\n",
       "d2v_63                  0.001724\n",
       "d2v_98                  0.001722\n",
       "d2v_225                 0.001710\n",
       "d2v_198                 0.001705\n",
       "d2v_222                 0.001700\n",
       "d2v_117                 0.001698\n",
       "d2v_29                  0.001689\n",
       "d2v_172                 0.001687\n",
       "d2v_202                 0.001683\n",
       "d2v_7                   0.001679\n",
       "d2v_105                 0.001662\n",
       "d2v_160                 0.001656\n",
       "d2v_163                 0.001655\n",
       "d2v_168                 0.001650\n",
       "d2v_244                 0.001647\n",
       "d2v_171                 0.001643\n",
       "d2v_161                 0.001622\n",
       "d2v_208                 0.001622\n",
       "d2v_50                  0.001613\n",
       "d2v_185                 0.001601\n",
       "d2v_279                 0.001598\n",
       "d2v_254                 0.001595\n",
       "d2v_212                 0.001592\n",
       "d2v_64                  0.001584\n",
       "d2v_22                  0.001582\n",
       "d2v_138                 0.001546\n",
       "d2v_154                 0.001541\n",
       "d2v_57                  0.001534\n",
       "d2v_119                 0.001513\n",
       "d2v_90                  0.001513\n",
       "d2v_265                 0.001495\n",
       "d2v_294                 0.001474\n",
       "d2v_148                 0.001462\n",
       "d2v_162                 0.001448\n",
       "d2v_11                  0.001436\n",
       "d2v_147                 0.001434\n",
       "d2v_1                   0.001432\n",
       "d2v_220                 0.001431\n",
       "d2v_259                 0.001419\n",
       "d2v_246                 0.001410\n",
       "d2v_261                 0.001373\n",
       "d2v_219                 0.001356\n",
       "d2v_135                 0.001348\n",
       "d2v_99                  0.001344\n",
       "d2v_263                 0.001338\n",
       "d2v_115                 0.001336\n",
       "d2v_27                  0.001333\n",
       "d2v_297                 0.001329\n",
       "d2v_281                 0.001324\n",
       "d2v_228                 0.001318\n",
       "d2v_196                 0.001306\n",
       "d2v_255                 0.001286\n",
       "d2v_48                  0.001283\n",
       "d2v_102                 0.001272\n",
       "d2v_250                 0.001242\n",
       "d2v_280                 0.001241\n",
       "d2v_149                 0.001239\n",
       "d2v_268                 0.001232\n",
       "d2v_170                 0.001232\n",
       "d2v_178                 0.001213\n",
       "d2v_71                  0.001125\n",
       "d2v_118                 0.001108\n",
       "d2v_133                 0.001064\n",
       "published_on_day        0.000554\n",
       "video_count             0.000093"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_all(pd.DataFrame((i for i in classifiers[0].feature_importances_), index=data.train.features.columns, columns=['importance']).sort_values(by=['importance'], ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier XGBClassifier does not contain feature importance data\n"
     ]
    }
   ],
   "source": [
    "show_importances(classifiers[1], data.train.features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        0\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "65684    1\n",
       "65685    1\n",
       "65686    0\n",
       "65687    1\n",
       "65688    1\n",
       "Name: is_fake_news_label, Length: 65689, dtype: int64"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(columns=[\"x\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.loc[1] = [[1,2,3,4]]\n",
    "x.loc[2] = [[3,4,5,6]]\n",
    "x.loc[3] = [[6,7,8,9]]\n",
    "x.loc[4] = [[10,11,12,13]]\n",
    "x.loc[5] = [[15]]\n",
    "x.loc[6] = [[15,16]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[3, 4, 5, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[6, 7, 8, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[10, 11, 12, 13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>[15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>[15, 16]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  x\n",
       "1      [1, 2, 3, 4]\n",
       "2      [3, 4, 5, 6]\n",
       "3      [6, 7, 8, 9]\n",
       "4  [10, 11, 12, 13]\n",
       "5              [15]\n",
       "6          [15, 16]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "zle = pd.Series([3,6,15,16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['zle'] = x['x'].apply(lambda stlpec: len([i for i in stlpec if i in zle]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>zle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[3, 4, 5, 6]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[6, 7, 8, 9]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[10, 11, 12, 13]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>[15]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>[15, 16]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  x  zle\n",
       "1      [1, 2, 3, 4]    1\n",
       "2      [3, 4, 5, 6]    2\n",
       "3      [6, 7, 8, 9]    1\n",
       "4  [10, 11, 12, 13]    0\n",
       "5              [15]    1\n",
       "6          [15, 16]    2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
