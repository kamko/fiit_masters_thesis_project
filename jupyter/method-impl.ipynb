{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'show_importances' from 'util' (C:\\Users\\j\\IdeaProjects\\fiit_masters_thesis_project\\jupyter\\util.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d5d6a7a82bea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcommon\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msave_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_session\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshow_importances\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msplit_X_y_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_X_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mempty_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_feature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr_contains\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'show_importances' from 'util' (C:\\Users\\j\\IdeaProjects\\fiit_masters_thesis_project\\jupyter\\util.py)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlalchemy\n",
    "import gensim\n",
    "import logging\n",
    "\n",
    "from common import create_engine\n",
    "from common import display_all\n",
    "from common import figsize\n",
    "from common import save_df, load_df\n",
    "from common import save_session, load_session\n",
    "\n",
    "from util import show_importances\n",
    "from util import split_X_y_all, split_X_y, split_data\n",
    "from util import empty_features, column_feature, str_contains\n",
    "\n",
    "from pbar import Pbar\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters() # converters e.g. for datetime in plots\n",
    "\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SESSION_FILE_NAME = 'method-impl.session-db'\n",
    "\n",
    "load_session(SESSION_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 123\n",
    "np_random = np.random.RandomState(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_df('final_data.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>perex</th>\n",
       "      <th>body</th>\n",
       "      <th>published_at</th>\n",
       "      <th>extracted_at</th>\n",
       "      <th>source_id</th>\n",
       "      <th>category</th>\n",
       "      <th>other_info</th>\n",
       "      <th>...</th>\n",
       "      <th>source_id</th>\n",
       "      <th>source_name</th>\n",
       "      <th>source_url</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_is_reliable</th>\n",
       "      <th>fb_sync_date</th>\n",
       "      <th>fb_reaction_count</th>\n",
       "      <th>fb_comment_count</th>\n",
       "      <th>fb_share_count</th>\n",
       "      <th>fb_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>235048</td>\n",
       "      <td>https://www.naturalnewsblogs.com/the-secret-to...</td>\n",
       "      <td>The Secret to Happiness &amp;#8211; Revealed!</td>\n",
       "      <td>&lt;p&gt;&amp;#8220;Why are you so happy all of the time...</td>\n",
       "      <td>“Why are you so happy all of the time?”\\nI am ...</td>\n",
       "      <td>2013-08-07 12:36:20</td>\n",
       "      <td>2019-09-05 06:45:28.429274</td>\n",
       "      <td>142</td>\n",
       "      <td>[Health, Mental Health]</td>\n",
       "      <td>{'tags': ['choices', 'depression', 'happiness'...</td>\n",
       "      <td>...</td>\n",
       "      <td>142</td>\n",
       "      <td>naturalnewsblogs.com</td>\n",
       "      <td>http://naturalnewsblogs.com</td>\n",
       "      <td>news_website</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-14 15:29:44.601408</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>235036</td>\n",
       "      <td>https://www.naturalnewsblogs.com/us-government...</td>\n",
       "      <td>US government claims 100% ownership over all y...</td>\n",
       "      <td>&lt;p&gt;(NaturalNews) The United States government ...</td>\n",
       "      <td>(NaturalNews) The United States government cla...</td>\n",
       "      <td>2013-05-19 18:50:37</td>\n",
       "      <td>2019-09-05 06:45:27.633650</td>\n",
       "      <td>142</td>\n",
       "      <td>[Health, News, Science, Weird, Biotechnology, ...</td>\n",
       "      <td>{'tags': ['gene patents', 'genetic slavery', '...</td>\n",
       "      <td>...</td>\n",
       "      <td>142</td>\n",
       "      <td>naturalnewsblogs.com</td>\n",
       "      <td>http://naturalnewsblogs.com</td>\n",
       "      <td>news_website</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-14 15:29:44.601408</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>235039</td>\n",
       "      <td>https://www.naturalnewsblogs.com/angelina-joli...</td>\n",
       "      <td>Angelina Jolie copied by men! Surgeons now cut...</td>\n",
       "      <td>&lt;p&gt;(NaturalNews) Beyond merely inspiring women...</td>\n",
       "      <td>(NaturalNews) Beyond merely inspiring women to...</td>\n",
       "      <td>2013-05-20 18:54:30</td>\n",
       "      <td>2019-09-05 06:45:28.083048</td>\n",
       "      <td>142</td>\n",
       "      <td>[Health, Science, Weird, Celebrity, Hospitals ...</td>\n",
       "      <td>{'tags': ['Angelina Jolie', 'BRCA genes', 'pro...</td>\n",
       "      <td>...</td>\n",
       "      <td>142</td>\n",
       "      <td>naturalnewsblogs.com</td>\n",
       "      <td>http://naturalnewsblogs.com</td>\n",
       "      <td>news_website</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-14 15:29:44.601408</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>235041</td>\n",
       "      <td>https://www.naturalnewsblogs.com/natural-news-...</td>\n",
       "      <td>Natural News releases latest laboratory test r...</td>\n",
       "      <td>&lt;p&gt;(NaturalNews) As Natural News readers know,...</td>\n",
       "      <td>(NaturalNews) As Natural News readers know, we...</td>\n",
       "      <td>2013-05-23 19:47:30</td>\n",
       "      <td>2019-09-05 06:45:28.167110</td>\n",
       "      <td>142</td>\n",
       "      <td>[Health, Food, Nutrition]</td>\n",
       "      <td>{'tags': ['clean chlorella', 'heavy metals', '...</td>\n",
       "      <td>...</td>\n",
       "      <td>142</td>\n",
       "      <td>naturalnewsblogs.com</td>\n",
       "      <td>http://naturalnewsblogs.com</td>\n",
       "      <td>news_website</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-14 15:29:44.601408</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>235052</td>\n",
       "      <td>https://www.naturalnewsblogs.com/food-insecuri...</td>\n",
       "      <td>Food Insecurity: A Solution Grows Under Your Feet</td>\n",
       "      <td>&lt;p&gt;Food insecurity is a serious problem that p...</td>\n",
       "      <td>Food insecurity is a serious problem that plag...</td>\n",
       "      <td>2013-08-08 10:12:31</td>\n",
       "      <td>2019-09-05 06:45:28.607943</td>\n",
       "      <td>142</td>\n",
       "      <td>[Health, Nutritional Medicine, Food, Nutrition]</td>\n",
       "      <td>{'tags': ['broadleaf plantain', 'food insecuri...</td>\n",
       "      <td>...</td>\n",
       "      <td>142</td>\n",
       "      <td>naturalnewsblogs.com</td>\n",
       "      <td>http://naturalnewsblogs.com</td>\n",
       "      <td>news_website</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-14 15:29:44.601408</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                                url  \\\n",
       "0  235048  https://www.naturalnewsblogs.com/the-secret-to...   \n",
       "1  235036  https://www.naturalnewsblogs.com/us-government...   \n",
       "2  235039  https://www.naturalnewsblogs.com/angelina-joli...   \n",
       "3  235041  https://www.naturalnewsblogs.com/natural-news-...   \n",
       "4  235052  https://www.naturalnewsblogs.com/food-insecuri...   \n",
       "\n",
       "                                               title  \\\n",
       "0          The Secret to Happiness &#8211; Revealed!   \n",
       "1  US government claims 100% ownership over all y...   \n",
       "2  Angelina Jolie copied by men! Surgeons now cut...   \n",
       "3  Natural News releases latest laboratory test r...   \n",
       "4  Food Insecurity: A Solution Grows Under Your Feet   \n",
       "\n",
       "                                               perex  \\\n",
       "0  <p>&#8220;Why are you so happy all of the time...   \n",
       "1  <p>(NaturalNews) The United States government ...   \n",
       "2  <p>(NaturalNews) Beyond merely inspiring women...   \n",
       "3  <p>(NaturalNews) As Natural News readers know,...   \n",
       "4  <p>Food insecurity is a serious problem that p...   \n",
       "\n",
       "                                                body        published_at  \\\n",
       "0  “Why are you so happy all of the time?”\\nI am ... 2013-08-07 12:36:20   \n",
       "1  (NaturalNews) The United States government cla... 2013-05-19 18:50:37   \n",
       "2  (NaturalNews) Beyond merely inspiring women to... 2013-05-20 18:54:30   \n",
       "3  (NaturalNews) As Natural News readers know, we... 2013-05-23 19:47:30   \n",
       "4  Food insecurity is a serious problem that plag... 2013-08-08 10:12:31   \n",
       "\n",
       "                extracted_at  source_id  \\\n",
       "0 2019-09-05 06:45:28.429274        142   \n",
       "1 2019-09-05 06:45:27.633650        142   \n",
       "2 2019-09-05 06:45:28.083048        142   \n",
       "3 2019-09-05 06:45:28.167110        142   \n",
       "4 2019-09-05 06:45:28.607943        142   \n",
       "\n",
       "                                            category  \\\n",
       "0                            [Health, Mental Health]   \n",
       "1  [Health, News, Science, Weird, Biotechnology, ...   \n",
       "2  [Health, Science, Weird, Celebrity, Hospitals ...   \n",
       "3                          [Health, Food, Nutrition]   \n",
       "4    [Health, Nutritional Medicine, Food, Nutrition]   \n",
       "\n",
       "                                          other_info  ...  source_id  \\\n",
       "0  {'tags': ['choices', 'depression', 'happiness'...  ...        142   \n",
       "1  {'tags': ['gene patents', 'genetic slavery', '...  ...        142   \n",
       "2  {'tags': ['Angelina Jolie', 'BRCA genes', 'pro...  ...        142   \n",
       "3  {'tags': ['clean chlorella', 'heavy metals', '...  ...        142   \n",
       "4  {'tags': ['broadleaf plantain', 'food insecuri...  ...        142   \n",
       "\n",
       "            source_name                   source_url   source_type  \\\n",
       "0  naturalnewsblogs.com  http://naturalnewsblogs.com  news_website   \n",
       "1  naturalnewsblogs.com  http://naturalnewsblogs.com  news_website   \n",
       "2  naturalnewsblogs.com  http://naturalnewsblogs.com  news_website   \n",
       "3  naturalnewsblogs.com  http://naturalnewsblogs.com  news_website   \n",
       "4  naturalnewsblogs.com  http://naturalnewsblogs.com  news_website   \n",
       "\n",
       "  source_is_reliable               fb_sync_date fb_reaction_count  \\\n",
       "0                  0 2019-10-14 15:29:44.601408                 0   \n",
       "1                  0 2019-10-14 15:29:44.601408                 0   \n",
       "2                  0 2019-10-14 15:29:44.601408                 0   \n",
       "3                  0 2019-10-14 15:29:44.601408                 0   \n",
       "4                  0 2019-10-14 15:29:44.601408                 0   \n",
       "\n",
       "   fb_comment_count fb_share_count  fb_popularity  \n",
       "0                 0              0              0  \n",
       "1                 0              0              0  \n",
       "2                 0              0              0  \n",
       "3                 0              0              0  \n",
       "4                 0              0              0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 164450 entries, 0 to 171743\n",
      "Data columns (total 23 columns):\n",
      "id                    164450 non-null int64\n",
      "url                   164450 non-null object\n",
      "title                 164450 non-null object\n",
      "perex                 140260 non-null object\n",
      "body                  164221 non-null object\n",
      "published_at          164450 non-null datetime64[ns]\n",
      "extracted_at          164450 non-null datetime64[ns]\n",
      "source_id             164450 non-null int64\n",
      "category              136428 non-null object\n",
      "other_info            164446 non-null object\n",
      "image_count           164450 non-null int64\n",
      "video_count           164450 non-null int64\n",
      "author_name           164450 non-null object\n",
      "source_id             164450 non-null int64\n",
      "source_name           164450 non-null object\n",
      "source_url            164450 non-null object\n",
      "source_type           164450 non-null object\n",
      "source_is_reliable    164450 non-null int64\n",
      "fb_sync_date          164450 non-null datetime64[ns]\n",
      "fb_reaction_count     164450 non-null int64\n",
      "fb_comment_count      164450 non-null int64\n",
      "fb_share_count        164450 non-null int64\n",
      "fb_popularity         164450 non-null int64\n",
      "dtypes: datetime64[ns](3), int64(10), object(10)\n",
      "memory usage: 30.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rozdelenie hodnot popularity do 5 skupin\n",
    "\n",
    "- `0 - 0.5`\n",
    "- `0.5 - 0.75`\n",
    "- `0.75 - 0.9`\n",
    "- `0.9 - 0.95`\n",
    "- `0.95 - 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_labels(df, quantiles, column='fb_popularity'):\n",
    "    df = df.copy()\n",
    "    label_str = f'{column}_label'\n",
    "    \n",
    "    df[label_str] = -1\n",
    "    \n",
    "    label = 1    \n",
    "    for i in range(len(quantiles) - 1):\n",
    "        low = df[column].quantile(quantiles[i])\n",
    "        high = df[column].quantile(quantiles[i + 1])\n",
    "        \n",
    "        df.loc[(low <= df[column]) & (df[column] <= high), label_str] = int(label)\n",
    "        \n",
    "        label += 1\n",
    "    df = df.drop(columns=[column])    \n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00          0.0\n",
      "0.50          0.0\n",
      "0.75         53.0\n",
      "0.90        460.0\n",
      "0.95       1372.0\n",
      "1.00    3929532.0\n",
      "Name: fb_reaction_count, dtype: float64\n",
      "0.00         0.0\n",
      "0.50         0.0\n",
      "0.75         8.0\n",
      "0.90        92.0\n",
      "0.95       311.0\n",
      "1.00    797490.0\n",
      "Name: fb_comment_count, dtype: float64\n",
      "0.00         0.0\n",
      "0.50         1.0\n",
      "0.75        35.0\n",
      "0.90       194.0\n",
      "0.95       530.0\n",
      "1.00    572708.0\n",
      "Name: fb_share_count, dtype: float64\n",
      "0.00          0.0\n",
      "0.50          2.0\n",
      "0.75        105.0\n",
      "0.90        772.0\n",
      "0.95       2257.0\n",
      "1.00    5197586.0\n",
      "Name: fb_popularity, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "quantiles = [\n",
    "    0,\n",
    "    .50,\n",
    "    .75,\n",
    "    .90,\n",
    "    .95,\n",
    "    1\n",
    "]\n",
    "\n",
    "cols = [\n",
    "    'fb_reaction_count',\n",
    "    'fb_comment_count',\n",
    "    'fb_share_count',\n",
    "    'fb_popularity'    \n",
    "]\n",
    "\n",
    "for i in cols:\n",
    "    print(df[i].quantile(quantiles))\n",
    "    df = add_labels(df, quantiles, column=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pri jednotlivych zlozkach sme pri tomto rozdeleni nasli len 4 skupiny (lebo 1 == 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jednoducha heuristika: ak je zdroj nedoveryhodny tak aj clanok je nedoveryhodny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_fake_news_label'] = df.source_is_reliable.replace({0:1, 1:0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear body, perex, etc from html...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows without body\n",
    "df = df[~df.body.isnull()]\n",
    "df = df[~df.title.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "\n",
    "def clear_text(text):\n",
    "    if text is None:\n",
    "        return ''\n",
    "\n",
    "    text = BeautifulSoup(text, features='html.parser').text\n",
    "    text = text.lower()\n",
    "    text = text.replace('\\r', '')\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = unicodedata.normalize('NFKD', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def clear_column(df, column):\n",
    "    df[column] = df[column].apply(clear_text)\n",
    "\n",
    "def clear_columns(df, columns):\n",
    "    pbar_conf = {\n",
    "        'refresh_rate': 1,\n",
    "        'action_names': columns\n",
    "    }\n",
    "        \n",
    "    for c in Pbar(columns, **pbar_conf):\n",
    "        clear_column(df, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                                  ] (processing: title) -- 0 / 3"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\j\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:314: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================                ] (processing: body) -- 2 / 33"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\j\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://medicalxpress.com/news/2013-08-vaccination-flu-worse-exposed-strain.html\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] -- 3 / 3 -- (finished)\n"
     ]
    }
   ],
   "source": [
    "clear_columns(df, ['title', 'perex', 'body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = list(filter(lambda x: x.endswith('_label'), df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ln in label_names:\n",
    "    df[ln] = pd.to_numeric(df[ln])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labely\n",
    "labels_df = pd.concat([labels_df] + [df[label_name] for label_name in label_names], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 164221 entries, 0 to 171743\n",
      "Data columns (total 28 columns):\n",
      "id                         164221 non-null int64\n",
      "url                        164221 non-null object\n",
      "title                      164221 non-null object\n",
      "perex                      164221 non-null object\n",
      "body                       164221 non-null object\n",
      "published_at               164221 non-null datetime64[ns]\n",
      "extracted_at               164221 non-null datetime64[ns]\n",
      "source_id                  164221 non-null int64\n",
      "category                   136391 non-null object\n",
      "other_info                 164217 non-null object\n",
      "image_count                164221 non-null int64\n",
      "video_count                164221 non-null int64\n",
      "author_name                164221 non-null object\n",
      "source_id                  164221 non-null int64\n",
      "source_name                164221 non-null object\n",
      "source_url                 164221 non-null object\n",
      "source_type                164221 non-null object\n",
      "source_is_reliable         164221 non-null int64\n",
      "fb_sync_date               164221 non-null datetime64[ns]\n",
      "fb_reaction_count          164221 non-null int64\n",
      "fb_comment_count           164221 non-null int64\n",
      "fb_share_count             164221 non-null int64\n",
      "fb_popularity              164221 non-null int64\n",
      "fb_reaction_count_label    164221 non-null int64\n",
      "fb_comment_count_label     164221 non-null int64\n",
      "fb_share_count_label       164221 non-null int64\n",
      "fb_popularity_label        164221 non-null int64\n",
      "is_fake_news_label         164221 non-null int64\n",
      "dtypes: datetime64[ns](3), int64(15), object(10)\n",
      "memory usage: 36.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rozdelenie dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, validation = tuple(split_data(df, sizes=[2, 2, 1], shuffle=True, np_random=np_random))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[65689, 65688, 32844]\n"
     ]
    }
   ],
   "source": [
    "print([len(i) for i in [train,test,validation]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fb_reaction_count_label',\n",
       " 'fb_comment_count_label',\n",
       " 'fb_share_count_label',\n",
       " 'fb_popularity_label',\n",
       " 'is_fake_news_label']"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from textblob import TextBlob\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    doc = nlp(text, disable=['parser', 'tagger', 'ner'])\n",
    "    \n",
    "    res = []\n",
    "    for i in doc:\n",
    "        if i.is_stop:\n",
    "            continue\n",
    "        if i.is_punct:\n",
    "            continue\n",
    "            \n",
    "        res.append(str(i))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_basic_features(df):\n",
    "    cv = CountVectorizer()\n",
    "    data = cv.fit_transform(df.title)\n",
    "\n",
    "    res = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    res['title_word_count'] = data.sum(axis=1)\n",
    "    res['title_char_length'] = df.title.apply(lambda x: len(x))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perex_basic_features(df):\n",
    "    cv = CountVectorizer()\n",
    "    data = cv.fit_transform(df.perex)\n",
    "\n",
    "    res = pd.DataFrame(index=df.index)    \n",
    "    res['perex_word_count'] = data.sum(axis=1)\n",
    "    res['perex_char_length'] = df.perex.apply(lambda x: len(x))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_basic_features(df):\n",
    "    content_cv = CountVectorizer()\n",
    "    data = content_cv.fit_transform(df.body)\n",
    "\n",
    "    res = pd.DataFrame(index=df.index)    \n",
    "    res['content_word_count'] = data.sum(axis=1)\n",
    "    res['content_char_length'] = df.body.apply(lambda x: len(x))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def media_count_total(df):\n",
    "    res = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    res['media_count_total'] = df['image_count'] + df['video_count']\n",
    "    \n",
    "    return res\n",
    "    \n",
    "def media_count_image(df):\n",
    "    return column_feature(df, 'image_count')\n",
    "\n",
    "def media_count_video(df):\n",
    "    return column_feature(df, 'video_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def published_on_day(df):\n",
    "    res = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    res['published_on_day'] = df.published_at.dt.weekday + 1\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_collective_author(df):\n",
    "    \n",
    "    uniq_source_names = df.source_name.unique()\n",
    "    def make_a_guess(author_name):\n",
    "\n",
    "        return any((\n",
    "                    str_contains(author_name, 'admin', case=False),\n",
    "                    author_name.startswith('Neuroscience News Posts Science Research News Labs Universities Hospitals News Departments Around The World'),\n",
    "                    author_name in ['Neuroscience News',\n",
    "                                    'Wake Up World',\n",
    "                                    'Health Sciences Institute',\n",
    "                                    'REALdeal', \n",
    "                                    'nmheditor',\n",
    "                                    'The Mind Unleashed',\n",
    "                                    'Thinking Moms\\' Revolution',\n",
    "                                    'TheNewsDoctors',\n",
    "                                    'clnews',\n",
    "                                    'Associated Press',\n",
    "                                    'HealthDay',\n",
    "                                    'Infowars',\n",
    "                                    'Natural News Editors',\n",
    "                                    'https://www.facebook.com/WebMD',\n",
    "                                    'naturalnews', 'peakconsciousness', 'HealingwithoutHurting',\n",
    "                                    'HealthNutNews.com',\n",
    "                                   ],\n",
    "                    author_name.startswith('The Associated Press'),\n",
    "                    # ' and ' in author_name, # todo: je to kolektivny autor ak ich je len viac?\n",
    "                    author_name in uniq_source_names,   \n",
    "        ))\n",
    "    \n",
    "    res = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    res['is_collective_author'] = df.author_name.map(make_a_guess)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     Health\n",
       "1                              Mental Health\n",
       "2                                       News\n",
       "3                                    Science\n",
       "4                                      Weird\n",
       "                        ...                 \n",
       "2631    a5651504-8f5f-5320-9d04-cea5db37ce62\n",
       "2632    2c63c2d2-7e9f-5e20-9a8d-8dc8a0c269fa\n",
       "2633    1c36abf6-c842-5ef4-9952-12d650ea5c82\n",
       "2634    937af7f5-414c-52ee-b01f-6a49488e9d52\n",
       "2635    e8834c5b-20a3-517d-a488-32652a2a690c\n",
       "Length: 2636, dtype: object"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(df.category.explode().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    title_basic_features,\n",
    "    perex_basic_features,\n",
    "    content_basic_features,\n",
    "    \n",
    "    media_count_total,\n",
    "    media_count_image,\n",
    "    media_count_video,\n",
    "    \n",
    "    published_on_day,\n",
    "    is_collective_author,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df):    \n",
    "    pbar_conf = {\n",
    "        'refresh_rate': 1,\n",
    "        'action_names': [i.__name__ for i in features]\n",
    "    }\n",
    "    \n",
    "    res = pd.DataFrame()\n",
    "    for feature_generator in Pbar(features, **pbar_conf):\n",
    "        res = pd.concat([res, feature_generator(df)], axis=1)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = split_X_y_all(train, test, validation, selected_label='is_fake_news_label', all_labels=label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] -- 8 / 8 -- (finished)tive_author) -- 7 / 8 8\n"
     ]
    }
   ],
   "source": [
    "data.train.features = add_features(data.train.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] -- 8 / 8 -- (finished)tive_author) -- 7 / 8 8\n"
     ]
    }
   ],
   "source": [
    "data.test.features = add_features(data.test.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] -- 8 / 8 -- (finished)tive_author) -- 7 / 8 8\n"
     ]
    }
   ],
   "source": [
    "data.validation.features = add_features(data.validation.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fb_reaction_count_label',\n",
       " 'fb_comment_count_label',\n",
       " 'fb_share_count_label',\n",
       " 'fb_popularity_label',\n",
       " 'is_fake_news_label']"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_to_file(data, file):\n",
    "    with open(file, 'w', encoding='utf-8') as f:\n",
    "        for i in Pbar(data):\n",
    "            f.write(f\"{' '.join(tokenize(i))}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 8 cores available\n"
     ]
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "print(f'>>> {cores} cores available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] -- 65689 / 65689 -- (finished)\n"
     ]
    }
   ],
   "source": [
    "tokenize_to_file(data.train.X.body, './data/train_body_tokenized.txt)\n",
    "tokenize_to_file(data.test.X.body, './data/test_body_tokenized.txt')\n",
    "tokenize_to_file(data.validation.X.body, './data/validation_body_tokenized.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-24 23:28:50,335 : INFO : collecting all words and their counts\n",
      "2020-03-24 23:28:50,337 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2020-03-24 23:28:51,590 : INFO : PROGRESS: at example #10000, processed 4298665 words (3432772/s), 123951 word types, 10000 tags\n",
      "2020-03-24 23:28:52,876 : INFO : PROGRESS: at example #20000, processed 8568952 words (3324739/s), 183544 word types, 20000 tags\n",
      "2020-03-24 23:28:54,350 : INFO : PROGRESS: at example #30000, processed 12895290 words (2935639/s), 233597 word types, 30000 tags\n",
      "2020-03-24 23:28:55,908 : INFO : PROGRESS: at example #40000, processed 17179182 words (2751366/s), 278031 word types, 40000 tags\n",
      "2020-03-24 23:28:58,066 : INFO : PROGRESS: at example #50000, processed 21473433 words (1990505/s), 319044 word types, 50000 tags\n",
      "2020-03-24 23:29:00,432 : INFO : PROGRESS: at example #60000, processed 25781908 words (1821971/s), 357488 word types, 60000 tags\n",
      "2020-03-24 23:29:01,813 : INFO : collected 378633 word types and 65689 unique tags from a corpus of 65689 examples and 28223162 words\n",
      "2020-03-24 23:29:01,814 : INFO : Loading a fresh vocabulary\n",
      "2020-03-24 23:29:02,614 : INFO : effective_min_count=2 retains 183511 unique words (48% of original 378633, drops 195122)\n",
      "2020-03-24 23:29:02,616 : INFO : effective_min_count=2 leaves 28028040 word corpus (99% of original 28223162, drops 195122)\n",
      "2020-03-24 23:29:03,425 : INFO : deleting the raw counts dictionary of 378633 items\n",
      "2020-03-24 23:29:03,435 : INFO : sample=0.001 downsamples 8 most-common words\n",
      "2020-03-24 23:29:03,436 : INFO : downsampling leaves estimated 27902567 word corpus (99.6% of prior 28028040)\n",
      "2020-03-24 23:29:04,114 : INFO : estimated required memory for 183511 words and 300 dimensions: 611008700 bytes\n",
      "2020-03-24 23:29:04,115 : INFO : resetting layer weights\n",
      "2020-03-24 23:29:07,656 : INFO : training model with 8 workers on 183511 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-03-24 23:29:40,614 : INFO : EPOCH 1 - PROGRESS: at 12.59% examples, 107144 words/s, in_qsize -1, out_qsize 1\n",
      "2020-03-24 23:29:40,616 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-24 23:29:40,669 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-24 23:29:41,183 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-24 23:29:41,210 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-24 23:29:46,859 : INFO : EPOCH 1 - PROGRESS: at 62.57% examples, 449725 words/s, in_qsize -1, out_qsize 1\n",
      "2020-03-24 23:29:46,861 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-24 23:29:47,082 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-24 23:29:47,126 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-24 23:29:47,493 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-24 23:29:47,495 : INFO : EPOCH - 1 : training on 28227579 raw words (27971915 effective words) took 39.5s, 707822 effective words/s\n",
      "2020-03-24 23:30:19,254 : INFO : EPOCH 2 - PROGRESS: at 12.59% examples, 111583 words/s, in_qsize -1, out_qsize 1\n",
      "2020-03-24 23:30:19,256 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-24 23:30:19,313 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-24 23:30:19,462 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-24 23:30:19,532 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-24 23:30:24,280 : INFO : EPOCH 2 - PROGRESS: at 62.51% examples, 480774 words/s, in_qsize -1, out_qsize 1\n",
      "2020-03-24 23:30:24,282 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-24 23:30:24,402 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-24 23:30:24,601 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-24 23:30:24,705 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-24 23:30:24,706 : INFO : EPOCH - 2 : training on 28227579 raw words (27972163 effective words) took 36.8s, 760332 effective words/s\n",
      "2020-03-24 23:30:51,347 : INFO : EPOCH 3 - PROGRESS: at 12.53% examples, 132495 words/s, in_qsize -1, out_qsize 1\n",
      "2020-03-24 23:30:51,349 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-24 23:30:51,539 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-24 23:30:51,694 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-24 23:30:51,827 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-24 23:30:53,995 : INFO : EPOCH 3 - PROGRESS: at 62.51% examples, 601985 words/s, in_qsize -1, out_qsize 1\n",
      "2020-03-24 23:30:53,996 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-24 23:30:54,091 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-24 23:30:54,298 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-24 23:30:54,316 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-24 23:30:54,317 : INFO : EPOCH - 3 : training on 28227579 raw words (27972975 effective words) took 29.4s, 952596 effective words/s\n",
      "2020-03-24 23:31:23,101 : INFO : EPOCH 4 - PROGRESS: at 12.49% examples, 122589 words/s, in_qsize -1, out_qsize 1\n",
      "2020-03-24 23:31:23,103 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-24 23:31:23,108 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-24 23:31:23,116 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-24 23:31:23,413 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-24 23:31:26,483 : INFO : EPOCH 4 - PROGRESS: at 62.52% examples, 548022 words/s, in_qsize -1, out_qsize 1\n",
      "2020-03-24 23:31:26,484 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-24 23:31:26,561 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-24 23:31:26,640 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-24 23:31:26,646 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-24 23:31:26,648 : INFO : EPOCH - 4 : training on 28227579 raw words (27972032 effective words) took 32.1s, 872222 effective words/s\n",
      "2020-03-24 23:31:56,723 : INFO : EPOCH 5 - PROGRESS: at 12.49% examples, 117374 words/s, in_qsize -1, out_qsize 1\n",
      "2020-03-24 23:31:56,725 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-24 23:31:56,767 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-24 23:31:56,783 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-24 23:31:56,851 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-24 23:31:59,211 : INFO : EPOCH 5 - PROGRESS: at 62.64% examples, 541694 words/s, in_qsize -1, out_qsize 1\n",
      "2020-03-24 23:31:59,213 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-24 23:31:59,217 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-24 23:31:59,452 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-24 23:31:59,552 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-24 23:31:59,553 : INFO : EPOCH - 5 : training on 28227579 raw words (27972081 effective words) took 32.6s, 857568 effective words/s\n",
      "2020-03-24 23:32:28,221 : INFO : EPOCH 6 - PROGRESS: at 12.49% examples, 123541 words/s, in_qsize -1, out_qsize 1\n",
      "2020-03-24 23:32:28,223 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-24 23:32:28,242 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-24 23:32:28,282 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-24 23:32:28,378 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-24 23:32:32,902 : INFO : EPOCH 6 - PROGRESS: at 62.51% examples, 530047 words/s, in_qsize -1, out_qsize 1\n",
      "2020-03-24 23:32:32,904 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-24 23:32:32,930 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-24 23:32:32,962 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-24 23:32:33,209 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-24 23:32:33,210 : INFO : EPOCH - 6 : training on 28227579 raw words (27972647 effective words) took 33.3s, 840230 effective words/s\n",
      "2020-03-24 23:33:01,392 : INFO : EPOCH 7 - PROGRESS: at 12.49% examples, 125272 words/s, in_qsize -1, out_qsize 1\n",
      "2020-03-24 23:33:01,394 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-24 23:33:01,408 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-24 23:33:01,441 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-24 23:33:01,495 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-24 23:33:05,725 : INFO : EPOCH 7 - PROGRESS: at 62.51% examples, 542217 words/s, in_qsize -1, out_qsize 1\n",
      "2020-03-24 23:33:05,726 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-24 23:33:05,790 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-24 23:33:05,905 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-24 23:33:05,946 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-24 23:33:05,947 : INFO : EPOCH - 7 : training on 28227579 raw words (27972363 effective words) took 32.5s, 861602 effective words/s\n",
      "2020-03-24 23:33:33,733 : INFO : EPOCH 8 - PROGRESS: at 12.49% examples, 126909 words/s, in_qsize -1, out_qsize 1\n",
      "2020-03-24 23:33:33,735 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-24 23:33:33,831 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-24 23:33:33,949 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-24 23:33:34,090 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-24 23:33:37,202 : INFO : EPOCH 8 - PROGRESS: at 62.51% examples, 563389 words/s, in_qsize -1, out_qsize 1\n",
      "2020-03-24 23:33:37,203 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-24 23:33:37,299 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-24 23:33:37,351 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-24 23:33:37,371 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-24 23:33:37,372 : INFO : EPOCH - 8 : training on 28227579 raw words (27972401 effective words) took 31.2s, 896496 effective words/s\n",
      "2020-03-24 23:34:04,532 : INFO : EPOCH 9 - PROGRESS: at 12.59% examples, 130089 words/s, in_qsize -1, out_qsize 1\n",
      "2020-03-24 23:34:04,534 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-24 23:34:04,570 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-24 23:34:04,668 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-24 23:34:04,738 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-24 23:34:06,951 : INFO : EPOCH 9 - PROGRESS: at 62.57% examples, 596785 words/s, in_qsize -1, out_qsize 1\n",
      "2020-03-24 23:34:06,953 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-24 23:34:07,010 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-24 23:34:07,071 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-24 23:34:07,105 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-24 23:34:07,106 : INFO : EPOCH - 9 : training on 28227579 raw words (27972178 effective words) took 29.5s, 949659 effective words/s\n",
      "2020-03-24 23:34:34,635 : INFO : EPOCH 10 - PROGRESS: at 12.49% examples, 128313 words/s, in_qsize -1, out_qsize 1\n",
      "2020-03-24 23:34:34,637 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-24 23:34:34,749 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-24 23:34:34,825 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-24 23:34:34,890 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-24 23:34:37,182 : INFO : EPOCH 10 - PROGRESS: at 62.52% examples, 586794 words/s, in_qsize -1, out_qsize 1\n",
      "2020-03-24 23:34:37,183 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-24 23:34:37,306 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-24 23:34:37,326 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-24 23:34:37,486 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-24 23:34:37,487 : INFO : EPOCH - 10 : training on 28227579 raw words (27972114 effective words) took 30.1s, 929250 effective words/s\n",
      "2020-03-24 23:35:05,353 : INFO : EPOCH 11 - PROGRESS: at 12.49% examples, 126683 words/s, in_qsize -1, out_qsize 1\n",
      "2020-03-24 23:35:05,356 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-24 23:35:05,396 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-24 23:35:05,417 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-24 23:35:05,680 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-24 23:35:08,140 : INFO : EPOCH 11 - PROGRESS: at 62.64% examples, 575395 words/s, in_qsize -1, out_qsize 1\n",
      "2020-03-24 23:35:08,141 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-24 23:35:08,164 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-24 23:35:08,190 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-24 23:35:08,216 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-24 23:35:08,216 : INFO : EPOCH - 11 : training on 28227579 raw words (27972927 effective words) took 30.5s, 918276 effective words/s\n",
      "2020-03-24 23:35:35,813 : INFO : EPOCH 12 - PROGRESS: at 12.49% examples, 127859 words/s, in_qsize -1, out_qsize 1\n",
      "2020-03-24 23:35:35,815 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-24 23:35:35,851 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-24 23:35:35,924 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-24 23:35:36,218 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-24 23:35:38,839 : INFO : EPOCH 12 - PROGRESS: at 62.52% examples, 575460 words/s, in_qsize -1, out_qsize 1\n",
      "2020-03-24 23:35:38,841 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-24 23:35:38,930 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-24 23:35:38,971 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-24 23:35:39,076 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-24 23:35:39,078 : INFO : EPOCH - 12 : training on 28227579 raw words (27971921 effective words) took 30.6s, 913463 effective words/s\n",
      "2020-03-24 23:36:06,740 : INFO : EPOCH 13 - PROGRESS: at 12.59% examples, 127588 words/s, in_qsize -1, out_qsize 1\n",
      "2020-03-24 23:36:06,742 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-24 23:36:06,890 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-24 23:36:06,901 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-24 23:36:06,907 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-24 23:36:08,292 : INFO : EPOCH 13 - PROGRESS: at 62.51% examples, 603665 words/s, in_qsize -1, out_qsize 1\n",
      "2020-03-24 23:36:08,293 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-24 23:36:08,510 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-24 23:36:08,512 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-24 23:36:08,608 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-24 23:36:08,609 : INFO : EPOCH - 13 : training on 28227579 raw words (27972467 effective words) took 29.3s, 955397 effective words/s\n",
      "2020-03-24 23:36:36,549 : INFO : EPOCH 14 - PROGRESS: at 12.49% examples, 126151 words/s, in_qsize -1, out_qsize 1\n",
      "2020-03-24 23:36:36,551 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-24 23:36:36,640 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-24 23:36:36,662 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-24 23:36:36,702 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-24 23:36:39,468 : INFO : EPOCH 14 - PROGRESS: at 62.57% examples, 570590 words/s, in_qsize -1, out_qsize 1\n",
      "2020-03-24 23:36:39,470 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-24 23:36:39,488 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-24 23:36:39,576 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-24 23:36:39,668 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-24 23:36:39,670 : INFO : EPOCH - 14 : training on 28227579 raw words (27972177 effective words) took 30.8s, 906790 effective words/s\n",
      "2020-03-24 23:37:07,971 : INFO : EPOCH 15 - PROGRESS: at 12.49% examples, 125296 words/s, in_qsize -1, out_qsize 1\n",
      "2020-03-24 23:37:07,973 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-03-24 23:37:08,074 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-03-24 23:37:08,302 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-03-24 23:37:08,544 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-03-24 23:37:11,675 : INFO : EPOCH 15 - PROGRESS: at 62.64% examples, 553081 words/s, in_qsize -1, out_qsize 1\n",
      "2020-03-24 23:37:11,677 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-24 23:37:11,814 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-24 23:37:11,958 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-24 23:37:12,039 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-24 23:37:12,040 : INFO : EPOCH - 15 : training on 28227579 raw words (27972141 effective words) took 32.0s, 874815 effective words/s\n",
      "2020-03-24 23:37:12,061 : INFO : training on a 423413685 raw words (419584502 effective words) took 484.4s, 866189 effective words/s\n"
     ]
    }
   ],
   "source": [
    "d2v = Doc2Vec(corpus_file='./data/train_body_tokenized.txt', vector_size=300, min_count=2, epochs=15, workers=cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_d2v(d2v_model, data_file):\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    with open(data_file, 'r', encoding='utf-8') as f:\n",
    "        for i in Pbar(f.readlines()):\n",
    "            res.append(d2v_model.infer_vector(i.split(' '), steps=20, alpha=0.025)) \n",
    "    \n",
    "    return res\n",
    "\n",
    "def infer_for_df(df, d2v_model, data_file):\n",
    "    lst = infer_d2v(d2v_model, data_file)\n",
    "    d2v_df = pd.DataFrame(lst, index=df.index, columns=[f'd2v_{i}' for i in range(1, 301)] )\n",
    "    \n",
    "    return pd.concat([df, d2v_df], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train.features = infer_for_df(data.train.features, d2v, './data/train_body_tokenized.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] -- 65688 / 65688 -- (finished)\n"
     ]
    }
   ],
   "source": [
    "data.test.features = infer_for_df(data.test.features, d2v, './data/test_body_tokenized.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(clf, data):\n",
    "    clf.fit(data.train.features, data.train.y)\n",
    "    return clf.predict(data.test.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train.features['media_count_total'] = pd.to_numeric(data.train.features['media_count_total'])\n",
    "data.train.features['image_count'] = pd.to_numeric(data.train.features['image_count'])\n",
    "data.train.features['video_count'] = pd.to_numeric(data.train.features['video_count'])\n",
    "\n",
    "data.test.features['media_count_total'] = pd.to_numeric(data.test.features['media_count_total'])\n",
    "data.test.features['image_count'] = pd.to_numeric(data.test.features['image_count'])\n",
    "data.test.features['video_count'] = pd.to_numeric(data.test.features['video_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================================================] -- 2 / 2 -- (finished)fier) -- 1 / 2 -- 0 / 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.97      0.71     32588\n",
      "           2       0.48      0.26      0.34     16658\n",
      "           3       0.48      0.06      0.10      9928\n",
      "           4       0.24      0.00      0.00      3302\n",
      "           5       0.40      0.00      0.00      3212\n",
      "\n",
      "    accuracy                           0.55     65688\n",
      "   macro avg       0.43      0.26      0.23     65688\n",
      "weighted avg       0.51      0.55      0.46     65688\n",
      "\n",
      "------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.96      0.72     32588\n",
      "           2       0.47      0.26      0.34     16658\n",
      "           3       0.43      0.09      0.15      9928\n",
      "           4       0.00      0.00      0.00      3302\n",
      "           5       0.29      0.00      0.00      3212\n",
      "\n",
      "    accuracy                           0.55     65688\n",
      "   macro avg       0.35      0.26      0.24     65688\n",
      "weighted avg       0.48      0.55      0.46     65688\n",
      "\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=cores),\n",
    "    XGBClassifier(n_jobs=cores, seed=RANDOM_STATE),\n",
    "]\n",
    "\n",
    "pbar_conf = {\n",
    "    'refresh_rate': 1,\n",
    "    'length': len(classifiers), \n",
    "    'pbar_width': 52,\n",
    "    'action_names': [i.__class__.__name__ for i in classifiers]\n",
    "}\n",
    "\n",
    "predictions = list(Pbar((fit_predict(clf, data) for clf in classifiers), **pbar_conf))\n",
    "\n",
    "for p in predictions:\n",
    "    print(classification_report(data.test.y, p))\n",
    "    print('-' * 54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>perex_word_count</td>\n",
       "      <td>0.011719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>perex_char_length</td>\n",
       "      <td>0.011410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>content_char_length</td>\n",
       "      <td>0.008882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>content_word_count</td>\n",
       "      <td>0.007891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>title_char_length</td>\n",
       "      <td>0.007131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>title_word_count</td>\n",
       "      <td>0.004839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>media_count_total</td>\n",
       "      <td>0.004458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>image_count</td>\n",
       "      <td>0.004145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_287</td>\n",
       "      <td>0.003971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>is_collective_author</td>\n",
       "      <td>0.003797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_83</td>\n",
       "      <td>0.003766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_296</td>\n",
       "      <td>0.003727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_128</td>\n",
       "      <td>0.003615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_66</td>\n",
       "      <td>0.003615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_212</td>\n",
       "      <td>0.003610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_39</td>\n",
       "      <td>0.003589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_110</td>\n",
       "      <td>0.003568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_169</td>\n",
       "      <td>0.003548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_113</td>\n",
       "      <td>0.003545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_260</td>\n",
       "      <td>0.003540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_72</td>\n",
       "      <td>0.003520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_124</td>\n",
       "      <td>0.003467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_78</td>\n",
       "      <td>0.003465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_206</td>\n",
       "      <td>0.003460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_146</td>\n",
       "      <td>0.003449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_256</td>\n",
       "      <td>0.003439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_224</td>\n",
       "      <td>0.003408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_246</td>\n",
       "      <td>0.003404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_223</td>\n",
       "      <td>0.003395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_19</td>\n",
       "      <td>0.003386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_33</td>\n",
       "      <td>0.003381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_38</td>\n",
       "      <td>0.003362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_2</td>\n",
       "      <td>0.003357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_97</td>\n",
       "      <td>0.003354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_108</td>\n",
       "      <td>0.003333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_238</td>\n",
       "      <td>0.003320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_40</td>\n",
       "      <td>0.003317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_119</td>\n",
       "      <td>0.003314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_75</td>\n",
       "      <td>0.003314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_84</td>\n",
       "      <td>0.003313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_22</td>\n",
       "      <td>0.003308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_74</td>\n",
       "      <td>0.003304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_16</td>\n",
       "      <td>0.003296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_186</td>\n",
       "      <td>0.003282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_227</td>\n",
       "      <td>0.003275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_205</td>\n",
       "      <td>0.003266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_62</td>\n",
       "      <td>0.003266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_292</td>\n",
       "      <td>0.003258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_104</td>\n",
       "      <td>0.003258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_133</td>\n",
       "      <td>0.003246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_279</td>\n",
       "      <td>0.003245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_189</td>\n",
       "      <td>0.003244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_290</td>\n",
       "      <td>0.003243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_218</td>\n",
       "      <td>0.003241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_277</td>\n",
       "      <td>0.003241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_139</td>\n",
       "      <td>0.003240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_299</td>\n",
       "      <td>0.003229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_297</td>\n",
       "      <td>0.003225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_132</td>\n",
       "      <td>0.003224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_4</td>\n",
       "      <td>0.003223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_143</td>\n",
       "      <td>0.003222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_55</td>\n",
       "      <td>0.003216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_140</td>\n",
       "      <td>0.003214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_300</td>\n",
       "      <td>0.003211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_80</td>\n",
       "      <td>0.003204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_47</td>\n",
       "      <td>0.003203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_151</td>\n",
       "      <td>0.003202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_291</td>\n",
       "      <td>0.003201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_95</td>\n",
       "      <td>0.003201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_96</td>\n",
       "      <td>0.003197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_148</td>\n",
       "      <td>0.003192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_106</td>\n",
       "      <td>0.003188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_159</td>\n",
       "      <td>0.003188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_48</td>\n",
       "      <td>0.003186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_112</td>\n",
       "      <td>0.003184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_176</td>\n",
       "      <td>0.003182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_228</td>\n",
       "      <td>0.003180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_123</td>\n",
       "      <td>0.003178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_103</td>\n",
       "      <td>0.003175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_219</td>\n",
       "      <td>0.003173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_232</td>\n",
       "      <td>0.003172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_183</td>\n",
       "      <td>0.003166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_28</td>\n",
       "      <td>0.003166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_43</td>\n",
       "      <td>0.003166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_166</td>\n",
       "      <td>0.003165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_200</td>\n",
       "      <td>0.003165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_172</td>\n",
       "      <td>0.003164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_236</td>\n",
       "      <td>0.003163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_51</td>\n",
       "      <td>0.003162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_213</td>\n",
       "      <td>0.003161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_230</td>\n",
       "      <td>0.003159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_138</td>\n",
       "      <td>0.003159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_201</td>\n",
       "      <td>0.003157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_247</td>\n",
       "      <td>0.003156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_49</td>\n",
       "      <td>0.003156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_98</td>\n",
       "      <td>0.003151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_215</td>\n",
       "      <td>0.003151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_10</td>\n",
       "      <td>0.003151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_239</td>\n",
       "      <td>0.003149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_194</td>\n",
       "      <td>0.003149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_31</td>\n",
       "      <td>0.003148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_197</td>\n",
       "      <td>0.003148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_69</td>\n",
       "      <td>0.003147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_254</td>\n",
       "      <td>0.003146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_11</td>\n",
       "      <td>0.003144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_192</td>\n",
       "      <td>0.003143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_155</td>\n",
       "      <td>0.003143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_293</td>\n",
       "      <td>0.003143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_120</td>\n",
       "      <td>0.003142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_6</td>\n",
       "      <td>0.003139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_210</td>\n",
       "      <td>0.003137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_44</td>\n",
       "      <td>0.003136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_204</td>\n",
       "      <td>0.003135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_257</td>\n",
       "      <td>0.003134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_182</td>\n",
       "      <td>0.003133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_174</td>\n",
       "      <td>0.003129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_234</td>\n",
       "      <td>0.003129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_86</td>\n",
       "      <td>0.003126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_156</td>\n",
       "      <td>0.003125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_202</td>\n",
       "      <td>0.003124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_165</td>\n",
       "      <td>0.003122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_286</td>\n",
       "      <td>0.003122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_265</td>\n",
       "      <td>0.003121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_252</td>\n",
       "      <td>0.003121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_35</td>\n",
       "      <td>0.003121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_242</td>\n",
       "      <td>0.003120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_89</td>\n",
       "      <td>0.003120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_284</td>\n",
       "      <td>0.003119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_54</td>\n",
       "      <td>0.003119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_8</td>\n",
       "      <td>0.003117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_77</td>\n",
       "      <td>0.003116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_71</td>\n",
       "      <td>0.003116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_56</td>\n",
       "      <td>0.003115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_102</td>\n",
       "      <td>0.003115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_175</td>\n",
       "      <td>0.003113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_274</td>\n",
       "      <td>0.003112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_20</td>\n",
       "      <td>0.003107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_67</td>\n",
       "      <td>0.003107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_60</td>\n",
       "      <td>0.003106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_41</td>\n",
       "      <td>0.003106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_233</td>\n",
       "      <td>0.003104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_88</td>\n",
       "      <td>0.003104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_23</td>\n",
       "      <td>0.003103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_282</td>\n",
       "      <td>0.003102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_114</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_222</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_295</td>\n",
       "      <td>0.003098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_160</td>\n",
       "      <td>0.003096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_251</td>\n",
       "      <td>0.003095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_65</td>\n",
       "      <td>0.003095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_188</td>\n",
       "      <td>0.003095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_87</td>\n",
       "      <td>0.003094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_91</td>\n",
       "      <td>0.003093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_142</td>\n",
       "      <td>0.003092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_141</td>\n",
       "      <td>0.003092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_34</td>\n",
       "      <td>0.003090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_255</td>\n",
       "      <td>0.003088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_285</td>\n",
       "      <td>0.003087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_264</td>\n",
       "      <td>0.003087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_101</td>\n",
       "      <td>0.003086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_118</td>\n",
       "      <td>0.003085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_154</td>\n",
       "      <td>0.003083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_193</td>\n",
       "      <td>0.003083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_184</td>\n",
       "      <td>0.003080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_262</td>\n",
       "      <td>0.003078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_63</td>\n",
       "      <td>0.003077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_208</td>\n",
       "      <td>0.003076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_30</td>\n",
       "      <td>0.003075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_226</td>\n",
       "      <td>0.003074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_179</td>\n",
       "      <td>0.003074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_157</td>\n",
       "      <td>0.003074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_144</td>\n",
       "      <td>0.003071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_27</td>\n",
       "      <td>0.003071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_217</td>\n",
       "      <td>0.003070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_225</td>\n",
       "      <td>0.003070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_181</td>\n",
       "      <td>0.003070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_190</td>\n",
       "      <td>0.003069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_278</td>\n",
       "      <td>0.003069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_58</td>\n",
       "      <td>0.003067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_93</td>\n",
       "      <td>0.003067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_134</td>\n",
       "      <td>0.003067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_115</td>\n",
       "      <td>0.003066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_268</td>\n",
       "      <td>0.003066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_82</td>\n",
       "      <td>0.003061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_170</td>\n",
       "      <td>0.003060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_171</td>\n",
       "      <td>0.003059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_5</td>\n",
       "      <td>0.003059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_122</td>\n",
       "      <td>0.003057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_243</td>\n",
       "      <td>0.003057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_131</td>\n",
       "      <td>0.003056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_137</td>\n",
       "      <td>0.003050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_280</td>\n",
       "      <td>0.003048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_207</td>\n",
       "      <td>0.003046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_73</td>\n",
       "      <td>0.003045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_178</td>\n",
       "      <td>0.003044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_231</td>\n",
       "      <td>0.003044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_241</td>\n",
       "      <td>0.003043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_130</td>\n",
       "      <td>0.003042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_15</td>\n",
       "      <td>0.003040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_244</td>\n",
       "      <td>0.003040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_42</td>\n",
       "      <td>0.003039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_45</td>\n",
       "      <td>0.003039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_288</td>\n",
       "      <td>0.003039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_258</td>\n",
       "      <td>0.003039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_162</td>\n",
       "      <td>0.003039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_261</td>\n",
       "      <td>0.003037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_111</td>\n",
       "      <td>0.003036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_13</td>\n",
       "      <td>0.003034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_127</td>\n",
       "      <td>0.003033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_248</td>\n",
       "      <td>0.003031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_64</td>\n",
       "      <td>0.003031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_269</td>\n",
       "      <td>0.003030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_152</td>\n",
       "      <td>0.003030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_18</td>\n",
       "      <td>0.003026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_196</td>\n",
       "      <td>0.003024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_7</td>\n",
       "      <td>0.003022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_52</td>\n",
       "      <td>0.003022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_289</td>\n",
       "      <td>0.003020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_92</td>\n",
       "      <td>0.003019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_61</td>\n",
       "      <td>0.003019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_94</td>\n",
       "      <td>0.003019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_57</td>\n",
       "      <td>0.003018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_275</td>\n",
       "      <td>0.003018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_214</td>\n",
       "      <td>0.003016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_76</td>\n",
       "      <td>0.003016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_209</td>\n",
       "      <td>0.003015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_276</td>\n",
       "      <td>0.003012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_168</td>\n",
       "      <td>0.003009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_79</td>\n",
       "      <td>0.003009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_249</td>\n",
       "      <td>0.003008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_150</td>\n",
       "      <td>0.003006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_25</td>\n",
       "      <td>0.003004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_46</td>\n",
       "      <td>0.003003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_161</td>\n",
       "      <td>0.003002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_121</td>\n",
       "      <td>0.003001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_237</td>\n",
       "      <td>0.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_116</td>\n",
       "      <td>0.002996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_149</td>\n",
       "      <td>0.002995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_50</td>\n",
       "      <td>0.002994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_298</td>\n",
       "      <td>0.002992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_147</td>\n",
       "      <td>0.002990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_17</td>\n",
       "      <td>0.002989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_203</td>\n",
       "      <td>0.002989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_68</td>\n",
       "      <td>0.002989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_198</td>\n",
       "      <td>0.002988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_36</td>\n",
       "      <td>0.002986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_216</td>\n",
       "      <td>0.002984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_107</td>\n",
       "      <td>0.002984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_211</td>\n",
       "      <td>0.002984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_3</td>\n",
       "      <td>0.002983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_129</td>\n",
       "      <td>0.002982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_90</td>\n",
       "      <td>0.002982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_185</td>\n",
       "      <td>0.002982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_250</td>\n",
       "      <td>0.002981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_9</td>\n",
       "      <td>0.002980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_281</td>\n",
       "      <td>0.002976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_263</td>\n",
       "      <td>0.002973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_229</td>\n",
       "      <td>0.002973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_180</td>\n",
       "      <td>0.002972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_32</td>\n",
       "      <td>0.002972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_187</td>\n",
       "      <td>0.002970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_145</td>\n",
       "      <td>0.002970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_266</td>\n",
       "      <td>0.002967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_273</td>\n",
       "      <td>0.002967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_199</td>\n",
       "      <td>0.002956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_240</td>\n",
       "      <td>0.002954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_109</td>\n",
       "      <td>0.002954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_85</td>\n",
       "      <td>0.002953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_117</td>\n",
       "      <td>0.002953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_81</td>\n",
       "      <td>0.002951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_164</td>\n",
       "      <td>0.002948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_191</td>\n",
       "      <td>0.002948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_245</td>\n",
       "      <td>0.002946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_59</td>\n",
       "      <td>0.002944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_26</td>\n",
       "      <td>0.002944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_283</td>\n",
       "      <td>0.002943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_177</td>\n",
       "      <td>0.002942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_14</td>\n",
       "      <td>0.002941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_173</td>\n",
       "      <td>0.002940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_29</td>\n",
       "      <td>0.002939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_272</td>\n",
       "      <td>0.002934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_253</td>\n",
       "      <td>0.002932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_100</td>\n",
       "      <td>0.002932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_126</td>\n",
       "      <td>0.002928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_259</td>\n",
       "      <td>0.002923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_21</td>\n",
       "      <td>0.002922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_158</td>\n",
       "      <td>0.002921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_1</td>\n",
       "      <td>0.002921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_153</td>\n",
       "      <td>0.002919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_37</td>\n",
       "      <td>0.002917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_267</td>\n",
       "      <td>0.002917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_24</td>\n",
       "      <td>0.002916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_99</td>\n",
       "      <td>0.002912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_136</td>\n",
       "      <td>0.002912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_12</td>\n",
       "      <td>0.002912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_270</td>\n",
       "      <td>0.002910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_220</td>\n",
       "      <td>0.002908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_53</td>\n",
       "      <td>0.002907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_70</td>\n",
       "      <td>0.002896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_294</td>\n",
       "      <td>0.002895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_125</td>\n",
       "      <td>0.002894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_221</td>\n",
       "      <td>0.002892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_195</td>\n",
       "      <td>0.002888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_135</td>\n",
       "      <td>0.002886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_167</td>\n",
       "      <td>0.002868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_105</td>\n",
       "      <td>0.002867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_235</td>\n",
       "      <td>0.002848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_271</td>\n",
       "      <td>0.002822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d2v_163</td>\n",
       "      <td>0.002815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>published_on_day</td>\n",
       "      <td>0.001432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>video_count</td>\n",
       "      <td>0.001210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      importance\n",
       "perex_word_count        0.011719\n",
       "perex_char_length       0.011410\n",
       "content_char_length     0.008882\n",
       "content_word_count      0.007891\n",
       "title_char_length       0.007131\n",
       "title_word_count        0.004839\n",
       "media_count_total       0.004458\n",
       "image_count             0.004145\n",
       "d2v_287                 0.003971\n",
       "is_collective_author    0.003797\n",
       "d2v_83                  0.003766\n",
       "d2v_296                 0.003727\n",
       "d2v_128                 0.003615\n",
       "d2v_66                  0.003615\n",
       "d2v_212                 0.003610\n",
       "d2v_39                  0.003589\n",
       "d2v_110                 0.003568\n",
       "d2v_169                 0.003548\n",
       "d2v_113                 0.003545\n",
       "d2v_260                 0.003540\n",
       "d2v_72                  0.003520\n",
       "d2v_124                 0.003467\n",
       "d2v_78                  0.003465\n",
       "d2v_206                 0.003460\n",
       "d2v_146                 0.003449\n",
       "d2v_256                 0.003439\n",
       "d2v_224                 0.003408\n",
       "d2v_246                 0.003404\n",
       "d2v_223                 0.003395\n",
       "d2v_19                  0.003386\n",
       "d2v_33                  0.003381\n",
       "d2v_38                  0.003362\n",
       "d2v_2                   0.003357\n",
       "d2v_97                  0.003354\n",
       "d2v_108                 0.003333\n",
       "d2v_238                 0.003320\n",
       "d2v_40                  0.003317\n",
       "d2v_119                 0.003314\n",
       "d2v_75                  0.003314\n",
       "d2v_84                  0.003313\n",
       "d2v_22                  0.003308\n",
       "d2v_74                  0.003304\n",
       "d2v_16                  0.003296\n",
       "d2v_186                 0.003282\n",
       "d2v_227                 0.003275\n",
       "d2v_205                 0.003266\n",
       "d2v_62                  0.003266\n",
       "d2v_292                 0.003258\n",
       "d2v_104                 0.003258\n",
       "d2v_133                 0.003246\n",
       "d2v_279                 0.003245\n",
       "d2v_189                 0.003244\n",
       "d2v_290                 0.003243\n",
       "d2v_218                 0.003241\n",
       "d2v_277                 0.003241\n",
       "d2v_139                 0.003240\n",
       "d2v_299                 0.003229\n",
       "d2v_297                 0.003225\n",
       "d2v_132                 0.003224\n",
       "d2v_4                   0.003223\n",
       "d2v_143                 0.003222\n",
       "d2v_55                  0.003216\n",
       "d2v_140                 0.003214\n",
       "d2v_300                 0.003211\n",
       "d2v_80                  0.003204\n",
       "d2v_47                  0.003203\n",
       "d2v_151                 0.003202\n",
       "d2v_291                 0.003201\n",
       "d2v_95                  0.003201\n",
       "d2v_96                  0.003197\n",
       "d2v_148                 0.003192\n",
       "d2v_106                 0.003188\n",
       "d2v_159                 0.003188\n",
       "d2v_48                  0.003186\n",
       "d2v_112                 0.003184\n",
       "d2v_176                 0.003182\n",
       "d2v_228                 0.003180\n",
       "d2v_123                 0.003178\n",
       "d2v_103                 0.003175\n",
       "d2v_219                 0.003173\n",
       "d2v_232                 0.003172\n",
       "d2v_183                 0.003166\n",
       "d2v_28                  0.003166\n",
       "d2v_43                  0.003166\n",
       "d2v_166                 0.003165\n",
       "d2v_200                 0.003165\n",
       "d2v_172                 0.003164\n",
       "d2v_236                 0.003163\n",
       "d2v_51                  0.003162\n",
       "d2v_213                 0.003161\n",
       "d2v_230                 0.003159\n",
       "d2v_138                 0.003159\n",
       "d2v_201                 0.003157\n",
       "d2v_247                 0.003156\n",
       "d2v_49                  0.003156\n",
       "d2v_98                  0.003151\n",
       "d2v_215                 0.003151\n",
       "d2v_10                  0.003151\n",
       "d2v_239                 0.003149\n",
       "d2v_194                 0.003149\n",
       "d2v_31                  0.003148\n",
       "d2v_197                 0.003148\n",
       "d2v_69                  0.003147\n",
       "d2v_254                 0.003146\n",
       "d2v_11                  0.003144\n",
       "d2v_192                 0.003143\n",
       "d2v_155                 0.003143\n",
       "d2v_293                 0.003143\n",
       "d2v_120                 0.003142\n",
       "d2v_6                   0.003139\n",
       "d2v_210                 0.003137\n",
       "d2v_44                  0.003136\n",
       "d2v_204                 0.003135\n",
       "d2v_257                 0.003134\n",
       "d2v_182                 0.003133\n",
       "d2v_174                 0.003129\n",
       "d2v_234                 0.003129\n",
       "d2v_86                  0.003126\n",
       "d2v_156                 0.003125\n",
       "d2v_202                 0.003124\n",
       "d2v_165                 0.003122\n",
       "d2v_286                 0.003122\n",
       "d2v_265                 0.003121\n",
       "d2v_252                 0.003121\n",
       "d2v_35                  0.003121\n",
       "d2v_242                 0.003120\n",
       "d2v_89                  0.003120\n",
       "d2v_284                 0.003119\n",
       "d2v_54                  0.003119\n",
       "d2v_8                   0.003117\n",
       "d2v_77                  0.003116\n",
       "d2v_71                  0.003116\n",
       "d2v_56                  0.003115\n",
       "d2v_102                 0.003115\n",
       "d2v_175                 0.003113\n",
       "d2v_274                 0.003112\n",
       "d2v_20                  0.003107\n",
       "d2v_67                  0.003107\n",
       "d2v_60                  0.003106\n",
       "d2v_41                  0.003106\n",
       "d2v_233                 0.003104\n",
       "d2v_88                  0.003104\n",
       "d2v_23                  0.003103\n",
       "d2v_282                 0.003102\n",
       "d2v_114                 0.003100\n",
       "d2v_222                 0.003100\n",
       "d2v_295                 0.003098\n",
       "d2v_160                 0.003096\n",
       "d2v_251                 0.003095\n",
       "d2v_65                  0.003095\n",
       "d2v_188                 0.003095\n",
       "d2v_87                  0.003094\n",
       "d2v_91                  0.003093\n",
       "d2v_142                 0.003092\n",
       "d2v_141                 0.003092\n",
       "d2v_34                  0.003090\n",
       "d2v_255                 0.003088\n",
       "d2v_285                 0.003087\n",
       "d2v_264                 0.003087\n",
       "d2v_101                 0.003086\n",
       "d2v_118                 0.003085\n",
       "d2v_154                 0.003083\n",
       "d2v_193                 0.003083\n",
       "d2v_184                 0.003080\n",
       "d2v_262                 0.003078\n",
       "d2v_63                  0.003077\n",
       "d2v_208                 0.003076\n",
       "d2v_30                  0.003075\n",
       "d2v_226                 0.003074\n",
       "d2v_179                 0.003074\n",
       "d2v_157                 0.003074\n",
       "d2v_144                 0.003071\n",
       "d2v_27                  0.003071\n",
       "d2v_217                 0.003070\n",
       "d2v_225                 0.003070\n",
       "d2v_181                 0.003070\n",
       "d2v_190                 0.003069\n",
       "d2v_278                 0.003069\n",
       "d2v_58                  0.003067\n",
       "d2v_93                  0.003067\n",
       "d2v_134                 0.003067\n",
       "d2v_115                 0.003066\n",
       "d2v_268                 0.003066\n",
       "d2v_82                  0.003061\n",
       "d2v_170                 0.003060\n",
       "d2v_171                 0.003059\n",
       "d2v_5                   0.003059\n",
       "d2v_122                 0.003057\n",
       "d2v_243                 0.003057\n",
       "d2v_131                 0.003056\n",
       "d2v_137                 0.003050\n",
       "d2v_280                 0.003048\n",
       "d2v_207                 0.003046\n",
       "d2v_73                  0.003045\n",
       "d2v_178                 0.003044\n",
       "d2v_231                 0.003044\n",
       "d2v_241                 0.003043\n",
       "d2v_130                 0.003042\n",
       "d2v_15                  0.003040\n",
       "d2v_244                 0.003040\n",
       "d2v_42                  0.003039\n",
       "d2v_45                  0.003039\n",
       "d2v_288                 0.003039\n",
       "d2v_258                 0.003039\n",
       "d2v_162                 0.003039\n",
       "d2v_261                 0.003037\n",
       "d2v_111                 0.003036\n",
       "d2v_13                  0.003034\n",
       "d2v_127                 0.003033\n",
       "d2v_248                 0.003031\n",
       "d2v_64                  0.003031\n",
       "d2v_269                 0.003030\n",
       "d2v_152                 0.003030\n",
       "d2v_18                  0.003026\n",
       "d2v_196                 0.003024\n",
       "d2v_7                   0.003022\n",
       "d2v_52                  0.003022\n",
       "d2v_289                 0.003020\n",
       "d2v_92                  0.003019\n",
       "d2v_61                  0.003019\n",
       "d2v_94                  0.003019\n",
       "d2v_57                  0.003018\n",
       "d2v_275                 0.003018\n",
       "d2v_214                 0.003016\n",
       "d2v_76                  0.003016\n",
       "d2v_209                 0.003015\n",
       "d2v_276                 0.003012\n",
       "d2v_168                 0.003009\n",
       "d2v_79                  0.003009\n",
       "d2v_249                 0.003008\n",
       "d2v_150                 0.003006\n",
       "d2v_25                  0.003004\n",
       "d2v_46                  0.003003\n",
       "d2v_161                 0.003002\n",
       "d2v_121                 0.003001\n",
       "d2v_237                 0.003000\n",
       "d2v_116                 0.002996\n",
       "d2v_149                 0.002995\n",
       "d2v_50                  0.002994\n",
       "d2v_298                 0.002992\n",
       "d2v_147                 0.002990\n",
       "d2v_17                  0.002989\n",
       "d2v_203                 0.002989\n",
       "d2v_68                  0.002989\n",
       "d2v_198                 0.002988\n",
       "d2v_36                  0.002986\n",
       "d2v_216                 0.002984\n",
       "d2v_107                 0.002984\n",
       "d2v_211                 0.002984\n",
       "d2v_3                   0.002983\n",
       "d2v_129                 0.002982\n",
       "d2v_90                  0.002982\n",
       "d2v_185                 0.002982\n",
       "d2v_250                 0.002981\n",
       "d2v_9                   0.002980\n",
       "d2v_281                 0.002976\n",
       "d2v_263                 0.002973\n",
       "d2v_229                 0.002973\n",
       "d2v_180                 0.002972\n",
       "d2v_32                  0.002972\n",
       "d2v_187                 0.002970\n",
       "d2v_145                 0.002970\n",
       "d2v_266                 0.002967\n",
       "d2v_273                 0.002967\n",
       "d2v_199                 0.002956\n",
       "d2v_240                 0.002954\n",
       "d2v_109                 0.002954\n",
       "d2v_85                  0.002953\n",
       "d2v_117                 0.002953\n",
       "d2v_81                  0.002951\n",
       "d2v_164                 0.002948\n",
       "d2v_191                 0.002948\n",
       "d2v_245                 0.002946\n",
       "d2v_59                  0.002944\n",
       "d2v_26                  0.002944\n",
       "d2v_283                 0.002943\n",
       "d2v_177                 0.002942\n",
       "d2v_14                  0.002941\n",
       "d2v_173                 0.002940\n",
       "d2v_29                  0.002939\n",
       "d2v_272                 0.002934\n",
       "d2v_253                 0.002932\n",
       "d2v_100                 0.002932\n",
       "d2v_126                 0.002928\n",
       "d2v_259                 0.002923\n",
       "d2v_21                  0.002922\n",
       "d2v_158                 0.002921\n",
       "d2v_1                   0.002921\n",
       "d2v_153                 0.002919\n",
       "d2v_37                  0.002917\n",
       "d2v_267                 0.002917\n",
       "d2v_24                  0.002916\n",
       "d2v_99                  0.002912\n",
       "d2v_136                 0.002912\n",
       "d2v_12                  0.002912\n",
       "d2v_270                 0.002910\n",
       "d2v_220                 0.002908\n",
       "d2v_53                  0.002907\n",
       "d2v_70                  0.002896\n",
       "d2v_294                 0.002895\n",
       "d2v_125                 0.002894\n",
       "d2v_221                 0.002892\n",
       "d2v_195                 0.002888\n",
       "d2v_135                 0.002886\n",
       "d2v_167                 0.002868\n",
       "d2v_105                 0.002867\n",
       "d2v_235                 0.002848\n",
       "d2v_271                 0.002822\n",
       "d2v_163                 0.002815\n",
       "published_on_day        0.001432\n",
       "video_count             0.001210"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_all(pd.DataFrame((i for i in classifiers[0].feature_importances_), index=data.train.features.columns, columns=['importance']).sort_values(by=['importance'], ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_importances(classifiers[0], data.train.features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        0\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "65684    1\n",
       "65685    1\n",
       "65686    0\n",
       "65687    1\n",
       "65688    1\n",
       "Name: is_fake_news_label, Length: 65689, dtype: int64"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train.y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
