{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlalchemy\n",
    "import gensim\n",
    "import logging\n",
    "import empath\n",
    "\n",
    "import common\n",
    "import util\n",
    "importlib.reload(common)\n",
    "importlib.reload(util)\n",
    "\n",
    "from common import create_engine\n",
    "from common import display_all\n",
    "from common import figsize\n",
    "from common import save_df, load_df\n",
    "from common import save_session, load_session\n",
    "\n",
    "from util import show_importances\n",
    "from util import split_X_y_all, split_X_y, split_data\n",
    "from util import empty_features, column_feature, str_contains\n",
    "\n",
    "from pbar import Pbar\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "\n",
    "register_matplotlib_converters() # converters e.g. for datetime in plots\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 123\n",
    "np_random = np.random.RandomState(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_df('final_data.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>perex</th>\n",
       "      <th>body</th>\n",
       "      <th>raw_body</th>\n",
       "      <th>published_at</th>\n",
       "      <th>extracted_at</th>\n",
       "      <th>category</th>\n",
       "      <th>other_info</th>\n",
       "      <th>image_count</th>\n",
       "      <th>video_count</th>\n",
       "      <th>...</th>\n",
       "      <th>fb_popularity_ad_2</th>\n",
       "      <th>fb_popularity_ad_3</th>\n",
       "      <th>fb_popularity_ad_4</th>\n",
       "      <th>fb_popularity_ad_5</th>\n",
       "      <th>fb_popularity_ad_6</th>\n",
       "      <th>fb_popularity_ad_7</th>\n",
       "      <th>fb_popularity_ad_8</th>\n",
       "      <th>fb_popularity_ad_9</th>\n",
       "      <th>fb_popularity_ad_10</th>\n",
       "      <th>body_urls</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>431065</th>\n",
       "      <td>put communities at the center of universal hea...</td>\n",
       "      <td>if universal health care is truly meant to ref...</td>\n",
       "      <td>if universal health care is truly meant to ref...</td>\n",
       "      <td>&lt;p&gt;The &lt;a href=\"https://www.who.int/news-room/...</td>\n",
       "      <td>2019-10-21 10:45:10</td>\n",
       "      <td>2019-10-21 12:13:53.281652</td>\n",
       "      <td>[First Opinion]</td>\n",
       "      <td>{'tags': ['public health', 'global health', 'H...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>165.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>[https://www.statnews.com/2019/10/21/communiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431066</th>\n",
       "      <td>rapid expansion of telehealth comes with new c...</td>\n",
       "      <td>although new delivery methods will help telehe...</td>\n",
       "      <td>although new delivery methods will help telehe...</td>\n",
       "      <td>&lt;p&gt;It&amp;#x2019;s a boom time for telehealth. Sta...</td>\n",
       "      <td>2019-10-21 10:40:26</td>\n",
       "      <td>2019-10-21 12:13:53.499347</td>\n",
       "      <td>[First Opinion]</td>\n",
       "      <td>{'tags': ['telehealth'], 'keywords': ['']}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>[https://www.statnews.com/2019/10/21/telehealt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431067</th>\n",
       "      <td>a biotech real estate firm wants a new slogan....</td>\n",
       "      <td>alexandria real estate, the lab-focused manage...</td>\n",
       "      <td>alexandria real estate, the lab-focused manage...</td>\n",
       "      <td>&lt;p&gt;Embattled office-subleasing and &amp;#x201C;&lt;a ...</td>\n",
       "      <td>2019-10-21 10:35:01</td>\n",
       "      <td>2019-10-21 12:13:53.593596</td>\n",
       "      <td>[Biotech]</td>\n",
       "      <td>{'tags': ['legal', 'ethics', 'STAT Plus', 'bio...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>[https://www.statnews.com/2019/10/21/wework-ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431068</th>\n",
       "      <td>after decades-long campaign, type 3 poliovirus...</td>\n",
       "      <td>the formal bid to eradicate all polio began in...</td>\n",
       "      <td>the formal bid to eradicate all polio began in...</td>\n",
       "      <td>&lt;p&gt;After &lt;a href=\"https://www.statnews.com/201...</td>\n",
       "      <td>2019-10-21 10:30:40</td>\n",
       "      <td>2019-10-21 12:13:53.714328</td>\n",
       "      <td>[Health]</td>\n",
       "      <td>{'tags': ['public health', 'infectious disease...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>617.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>698.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>709.0</td>\n",
       "      <td>913.0</td>\n",
       "      <td>1137.0</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>1232.0</td>\n",
       "      <td>[https://www.statnews.com/2019/10/21/decades-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431081</th>\n",
       "      <td>be humble, and proudly, psychologists say</td>\n",
       "      <td>humility is not the boldest of personality tra...</td>\n",
       "      <td>humility is not the boldest of personality tra...</td>\n",
       "      <td></td>\n",
       "      <td>2019-10-21 00:00:00</td>\n",
       "      <td>2019-10-21 12:14:05.770730</td>\n",
       "      <td>None</td>\n",
       "      <td>{'tags': [], 'keywords': ['']}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3714.0</td>\n",
       "      <td>4217.0</td>\n",
       "      <td>5480.0</td>\n",
       "      <td>8674.0</td>\n",
       "      <td>9476.0</td>\n",
       "      <td>9867.0</td>\n",
       "      <td>10241.0</td>\n",
       "      <td>10792.0</td>\n",
       "      <td>11391.0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  \\\n",
       "id                                                          \n",
       "431065  put communities at the center of universal hea...   \n",
       "431066  rapid expansion of telehealth comes with new c...   \n",
       "431067  a biotech real estate firm wants a new slogan....   \n",
       "431068  after decades-long campaign, type 3 poliovirus...   \n",
       "431081          be humble, and proudly, psychologists say   \n",
       "\n",
       "                                                    perex  \\\n",
       "id                                                          \n",
       "431065  if universal health care is truly meant to ref...   \n",
       "431066  although new delivery methods will help telehe...   \n",
       "431067  alexandria real estate, the lab-focused manage...   \n",
       "431068  the formal bid to eradicate all polio began in...   \n",
       "431081  humility is not the boldest of personality tra...   \n",
       "\n",
       "                                                     body  \\\n",
       "id                                                          \n",
       "431065  if universal health care is truly meant to ref...   \n",
       "431066  although new delivery methods will help telehe...   \n",
       "431067  alexandria real estate, the lab-focused manage...   \n",
       "431068  the formal bid to eradicate all polio began in...   \n",
       "431081  humility is not the boldest of personality tra...   \n",
       "\n",
       "                                                 raw_body        published_at  \\\n",
       "id                                                                              \n",
       "431065  <p>The <a href=\"https://www.who.int/news-room/... 2019-10-21 10:45:10   \n",
       "431066  <p>It&#x2019;s a boom time for telehealth. Sta... 2019-10-21 10:40:26   \n",
       "431067  <p>Embattled office-subleasing and &#x201C;<a ... 2019-10-21 10:35:01   \n",
       "431068  <p>After <a href=\"https://www.statnews.com/201... 2019-10-21 10:30:40   \n",
       "431081                                                    2019-10-21 00:00:00   \n",
       "\n",
       "                     extracted_at         category  \\\n",
       "id                                                   \n",
       "431065 2019-10-21 12:13:53.281652  [First Opinion]   \n",
       "431066 2019-10-21 12:13:53.499347  [First Opinion]   \n",
       "431067 2019-10-21 12:13:53.593596        [Biotech]   \n",
       "431068 2019-10-21 12:13:53.714328         [Health]   \n",
       "431081 2019-10-21 12:14:05.770730             None   \n",
       "\n",
       "                                               other_info  image_count  \\\n",
       "id                                                                       \n",
       "431065  {'tags': ['public health', 'global health', 'H...            1   \n",
       "431066         {'tags': ['telehealth'], 'keywords': ['']}            1   \n",
       "431067  {'tags': ['legal', 'ethics', 'STAT Plus', 'bio...            1   \n",
       "431068  {'tags': ['public health', 'infectious disease...            1   \n",
       "431081                     {'tags': [], 'keywords': ['']}            1   \n",
       "\n",
       "        video_count  ... fb_popularity_ad_2  fb_popularity_ad_3  \\\n",
       "id                   ...                                          \n",
       "431065            0  ...              165.0               176.0   \n",
       "431066            0  ...               44.0                47.0   \n",
       "431067            0  ...                7.0                 7.0   \n",
       "431068            0  ...              617.0               673.0   \n",
       "431081            0  ...             3714.0              4217.0   \n",
       "\n",
       "       fb_popularity_ad_4 fb_popularity_ad_5 fb_popularity_ad_6  \\\n",
       "id                                                                \n",
       "431065              185.0              192.0              193.0   \n",
       "431066               47.0               47.0               49.0   \n",
       "431067                7.0               10.0               14.0   \n",
       "431068              698.0              705.0              709.0   \n",
       "431081             5480.0             8674.0             9476.0   \n",
       "\n",
       "        fb_popularity_ad_7 fb_popularity_ad_8  fb_popularity_ad_9  \\\n",
       "id                                                                  \n",
       "431065               207.0              210.0               228.0   \n",
       "431066                55.0               56.0                62.0   \n",
       "431067                18.0               19.0                19.0   \n",
       "431068               913.0             1137.0              1197.0   \n",
       "431081              9867.0            10241.0             10792.0   \n",
       "\n",
       "        fb_popularity_ad_10                                          body_urls  \n",
       "id                                                                              \n",
       "431065                233.0  [https://www.statnews.com/2019/10/21/communiti...  \n",
       "431066                 67.0  [https://www.statnews.com/2019/10/21/telehealt...  \n",
       "431067                 19.0  [https://www.statnews.com/2019/10/21/wework-ch...  \n",
       "431068               1232.0  [https://www.statnews.com/2019/10/21/decades-l...  \n",
       "431081              11391.0                                                 []  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18605 entries, 431065 to 812426\n",
      "Data columns (total 68 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   title                    18605 non-null  object        \n",
      " 1   perex                    18605 non-null  object        \n",
      " 2   body                     18605 non-null  object        \n",
      " 3   raw_body                 18605 non-null  object        \n",
      " 4   published_at             18605 non-null  datetime64[ns]\n",
      " 5   extracted_at             18605 non-null  datetime64[ns]\n",
      " 6   category                 13024 non-null  object        \n",
      " 7   other_info               18601 non-null  object        \n",
      " 8   image_count              18605 non-null  int64         \n",
      " 9   video_count              18605 non-null  int64         \n",
      " 10  author_name              18605 non-null  object        \n",
      " 11  source_id                18605 non-null  int64         \n",
      " 12  source_name              18605 non-null  object        \n",
      " 13  source_url               18605 non-null  object        \n",
      " 14  source_type              18605 non-null  object        \n",
      " 15  source_is_reliable       18605 non-null  int64         \n",
      " 16  av_veracity              3754 non-null   object        \n",
      " 17  av_claims_false          18605 non-null  int64         \n",
      " 18  av_claims_mostly_false   18605 non-null  int64         \n",
      " 19  av_claims_mixture        18605 non-null  int64         \n",
      " 20  av_claims_mostly_true    18605 non-null  int64         \n",
      " 21  av_claims_true           18605 non-null  int64         \n",
      " 22  av_claims_unknown        18605 non-null  int64         \n",
      " 23  fb_ad_0_comment_count    18605 non-null  float64       \n",
      " 24  fb_ad_1_comment_count    18605 non-null  float64       \n",
      " 25  fb_ad_2_comment_count    18605 non-null  float64       \n",
      " 26  fb_ad_3_comment_count    18605 non-null  float64       \n",
      " 27  fb_ad_4_comment_count    18605 non-null  float64       \n",
      " 28  fb_ad_5_comment_count    18605 non-null  float64       \n",
      " 29  fb_ad_6_comment_count    18605 non-null  float64       \n",
      " 30  fb_ad_7_comment_count    18605 non-null  float64       \n",
      " 31  fb_ad_8_comment_count    18605 non-null  float64       \n",
      " 32  fb_ad_9_comment_count    18605 non-null  float64       \n",
      " 33  fb_ad_10_comment_count   18605 non-null  float64       \n",
      " 34  fb_ad_0_reaction_count   18605 non-null  float64       \n",
      " 35  fb_ad_1_reaction_count   18605 non-null  float64       \n",
      " 36  fb_ad_2_reaction_count   18605 non-null  float64       \n",
      " 37  fb_ad_3_reaction_count   18605 non-null  float64       \n",
      " 38  fb_ad_4_reaction_count   18605 non-null  float64       \n",
      " 39  fb_ad_5_reaction_count   18605 non-null  float64       \n",
      " 40  fb_ad_6_reaction_count   18605 non-null  float64       \n",
      " 41  fb_ad_7_reaction_count   18605 non-null  float64       \n",
      " 42  fb_ad_8_reaction_count   18605 non-null  float64       \n",
      " 43  fb_ad_9_reaction_count   18605 non-null  float64       \n",
      " 44  fb_ad_10_reaction_count  18605 non-null  float64       \n",
      " 45  fb_ad_0_share_count      18605 non-null  float64       \n",
      " 46  fb_ad_1_share_count      18605 non-null  float64       \n",
      " 47  fb_ad_2_share_count      18605 non-null  float64       \n",
      " 48  fb_ad_3_share_count      18605 non-null  float64       \n",
      " 49  fb_ad_4_share_count      18605 non-null  float64       \n",
      " 50  fb_ad_5_share_count      18605 non-null  float64       \n",
      " 51  fb_ad_6_share_count      18605 non-null  float64       \n",
      " 52  fb_ad_7_share_count      18605 non-null  float64       \n",
      " 53  fb_ad_8_share_count      18605 non-null  float64       \n",
      " 54  fb_ad_9_share_count      18605 non-null  float64       \n",
      " 55  fb_ad_10_share_count     18605 non-null  float64       \n",
      " 56  fb_popularity_ad_0       18605 non-null  float64       \n",
      " 57  fb_popularity_ad_1       18605 non-null  float64       \n",
      " 58  fb_popularity_ad_2       18605 non-null  float64       \n",
      " 59  fb_popularity_ad_3       18605 non-null  float64       \n",
      " 60  fb_popularity_ad_4       18605 non-null  float64       \n",
      " 61  fb_popularity_ad_5       18605 non-null  float64       \n",
      " 62  fb_popularity_ad_6       18605 non-null  float64       \n",
      " 63  fb_popularity_ad_7       18605 non-null  float64       \n",
      " 64  fb_popularity_ad_8       18605 non-null  float64       \n",
      " 65  fb_popularity_ad_9       18605 non-null  float64       \n",
      " 66  fb_popularity_ad_10      18605 non-null  float64       \n",
      " 67  body_urls                18605 non-null  object        \n",
      "dtypes: datetime64[ns](2), float64(44), int64(10), object(12)\n",
      "memory usage: 9.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "          \\item NepopulÃ¡rne sprÃ¡vy 0 - 0.6\n",
    "            \\item BeÅ¾nÃ© sprÃ¡vy  0.6 - 0.8\n",
    "            \\item PopulÃ¡rne sprÃ¡vy - 0.8 - 0.9\n",
    "            \\item VeÄ¾mi populÃ¡rne sprÃ¡vy 0.9 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q</th>\n",
       "      <th>fb_popularity_ad_0</th>\n",
       "      <th>fb_popularity_ad_1</th>\n",
       "      <th>fb_popularity_ad_2</th>\n",
       "      <th>fb_popularity_ad_3</th>\n",
       "      <th>fb_popularity_ad_4</th>\n",
       "      <th>fb_popularity_ad_5</th>\n",
       "      <th>fb_popularity_ad_6</th>\n",
       "      <th>fb_popularity_ad_7</th>\n",
       "      <th>fb_popularity_ad_8</th>\n",
       "      <th>fb_popularity_ad_9</th>\n",
       "      <th>fb_popularity_ad_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.35</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.40</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.45</td>\n",
       "      <td>9.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.50</td>\n",
       "      <td>14.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.55</td>\n",
       "      <td>23.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.60</td>\n",
       "      <td>36.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>163.4</td>\n",
       "      <td>165.4</td>\n",
       "      <td>168.0</td>\n",
       "      <td>172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.65</td>\n",
       "      <td>55.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>271.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.70</td>\n",
       "      <td>86.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>325.8</td>\n",
       "      <td>352.0</td>\n",
       "      <td>372.8</td>\n",
       "      <td>386.0</td>\n",
       "      <td>397.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.75</td>\n",
       "      <td>135.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>598.0</td>\n",
       "      <td>613.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>646.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.80</td>\n",
       "      <td>224.0</td>\n",
       "      <td>547.2</td>\n",
       "      <td>705.0</td>\n",
       "      <td>793.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>900.2</td>\n",
       "      <td>931.0</td>\n",
       "      <td>951.0</td>\n",
       "      <td>969.0</td>\n",
       "      <td>985.0</td>\n",
       "      <td>1007.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.85</td>\n",
       "      <td>391.0</td>\n",
       "      <td>894.0</td>\n",
       "      <td>1166.0</td>\n",
       "      <td>1303.0</td>\n",
       "      <td>1420.6</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>1554.4</td>\n",
       "      <td>1600.4</td>\n",
       "      <td>1635.8</td>\n",
       "      <td>1653.0</td>\n",
       "      <td>1682.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.90</td>\n",
       "      <td>745.0</td>\n",
       "      <td>1715.6</td>\n",
       "      <td>2287.6</td>\n",
       "      <td>2537.4</td>\n",
       "      <td>2758.0</td>\n",
       "      <td>2907.8</td>\n",
       "      <td>3039.0</td>\n",
       "      <td>3150.4</td>\n",
       "      <td>3205.0</td>\n",
       "      <td>3254.4</td>\n",
       "      <td>3337.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.95</td>\n",
       "      <td>1949.6</td>\n",
       "      <td>4410.8</td>\n",
       "      <td>5744.2</td>\n",
       "      <td>6588.4</td>\n",
       "      <td>7387.2</td>\n",
       "      <td>7862.4</td>\n",
       "      <td>8291.2</td>\n",
       "      <td>8608.4</td>\n",
       "      <td>8829.4</td>\n",
       "      <td>9006.4</td>\n",
       "      <td>9202.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       q  fb_popularity_ad_0  fb_popularity_ad_1  fb_popularity_ad_2  \\\n",
       "0   0.00                 0.0                 0.0                 0.0   \n",
       "1   0.05                 0.0                 0.0                 0.0   \n",
       "2   0.10                 0.0                 0.0                 0.0   \n",
       "3   0.15                 0.0                 0.0                 0.0   \n",
       "4   0.20                 0.0                 0.0                 0.0   \n",
       "5   0.25                 0.0                 0.0                 1.0   \n",
       "6   0.30                 1.0                 2.0                 2.0   \n",
       "7   0.35                 2.0                 4.0                 6.0   \n",
       "8   0.40                 5.0                11.0                15.0   \n",
       "9   0.45                 9.0                21.0                28.0   \n",
       "10  0.50                14.0                34.0                46.0   \n",
       "11  0.55                23.0                55.0                75.0   \n",
       "12  0.60                36.0                87.0               117.0   \n",
       "13  0.65                55.0               139.0               184.0   \n",
       "14  0.70                86.0               212.0               286.0   \n",
       "15  0.75               135.0               336.0               445.0   \n",
       "16  0.80               224.0               547.2               705.0   \n",
       "17  0.85               391.0               894.0              1166.0   \n",
       "18  0.90               745.0              1715.6              2287.6   \n",
       "19  0.95              1949.6              4410.8              5744.2   \n",
       "\n",
       "    fb_popularity_ad_3  fb_popularity_ad_4  fb_popularity_ad_5  \\\n",
       "0                  0.0                 0.0                 0.0   \n",
       "1                  0.0                 0.0                 0.0   \n",
       "2                  0.0                 0.0                 0.0   \n",
       "3                  0.0                 0.0                 0.0   \n",
       "4                  0.0                 0.0                 0.0   \n",
       "5                  1.0                 1.0                 1.0   \n",
       "6                  2.0                 3.0                 3.0   \n",
       "7                  7.0                 8.0                 8.0   \n",
       "8                 17.0                19.0                20.0   \n",
       "9                 32.0                34.0                35.0   \n",
       "10                52.0                56.0                59.0   \n",
       "11                84.0                90.0                95.0   \n",
       "12               133.0               145.0               152.0   \n",
       "13               209.0               227.0               239.0   \n",
       "14               325.8               352.0               372.8   \n",
       "15               505.0               550.0               575.0   \n",
       "16               793.0               861.0               900.2   \n",
       "17              1303.0              1420.6              1498.0   \n",
       "18              2537.4              2758.0              2907.8   \n",
       "19              6588.4              7387.2              7862.4   \n",
       "\n",
       "    fb_popularity_ad_6  fb_popularity_ad_7  fb_popularity_ad_8  \\\n",
       "0                  0.0                 0.0                 0.0   \n",
       "1                  0.0                 0.0                 0.0   \n",
       "2                  0.0                 0.0                 0.0   \n",
       "3                  0.0                 0.0                 0.0   \n",
       "4                  0.0                 0.0                 0.0   \n",
       "5                  1.0                 1.0                 1.0   \n",
       "6                  3.0                 3.0                 3.0   \n",
       "7                  9.0                 9.0                10.0   \n",
       "8                 21.0                22.0                23.0   \n",
       "9                 37.0                38.0                39.0   \n",
       "10                61.0                63.0                64.0   \n",
       "11                98.0               101.0               103.0   \n",
       "12               157.0               163.4               165.4   \n",
       "13               248.0               256.0               261.0   \n",
       "14               386.0               397.0               404.0   \n",
       "15               598.0               613.0               622.0   \n",
       "16               931.0               951.0               969.0   \n",
       "17              1554.4              1600.4              1635.8   \n",
       "18              3039.0              3150.4              3205.0   \n",
       "19              8291.2              8608.4              8829.4   \n",
       "\n",
       "    fb_popularity_ad_9  fb_popularity_ad_10  \n",
       "0                  0.0                  0.0  \n",
       "1                  0.0                  0.0  \n",
       "2                  0.0                  0.0  \n",
       "3                  0.0                  0.0  \n",
       "4                  0.0                  0.0  \n",
       "5                  1.0                  1.0  \n",
       "6                  4.0                  4.0  \n",
       "7                 10.0                 11.0  \n",
       "8                 24.0                 24.0  \n",
       "9                 40.0                 41.0  \n",
       "10                66.0                 67.0  \n",
       "11               106.0                108.0  \n",
       "12               168.0                172.0  \n",
       "13               266.0                271.0  \n",
       "14               410.0                415.0  \n",
       "15               635.0                646.0  \n",
       "16               985.0               1007.0  \n",
       "17              1653.0               1682.2  \n",
       "18              3254.4               3337.0  \n",
       "19              9006.4               9202.0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop = pd.DataFrame()\n",
    "qrange = [np.round(i, 2) for i in np.arange(0, 1, 0.05)]\n",
    "pop['q'] = qrange\n",
    "for i in range(0, 11):\n",
    "    col = f'fb_popularity_ad_{i}'\n",
    "    pop[col] = [df[col].quantile(q) for q in qrange]\n",
    "pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rozdelenie hodnot popularity do 5 skupin\n",
    "\n",
    "- `0 - 0.6`\n",
    "- `0.6 - 0.8`\n",
    "- `0.8 - 0.9`\n",
    "- `0.9 - 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_labels(df, quantiles, column='fb_popularity_ad_10'):\n",
    "    df = df.copy()\n",
    "    label_str = f'{column}_label'\n",
    "    \n",
    "    df[label_str] = -1\n",
    "    \n",
    "    label = 1    \n",
    "    for i in range(len(quantiles) - 1):\n",
    "        low = df[column].quantile(quantiles[i])\n",
    "        high = df[column].quantile(quantiles[i + 1])\n",
    "        \n",
    "        df.loc[(low <= df[column]) & (df[column] <= high), label_str] = int(label)\n",
    "        \n",
    "        label += 1\n",
    "    df = df.drop(columns=[column])    \n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00          0.0\n",
      "0.55         47.0\n",
      "0.70        233.0\n",
      "0.90       2014.0\n",
      "1.00    1368305.0\n",
      "Name: fb_ad_10_reaction_count, dtype: float64\n",
      "0.00         0.0\n",
      "0.55         8.0\n",
      "0.70        45.0\n",
      "0.90       511.6\n",
      "1.00    897945.0\n",
      "Name: fb_ad_10_comment_count, dtype: float64\n",
      "0.00         0.0\n",
      "0.55        40.0\n",
      "0.70       115.2\n",
      "0.90       695.0\n",
      "1.00    298199.0\n",
      "Name: fb_ad_10_share_count, dtype: float64\n",
      "0.00          0.0\n",
      "0.55        108.0\n",
      "0.70        415.0\n",
      "0.90       3337.0\n",
      "1.00    2564449.0\n",
      "Name: fb_popularity_ad_10, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "quantiles = [\n",
    "    0,\n",
    "    .55,\n",
    "    .7,\n",
    "    .9,\n",
    "    1\n",
    "]\n",
    "\n",
    "cols = [\n",
    "    'fb_ad_10_reaction_count',\n",
    "    'fb_ad_10_comment_count',\n",
    "    'fb_ad_10_share_count',\n",
    "    'fb_popularity_ad_10'\n",
    "]\n",
    "\n",
    "for i in cols:\n",
    "    print(df[i].quantile(quantiles))\n",
    "    df = add_labels(df, quantiles, column=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    11151\n",
       "2     3732\n",
       "4     1861\n",
       "3     1861\n",
       "Name: fb_popularity_ad_10_label, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fb_popularity_ad_10_label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pri jednotlivych zlozkach sme pri tomto rozdeleni nasli len 4 skupiny (lebo 1 == 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jednoducha heuristika: ak je zdroj nedoveryhodny tak aj clanok je nedoveryhodny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_fake_news_label'] = df.source_is_reliable.replace({0:1, 1:0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = list(filter(lambda x: x.endswith('_label'), df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ln in label_names:\n",
    "    df[ln] = pd.to_numeric(df[ln])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labely\n",
    "labels_df = pd.concat([labels_df] + [df[label_name] for label_name in label_names], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20246 entries, 428781 to 812426\n",
      "Data columns (total 87 columns):\n",
      " #   Column                         Non-Null Count  Dtype         \n",
      "---  ------                         --------------  -----         \n",
      " 0   title                          20246 non-null  object        \n",
      " 1   perex                          20246 non-null  object        \n",
      " 2   body                           20246 non-null  object        \n",
      " 3   published_at                   20246 non-null  datetime64[ns]\n",
      " 4   extracted_at                   20246 non-null  datetime64[ns]\n",
      " 5   category                       13685 non-null  object        \n",
      " 6   other_info                     20242 non-null  object        \n",
      " 7   image_count                    20246 non-null  int64         \n",
      " 8   video_count                    20246 non-null  int64         \n",
      " 9   author_name                    20246 non-null  object        \n",
      " 10  source_id                      20246 non-null  int64         \n",
      " 11  source_name                    20246 non-null  object        \n",
      " 12  source_url                     20246 non-null  object        \n",
      " 13  source_type                    20246 non-null  object        \n",
      " 14  source_is_reliable             20246 non-null  int64         \n",
      " 15  av_veracity                    4249 non-null   object        \n",
      " 16  av_claims_false                20246 non-null  int64         \n",
      " 17  av_claims_mostly_false         20246 non-null  int64         \n",
      " 18  av_claims_mixture              20246 non-null  int64         \n",
      " 19  av_claims_mostly_true          20246 non-null  int64         \n",
      " 20  av_claims_true                 20246 non-null  int64         \n",
      " 21  av_claims_unknown              20246 non-null  int64         \n",
      " 22  fb_ad_0_comment_count          9371 non-null   float64       \n",
      " 23  fb_ad_1_comment_count          14380 non-null  float64       \n",
      " 24  fb_ad_2_comment_count          15336 non-null  float64       \n",
      " 25  fb_ad_3_comment_count          16029 non-null  float64       \n",
      " 26  fb_ad_4_comment_count          16502 non-null  float64       \n",
      " 27  fb_ad_5_comment_count          16498 non-null  float64       \n",
      " 28  fb_ad_6_comment_count          16508 non-null  float64       \n",
      " 29  fb_ad_7_comment_count          16453 non-null  float64       \n",
      " 30  fb_ad_8_comment_count          16140 non-null  float64       \n",
      " 31  fb_ad_9_comment_count          16209 non-null  float64       \n",
      " 32  fb_ad_10_comment_count         16459 non-null  float64       \n",
      " 33  fb_ad_11_comment_count         16646 non-null  float64       \n",
      " 34  fb_ad_12_comment_count         16541 non-null  float64       \n",
      " 35  fb_ad_13_comment_count         16240 non-null  float64       \n",
      " 36  fb_ad_14_comment_count         16024 non-null  float64       \n",
      " 37  fb_ad_0_reaction_count         9371 non-null   float64       \n",
      " 38  fb_ad_1_reaction_count         14380 non-null  float64       \n",
      " 39  fb_ad_2_reaction_count         15336 non-null  float64       \n",
      " 40  fb_ad_3_reaction_count         16029 non-null  float64       \n",
      " 41  fb_ad_4_reaction_count         16502 non-null  float64       \n",
      " 42  fb_ad_5_reaction_count         16498 non-null  float64       \n",
      " 43  fb_ad_6_reaction_count         16508 non-null  float64       \n",
      " 44  fb_ad_7_reaction_count         16453 non-null  float64       \n",
      " 45  fb_ad_8_reaction_count         16140 non-null  float64       \n",
      " 46  fb_ad_9_reaction_count         16209 non-null  float64       \n",
      " 47  fb_ad_10_reaction_count        16459 non-null  float64       \n",
      " 48  fb_ad_11_reaction_count        16646 non-null  float64       \n",
      " 49  fb_ad_12_reaction_count        16541 non-null  float64       \n",
      " 50  fb_ad_13_reaction_count        16240 non-null  float64       \n",
      " 51  fb_ad_14_reaction_count        16024 non-null  float64       \n",
      " 52  fb_ad_0_share_count            9371 non-null   float64       \n",
      " 53  fb_ad_1_share_count            14380 non-null  float64       \n",
      " 54  fb_ad_2_share_count            15336 non-null  float64       \n",
      " 55  fb_ad_3_share_count            16029 non-null  float64       \n",
      " 56  fb_ad_4_share_count            16502 non-null  float64       \n",
      " 57  fb_ad_5_share_count            16498 non-null  float64       \n",
      " 58  fb_ad_6_share_count            16508 non-null  float64       \n",
      " 59  fb_ad_7_share_count            16453 non-null  float64       \n",
      " 60  fb_ad_8_share_count            16140 non-null  float64       \n",
      " 61  fb_ad_9_share_count            16209 non-null  float64       \n",
      " 62  fb_ad_10_share_count           16459 non-null  float64       \n",
      " 63  fb_ad_11_share_count           16646 non-null  float64       \n",
      " 64  fb_ad_12_share_count           16541 non-null  float64       \n",
      " 65  fb_ad_13_share_count           16240 non-null  float64       \n",
      " 66  fb_ad_14_share_count           16024 non-null  float64       \n",
      " 67  fb_popularity_ad_0             20246 non-null  float64       \n",
      " 68  fb_popularity_ad_1             20246 non-null  float64       \n",
      " 69  fb_popularity_ad_2             20246 non-null  float64       \n",
      " 70  fb_popularity_ad_3             20246 non-null  float64       \n",
      " 71  fb_popularity_ad_4             20246 non-null  float64       \n",
      " 72  fb_popularity_ad_5             20246 non-null  float64       \n",
      " 73  fb_popularity_ad_6             20246 non-null  float64       \n",
      " 74  fb_popularity_ad_7             20246 non-null  float64       \n",
      " 75  fb_popularity_ad_8             20246 non-null  float64       \n",
      " 76  fb_popularity_ad_9             20246 non-null  float64       \n",
      " 77  fb_popularity_ad_10            20246 non-null  float64       \n",
      " 78  fb_popularity_ad_11            20246 non-null  float64       \n",
      " 79  fb_popularity_ad_12            20246 non-null  float64       \n",
      " 80  fb_popularity_ad_13            20246 non-null  float64       \n",
      " 81  fb_popularity_ad_14            20246 non-null  float64       \n",
      " 82  fb_ad_15_reaction_count_label  20246 non-null  int64         \n",
      " 83  fb_ad_15_comment_count_label   20246 non-null  int64         \n",
      " 84  fb_ad_15_share_count_label     20246 non-null  int64         \n",
      " 85  fb_popularity_ad_15_label      20246 non-null  int64         \n",
      " 86  is_fake_news_label             20246 non-null  int64         \n",
      "dtypes: datetime64[ns](2), float64(60), int64(15), object(10)\n",
      "memory usage: 13.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rozdelenie dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, validation = tuple(split_data(df, sizes=[2, 2, 1], shuffle=True, np_random=np_random))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8099, 8098, 4049]\n"
     ]
    }
   ],
   "source": [
    "print([len(i) for i in [train,test,validation]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fb_ad_15_reaction_count_label',\n",
       " 'fb_ad_15_comment_count_label',\n",
       " 'fb_ad_15_share_count_label',\n",
       " 'fb_popularity_ad_15_label',\n",
       " 'is_fake_news_label']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skupina 'metadata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def media_count_total(df):\n",
    "    res = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    res['media_count_total'] = df['image_count'] + df['video_count']\n",
    "    \n",
    "    return res\n",
    "    \n",
    "def media_count_image(df):\n",
    "    return column_feature(df, 'image_count')\n",
    "\n",
    "def media_count_video(df):\n",
    "    return column_feature(df, 'video_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = split_X_y_all(train, test, validation, selected_label='is_fake_news_label', all_labels=label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] -- 10 / 10 -- (finished)\n"
     ]
    }
   ],
   "source": [
    "data.train.features = add_features(data.train.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] -- 10 / 10 -- (finished)\n"
     ]
    }
   ],
   "source": [
    "data.test.features = add_features(data.test.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] -- 10 / 10 -- (finished)\n"
     ]
    }
   ],
   "source": [
    "data.validation.features = add_features(data.validation.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fb_ad_15_reaction_count_label',\n",
       " 'fb_ad_15_comment_count_label',\n",
       " 'fb_ad_15_share_count_label',\n",
       " 'fb_popularity_ad_15_label',\n",
       " 'is_fake_news_label']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_to_file(data, file):\n",
    "    with open(file, 'w', encoding='utf-8') as f:\n",
    "        for i in Pbar(data):\n",
    "            f.write(f\"{' '.join(tokenize(i))}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 12 cores available\n"
     ]
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "print(f'>>> {cores} cores available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] -- 8099 / 8099 -- (finished)\n",
      "[==================================================] -- 8098 / 8098 -- (finished)\n",
      "[==================================================] -- 4049 / 4049 -- (finished)\n"
     ]
    }
   ],
   "source": [
    "tokenize_to_file(data.train.X.body, './data/train_body_tokenized.txt')\n",
    "tokenize_to_file(data.test.X.body, './data/test_body_tokenized.txt')\n",
    "tokenize_to_file(data.validation.X.body, './data/validation_body_tokenized.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-27 11:30:50,863 : INFO : collecting all words and their counts\n",
      "2020-04-27 11:30:50,864 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2020-04-27 11:30:51,711 : INFO : collected 90408 word types and 8099 unique tags from a corpus of 8099 examples and 2789006 words\n",
      "2020-04-27 11:30:51,712 : INFO : Loading a fresh vocabulary\n",
      "2020-04-27 11:30:51,878 : INFO : effective_min_count=2 retains 51892 unique words (57% of original 90408, drops 38516)\n",
      "2020-04-27 11:30:51,878 : INFO : effective_min_count=2 leaves 2750490 word corpus (98% of original 2789006, drops 38516)\n",
      "2020-04-27 11:30:52,056 : INFO : deleting the raw counts dictionary of 90408 items\n",
      "2020-04-27 11:30:52,059 : INFO : sample=0.001 downsamples 9 most-common words\n",
      "2020-04-27 11:30:52,060 : INFO : downsampling leaves estimated 2721940 word corpus (99.0% of prior 2750490)\n",
      "2020-04-27 11:30:52,213 : INFO : estimated required memory for 51892 words and 300 dimensions: 160205600 bytes\n",
      "2020-04-27 11:30:52,214 : INFO : resetting layer weights\n",
      "2020-04-27 11:31:05,982 : INFO : training model with 12 workers on 51892 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-27 11:31:08,278 : INFO : EPOCH 1 - PROGRESS: at 8.47% examples, 103718 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-27 11:31:08,279 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-04-27 11:31:08,423 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-04-27 11:31:08,440 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-04-27 11:31:08,451 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-04-27 11:31:08,517 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-27 11:31:08,529 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-27 11:31:08,599 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-27 11:31:08,606 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-27 11:31:08,746 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-27 11:31:08,750 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-27 11:31:08,776 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-27 11:31:08,793 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-27 11:31:08,794 : INFO : EPOCH - 1 : training on 2791076 raw words (2731929 effective words) took 2.7s, 1007789 effective words/s\n",
      "2020-04-27 11:31:10,976 : INFO : EPOCH 2 - PROGRESS: at 8.56% examples, 107446 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-27 11:31:10,978 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-04-27 11:31:10,992 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-04-27 11:31:10,999 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-04-27 11:31:11,070 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-04-27 11:31:11,098 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-27 11:31:11,104 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-27 11:31:11,164 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-27 11:31:11,205 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-27 11:31:11,338 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-27 11:31:11,385 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-27 11:31:11,415 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-27 11:31:11,459 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-27 11:31:11,460 : INFO : EPOCH - 2 : training on 2791076 raw words (2732163 effective words) took 2.6s, 1049396 effective words/s\n",
      "2020-04-27 11:31:13,785 : INFO : EPOCH 3 - PROGRESS: at 8.25% examples, 102454 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-27 11:31:13,787 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-04-27 11:31:13,828 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-04-27 11:31:13,839 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-04-27 11:31:13,886 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-04-27 11:31:13,920 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-27 11:31:13,931 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-27 11:31:13,959 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-27 11:31:13,993 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-27 11:31:14,267 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-27 11:31:14,276 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-27 11:31:14,335 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-27 11:31:14,392 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-27 11:31:14,394 : INFO : EPOCH - 3 : training on 2791076 raw words (2731958 effective words) took 2.8s, 965117 effective words/s\n",
      "2020-04-27 11:31:16,745 : INFO : EPOCH 4 - PROGRESS: at 8.47% examples, 100740 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-27 11:31:16,747 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-04-27 11:31:16,776 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-04-27 11:31:16,817 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-04-27 11:31:16,819 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-04-27 11:31:16,823 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-27 11:31:16,845 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-27 11:31:16,873 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-27 11:31:16,883 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-27 11:31:17,065 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-27 11:31:17,069 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-27 11:31:17,076 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-27 11:31:17,099 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-27 11:31:17,101 : INFO : EPOCH - 4 : training on 2791076 raw words (2732188 effective words) took 2.6s, 1044526 effective words/s\n",
      "2020-04-27 11:31:19,513 : INFO : EPOCH 5 - PROGRESS: at 8.56% examples, 98541 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-27 11:31:19,515 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-04-27 11:31:19,523 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-04-27 11:31:19,526 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-04-27 11:31:19,528 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-04-27 11:31:19,535 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-27 11:31:19,545 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-27 11:31:19,558 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-27 11:31:19,574 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-27 11:31:19,595 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-27 11:31:19,632 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-27 11:31:19,633 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-27 11:31:19,635 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-27 11:31:19,636 : INFO : EPOCH - 5 : training on 2791076 raw words (2732257 effective words) took 2.4s, 1123041 effective words/s\n",
      "2020-04-27 11:31:21,866 : INFO : EPOCH 6 - PROGRESS: at 8.36% examples, 105698 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-27 11:31:21,868 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-04-27 11:31:21,890 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-04-27 11:31:21,893 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-04-27 11:31:21,924 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-04-27 11:31:21,936 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-27 11:31:21,959 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-27 11:31:21,989 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-27 11:31:21,992 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-27 11:31:22,012 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-27 11:31:22,025 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-27 11:31:22,058 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-27 11:31:22,063 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-27 11:31:22,064 : INFO : EPOCH - 6 : training on 2791076 raw words (2731884 effective words) took 2.3s, 1162893 effective words/s\n",
      "2020-04-27 11:31:24,237 : INFO : EPOCH 7 - PROGRESS: at 8.42% examples, 108667 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-27 11:31:24,239 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-04-27 11:31:24,273 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-04-27 11:31:24,291 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-04-27 11:31:24,300 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-04-27 11:31:24,324 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-27 11:31:24,342 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-27 11:31:24,376 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-27 11:31:24,389 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-27 11:31:24,413 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-27 11:31:24,447 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-27 11:31:24,464 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-27 11:31:24,484 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-27 11:31:24,485 : INFO : EPOCH - 7 : training on 2791076 raw words (2732281 effective words) took 2.3s, 1166238 effective words/s\n",
      "2020-04-27 11:31:26,611 : INFO : EPOCH 8 - PROGRESS: at 8.25% examples, 111670 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-27 11:31:26,625 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-04-27 11:31:26,646 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-04-27 11:31:26,722 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-04-27 11:31:26,743 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-04-27 11:31:26,784 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-27 11:31:26,803 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-27 11:31:26,821 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-27 11:31:26,879 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-27 11:31:26,894 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-27 11:31:26,913 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-27 11:31:26,961 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-27 11:31:27,006 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-27 11:31:27,007 : INFO : EPOCH - 8 : training on 2791076 raw words (2731976 effective words) took 2.4s, 1119111 effective words/s\n",
      "2020-04-27 11:31:29,208 : INFO : EPOCH 9 - PROGRESS: at 8.47% examples, 107324 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-27 11:31:29,209 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-04-27 11:31:29,241 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-04-27 11:31:29,266 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-04-27 11:31:29,276 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-04-27 11:31:29,329 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-27 11:31:29,341 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-27 11:31:29,361 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-27 11:31:29,370 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-27 11:31:29,393 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-27 11:31:29,394 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-27 11:31:29,405 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-27 11:31:29,411 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-27 11:31:29,412 : INFO : EPOCH - 9 : training on 2791076 raw words (2731958 effective words) took 2.3s, 1174957 effective words/s\n",
      "2020-04-27 11:31:31,538 : INFO : EPOCH 10 - PROGRESS: at 8.47% examples, 113081 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-27 11:31:31,540 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-04-27 11:31:31,612 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-04-27 11:31:31,617 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-04-27 11:31:31,666 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-04-27 11:31:31,689 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-27 11:31:31,726 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-27 11:31:31,731 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-27 11:31:31,761 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-27 11:31:31,785 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-27 11:31:31,815 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-27 11:31:31,822 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-27 11:31:31,827 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-27 11:31:31,828 : INFO : EPOCH - 10 : training on 2791076 raw words (2732147 effective words) took 2.3s, 1186417 effective words/s\n",
      "2020-04-27 11:31:33,949 : INFO : EPOCH 11 - PROGRESS: at 8.36% examples, 110530 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-27 11:31:33,951 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-04-27 11:31:33,970 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-04-27 11:31:33,974 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-04-27 11:31:33,976 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-04-27 11:31:33,987 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-27 11:31:33,998 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-27 11:31:34,008 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-27 11:31:34,029 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-27 11:31:34,062 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-27 11:31:34,086 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-27 11:31:34,137 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-27 11:31:34,142 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-27 11:31:34,143 : INFO : EPOCH - 11 : training on 2791076 raw words (2732012 effective words) took 2.3s, 1212748 effective words/s\n",
      "2020-04-27 11:31:36,266 : INFO : EPOCH 12 - PROGRESS: at 8.25% examples, 110123 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-27 11:31:36,268 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-04-27 11:31:36,323 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-04-27 11:31:36,327 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-04-27 11:31:36,343 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-04-27 11:31:36,363 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-27 11:31:36,371 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-27 11:31:36,394 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-27 11:31:36,412 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-27 11:31:36,424 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-27 11:31:36,425 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-27 11:31:36,437 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-27 11:31:36,462 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-27 11:31:36,463 : INFO : EPOCH - 12 : training on 2791076 raw words (2731918 effective words) took 2.3s, 1206476 effective words/s\n",
      "2020-04-27 11:31:38,636 : INFO : EPOCH 13 - PROGRESS: at 8.36% examples, 108699 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-27 11:31:38,637 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-04-27 11:31:38,657 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-04-27 11:31:38,672 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-04-27 11:31:38,674 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-04-27 11:31:38,692 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-27 11:31:38,693 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-27 11:31:38,723 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-27 11:31:38,735 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-27 11:31:38,743 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-27 11:31:38,745 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-27 11:31:38,780 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-27 11:31:38,814 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-27 11:31:38,816 : INFO : EPOCH - 13 : training on 2791076 raw words (2731646 effective words) took 2.3s, 1202229 effective words/s\n",
      "2020-04-27 11:31:40,886 : INFO : EPOCH 14 - PROGRESS: at 8.47% examples, 115056 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-27 11:31:40,888 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-04-27 11:31:40,900 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-04-27 11:31:40,930 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-04-27 11:31:40,950 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-04-27 11:31:40,962 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-27 11:31:41,003 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-27 11:31:41,012 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-27 11:31:41,067 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-27 11:31:41,103 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-27 11:31:41,128 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-27 11:31:41,142 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-27 11:31:41,156 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-27 11:31:41,157 : INFO : EPOCH - 14 : training on 2791076 raw words (2731746 effective words) took 2.2s, 1214307 effective words/s\n",
      "2020-04-27 11:31:43,316 : INFO : EPOCH 15 - PROGRESS: at 8.24% examples, 109124 words/s, in_qsize -1, out_qsize 1\n",
      "2020-04-27 11:31:43,318 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-04-27 11:31:43,364 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-04-27 11:31:43,366 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-04-27 11:31:43,378 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-04-27 11:31:43,399 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-27 11:31:43,411 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-27 11:31:43,466 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-27 11:31:43,473 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-27 11:31:43,591 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-27 11:31:43,608 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-27 11:31:43,624 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-27 11:31:43,625 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-27 11:31:43,625 : INFO : EPOCH - 15 : training on 2791076 raw words (2732309 effective words) took 2.4s, 1141712 effective words/s\n",
      "2020-04-27 11:31:43,630 : INFO : training on a 41866140 raw words (40980372 effective words) took 37.6s, 1088564 effective words/s\n"
     ]
    }
   ],
   "source": [
    "d2v = Doc2Vec(corpus_file='./data/train_body_tokenized.txt', vector_size=300, min_count=2, epochs=15, workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_d2v(d2v_model, data_file):\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    with open(data_file, 'r', encoding='utf-8') as f:\n",
    "        for i in Pbar(f.readlines()):\n",
    "            res.append(d2v_model.infer_vector(i.split(' '), steps=20, alpha=0.025)) \n",
    "    \n",
    "    return res\n",
    "\n",
    "def infer_for_df(df, d2v_model, data_file):\n",
    "    lst = infer_d2v(d2v_model, data_file)\n",
    "    d2v_df = pd.DataFrame(lst, index=df.index, columns=[f'd2v_{i}' for i in range(1, 301)] )\n",
    "    \n",
    "    return pd.concat([df, d2v_df], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] -- 8099 / 8099 -- (finished)\n"
     ]
    }
   ],
   "source": [
    "data.train.features = infer_for_df(data.train.features, d2v, './data/train_body_tokenized.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] -- 8098 / 8098 -- (finished)\n"
     ]
    }
   ],
   "source": [
    "data.test.features = infer_for_df(data.test.features, d2v, './data/test_body_tokenized.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(clf, data):\n",
    "    clf.fit(data.train.features, data.train.y)\n",
    "    return clf.predict(data.test.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fb_ad_15_reaction_count_label',\n",
       " 'fb_ad_15_comment_count_label',\n",
       " 'fb_ad_15_share_count_label',\n",
       " 'fb_popularity_ad_15_label',\n",
       " 'is_fake_news_label']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train.switch_label('is_fake_news_label')\n",
    "data.test.switch_label('is_fake_news_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train.features['media_count_total'] = pd.to_numeric(data.train.features['media_count_total'])\n",
    "data.train.features['image_count'] = pd.to_numeric(data.train.features['image_count'])\n",
    "data.train.features['video_count'] = pd.to_numeric(data.train.features['video_count'])\n",
    "\n",
    "data.test.features['media_count_total'] = pd.to_numeric(data.test.features['media_count_total'])\n",
    "data.test.features['image_count'] = pd.to_numeric(data.test.features['image_count'])\n",
    "data.test.features['video_count'] = pd.to_numeric(data.test.features['video_count'])\n",
    "\n",
    "data.train.features['av_claims_false'] = pd.to_numeric(data.train.features['av_claims_false'])\n",
    "data.train.features['av_claims_mostly_false'] = pd.to_numeric(data.train.features['av_claims_mostly_false'])\n",
    "data.train.features['av_claims_mixture'] = pd.to_numeric(data.train.features['av_claims_mixture'])\n",
    "data.train.features['av_claims_mostly_true'] = pd.to_numeric(data.train.features['av_claims_mostly_true'])\n",
    "data.train.features['av_claims_true'] = pd.to_numeric(data.train.features['av_claims_true'])\n",
    "data.train.features['av_claims_unknown'] = pd.to_numeric(data.train.features['av_claims_unknown'])\n",
    "\n",
    "\n",
    "data.test.features['av_claims_false'] = pd.to_numeric(data.test.features['av_claims_false'])\n",
    "data.test.features['av_claims_mostly_false'] = pd.to_numeric(data.test.features['av_claims_mostly_false'])\n",
    "data.test.features['av_claims_mixture'] = pd.to_numeric(data.test.features['av_claims_mixture'])\n",
    "data.test.features['av_claims_mostly_true'] = pd.to_numeric(data.test.features['av_claims_mostly_true'])\n",
    "data.test.features['av_claims_true'] = pd.to_numeric(data.test.features['av_claims_true'])\n",
    "data.test.features['av_claims_unknown'] = pd.to_numeric(data.test.features['av_claims_unknown'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train.features.drop(columns=['perex_word_count', 'perex_char_length'], inplace=True)\n",
    "data.test.features.drop(columns=['perex_word_count', 'perex_char_length'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train.y = pd.to_numeric(data.train.y)\n",
    "data.test.y = pd.to_numeric(data.test.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=======================================             ] (processing: LogisticRegression) -- 3 / 4"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamko\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================================================] -- 4 / 4 -- (finished)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      4838\n",
      "           1       0.93      0.81      0.87      3260\n",
      "\n",
      "    accuracy                           0.90      8098\n",
      "   macro avg       0.90      0.88      0.89      8098\n",
      "weighted avg       0.90      0.90      0.90      8098\n",
      "\n",
      "------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92      4838\n",
      "           1       0.91      0.84      0.87      3260\n",
      "\n",
      "    accuracy                           0.90      8098\n",
      "   macro avg       0.90      0.89      0.90      8098\n",
      "weighted avg       0.90      0.90      0.90      8098\n",
      "\n",
      "------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.88      0.82      4838\n",
      "           1       0.77      0.61      0.68      3260\n",
      "\n",
      "    accuracy                           0.77      8098\n",
      "   macro avg       0.77      0.74      0.75      8098\n",
      "weighted avg       0.77      0.77      0.76      8098\n",
      "\n",
      "------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73      4838\n",
      "           1       0.61      0.75      0.67      3260\n",
      "\n",
      "    accuracy                           0.70      8098\n",
      "   macro avg       0.70      0.71      0.70      8098\n",
      "weighted avg       0.72      0.70      0.71      8098\n",
      "\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=cores),\n",
    "    XGBClassifier(n_jobs=cores, seed=RANDOM_STATE),\n",
    "    GaussianNB(),\n",
    "    LogisticRegression()\n",
    "]\n",
    "\n",
    "pbar_conf = {\n",
    "    'refresh_rate': 1,\n",
    "    'length': len(classifiers), \n",
    "    'pbar_width': 52,\n",
    "    'action_names': [i.__class__.__name__ for i in classifiers]\n",
    "}\n",
    "\n",
    "predictions = list(Pbar((fit_predict(clf, data) for clf in classifiers), **pbar_conf))\n",
    "\n",
    "for p in predictions:\n",
    "    print(classification_report(data.test.y, p))\n",
    "    print('-' * 54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[====================================================] -- 2 / 2 -- (finished)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.89      0.96      0.92      4838\n",
    "           1       0.92      0.82      0.87      3260\n",
    "\n",
    "    accuracy                           0.90      8098\n",
    "   macro avg       0.91      0.89      0.89      8098\n",
    "weighted avg       0.90      0.90      0.90      8098\n",
    "\n",
    "------------------------------------------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.90      0.94      0.92      4838\n",
    "           1       0.90      0.84      0.87      3260\n",
    "\n",
    "    accuracy                           0.90      8098\n",
    "   macro avg       0.90      0.89      0.89      8098\n",
    "weighted avg       0.90      0.90      0.90      8098\n",
    "\n",
    "------------------------------------------------------\n",
    "\n",
    "[====================================================] -- 2 / 2 -- (finished)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.83      0.88      0.85      4838\n",
    "           1       0.80      0.73      0.76      3260\n",
    "\n",
    "    accuracy                           0.82      8098\n",
    "   macro avg       0.81      0.80      0.81      8098\n",
    "weighted avg       0.82      0.82      0.82      8098\n",
    "\n",
    "------------------------------------------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.82      0.88      0.85      4838\n",
    "           1       0.81      0.72      0.76      3260\n",
    "\n",
    "    accuracy                           0.82      8098\n",
    "   macro avg       0.82      0.80      0.81      8098\n",
    "weighted avg       0.82      0.82      0.82      8098\n",
    "\n",
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fb_ad_0_share_count</th>\n",
       "      <td>0.037344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb_ad_0_reaction_count</th>\n",
       "      <td>0.032782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_char_length</th>\n",
       "      <td>0.030757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb_ad_0_comment_count</th>\n",
       "      <td>0.026981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content_word_count</th>\n",
       "      <td>0.025531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb_popularity_ad_0</th>\n",
       "      <td>0.024881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_word_count</th>\n",
       "      <td>0.021971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>media_count_total</th>\n",
       "      <td>0.021888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_count</th>\n",
       "      <td>0.021173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb_ad_1_reaction_count</th>\n",
       "      <td>0.020109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content_char_length</th>\n",
       "      <td>0.019831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb_ad_1_share_count</th>\n",
       "      <td>0.019254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb_ad_1_comment_count</th>\n",
       "      <td>0.016520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_collective_author</th>\n",
       "      <td>0.014032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_187</th>\n",
       "      <td>0.013095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_65</th>\n",
       "      <td>0.012808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb_ad_3_share_count</th>\n",
       "      <td>0.011319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb_ad_3_reaction_count</th>\n",
       "      <td>0.009092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb_ad_3_comment_count</th>\n",
       "      <td>0.007162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_272</th>\n",
       "      <td>0.006980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_57</th>\n",
       "      <td>0.006657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_232</th>\n",
       "      <td>0.006600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_119</th>\n",
       "      <td>0.006544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_287</th>\n",
       "      <td>0.006314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_285</th>\n",
       "      <td>0.005826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_4</th>\n",
       "      <td>0.005797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_72</th>\n",
       "      <td>0.005489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_135</th>\n",
       "      <td>0.005329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_44</th>\n",
       "      <td>0.005037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_169</th>\n",
       "      <td>0.004770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_33</th>\n",
       "      <td>0.004689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_12</th>\n",
       "      <td>0.004671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_20</th>\n",
       "      <td>0.004647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_191</th>\n",
       "      <td>0.004597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_276</th>\n",
       "      <td>0.004386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_66</th>\n",
       "      <td>0.004103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_77</th>\n",
       "      <td>0.003998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_200</th>\n",
       "      <td>0.003792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_122</th>\n",
       "      <td>0.003702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb_popularity_ad_1</th>\n",
       "      <td>0.003615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb_popularity_ad_3</th>\n",
       "      <td>0.003585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_104</th>\n",
       "      <td>0.003569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_39</th>\n",
       "      <td>0.003528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_125</th>\n",
       "      <td>0.003473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_40</th>\n",
       "      <td>0.003463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_176</th>\n",
       "      <td>0.003434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_259</th>\n",
       "      <td>0.003307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_177</th>\n",
       "      <td>0.003279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_110</th>\n",
       "      <td>0.003170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_26</th>\n",
       "      <td>0.003168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_214</th>\n",
       "      <td>0.003146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_261</th>\n",
       "      <td>0.003088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_283</th>\n",
       "      <td>0.003056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_69</th>\n",
       "      <td>0.003025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_222</th>\n",
       "      <td>0.002953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_129</th>\n",
       "      <td>0.002939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_265</th>\n",
       "      <td>0.002912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_263</th>\n",
       "      <td>0.002907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_24</th>\n",
       "      <td>0.002895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_152</th>\n",
       "      <td>0.002888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_51</th>\n",
       "      <td>0.002874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_82</th>\n",
       "      <td>0.002862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_258</th>\n",
       "      <td>0.002848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_195</th>\n",
       "      <td>0.002826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_34</th>\n",
       "      <td>0.002759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_227</th>\n",
       "      <td>0.002698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_254</th>\n",
       "      <td>0.002694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_11</th>\n",
       "      <td>0.002687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_203</th>\n",
       "      <td>0.002657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_207</th>\n",
       "      <td>0.002654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_25</th>\n",
       "      <td>0.002558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_233</th>\n",
       "      <td>0.002554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_168</th>\n",
       "      <td>0.002539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_161</th>\n",
       "      <td>0.002534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_88</th>\n",
       "      <td>0.002523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_23</th>\n",
       "      <td>0.002520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_209</th>\n",
       "      <td>0.002519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_147</th>\n",
       "      <td>0.002508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_138</th>\n",
       "      <td>0.002498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_108</th>\n",
       "      <td>0.002481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_131</th>\n",
       "      <td>0.002413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_30</th>\n",
       "      <td>0.002400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_196</th>\n",
       "      <td>0.002397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_268</th>\n",
       "      <td>0.002375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_275</th>\n",
       "      <td>0.002366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_229</th>\n",
       "      <td>0.002349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_99</th>\n",
       "      <td>0.002317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_294</th>\n",
       "      <td>0.002316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_85</th>\n",
       "      <td>0.002300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_141</th>\n",
       "      <td>0.002293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_38</th>\n",
       "      <td>0.002290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_36</th>\n",
       "      <td>0.002275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_163</th>\n",
       "      <td>0.002264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_216</th>\n",
       "      <td>0.002257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_197</th>\n",
       "      <td>0.002245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_288</th>\n",
       "      <td>0.002189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_242</th>\n",
       "      <td>0.002183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_56</th>\n",
       "      <td>0.002160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_134</th>\n",
       "      <td>0.002149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_208</th>\n",
       "      <td>0.002139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_230</th>\n",
       "      <td>0.002138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_84</th>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_15</th>\n",
       "      <td>0.002113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_67</th>\n",
       "      <td>0.002113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_80</th>\n",
       "      <td>0.002105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_94</th>\n",
       "      <td>0.002075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_226</th>\n",
       "      <td>0.002074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_86</th>\n",
       "      <td>0.002063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_92</th>\n",
       "      <td>0.002062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_68</th>\n",
       "      <td>0.002044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_106</th>\n",
       "      <td>0.002039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_269</th>\n",
       "      <td>0.002038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_250</th>\n",
       "      <td>0.002035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_146</th>\n",
       "      <td>0.002011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_54</th>\n",
       "      <td>0.002011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_185</th>\n",
       "      <td>0.002008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_180</th>\n",
       "      <td>0.002007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_2</th>\n",
       "      <td>0.001993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_274</th>\n",
       "      <td>0.001976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_234</th>\n",
       "      <td>0.001976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_18</th>\n",
       "      <td>0.001939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_63</th>\n",
       "      <td>0.001918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_22</th>\n",
       "      <td>0.001917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_281</th>\n",
       "      <td>0.001914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_53</th>\n",
       "      <td>0.001909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_123</th>\n",
       "      <td>0.001908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_280</th>\n",
       "      <td>0.001895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_217</th>\n",
       "      <td>0.001894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_76</th>\n",
       "      <td>0.001887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_1</th>\n",
       "      <td>0.001877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_102</th>\n",
       "      <td>0.001874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_140</th>\n",
       "      <td>0.001867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_205</th>\n",
       "      <td>0.001865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_291</th>\n",
       "      <td>0.001862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_29</th>\n",
       "      <td>0.001858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_50</th>\n",
       "      <td>0.001856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_87</th>\n",
       "      <td>0.001833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_183</th>\n",
       "      <td>0.001821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_31</th>\n",
       "      <td>0.001819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_247</th>\n",
       "      <td>0.001809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_253</th>\n",
       "      <td>0.001804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_111</th>\n",
       "      <td>0.001800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_107</th>\n",
       "      <td>0.001794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_167</th>\n",
       "      <td>0.001791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_192</th>\n",
       "      <td>0.001789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_41</th>\n",
       "      <td>0.001772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_121</th>\n",
       "      <td>0.001760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_115</th>\n",
       "      <td>0.001756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_103</th>\n",
       "      <td>0.001756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_251</th>\n",
       "      <td>0.001739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_188</th>\n",
       "      <td>0.001736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_145</th>\n",
       "      <td>0.001732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_178</th>\n",
       "      <td>0.001732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_100</th>\n",
       "      <td>0.001729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_83</th>\n",
       "      <td>0.001725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_262</th>\n",
       "      <td>0.001724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_165</th>\n",
       "      <td>0.001723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_201</th>\n",
       "      <td>0.001717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_237</th>\n",
       "      <td>0.001712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_42</th>\n",
       "      <td>0.001711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_5</th>\n",
       "      <td>0.001710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_43</th>\n",
       "      <td>0.001702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_136</th>\n",
       "      <td>0.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_249</th>\n",
       "      <td>0.001697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_290</th>\n",
       "      <td>0.001695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_159</th>\n",
       "      <td>0.001691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_170</th>\n",
       "      <td>0.001691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_244</th>\n",
       "      <td>0.001681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_219</th>\n",
       "      <td>0.001673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_133</th>\n",
       "      <td>0.001664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_120</th>\n",
       "      <td>0.001664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_179</th>\n",
       "      <td>0.001660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_61</th>\n",
       "      <td>0.001659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_199</th>\n",
       "      <td>0.001654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_60</th>\n",
       "      <td>0.001646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_295</th>\n",
       "      <td>0.001645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_128</th>\n",
       "      <td>0.001642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_90</th>\n",
       "      <td>0.001639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_257</th>\n",
       "      <td>0.001636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_289</th>\n",
       "      <td>0.001630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_95</th>\n",
       "      <td>0.001630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_35</th>\n",
       "      <td>0.001628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_79</th>\n",
       "      <td>0.001628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_81</th>\n",
       "      <td>0.001625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_137</th>\n",
       "      <td>0.001619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_144</th>\n",
       "      <td>0.001614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_150</th>\n",
       "      <td>0.001611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_89</th>\n",
       "      <td>0.001607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_270</th>\n",
       "      <td>0.001606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_220</th>\n",
       "      <td>0.001598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_19</th>\n",
       "      <td>0.001598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_194</th>\n",
       "      <td>0.001592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_296</th>\n",
       "      <td>0.001590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_155</th>\n",
       "      <td>0.001588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_105</th>\n",
       "      <td>0.001587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_17</th>\n",
       "      <td>0.001583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_228</th>\n",
       "      <td>0.001581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_151</th>\n",
       "      <td>0.001569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_21</th>\n",
       "      <td>0.001565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_271</th>\n",
       "      <td>0.001558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_218</th>\n",
       "      <td>0.001553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_239</th>\n",
       "      <td>0.001550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_255</th>\n",
       "      <td>0.001546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_13</th>\n",
       "      <td>0.001537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_238</th>\n",
       "      <td>0.001533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_298</th>\n",
       "      <td>0.001531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_78</th>\n",
       "      <td>0.001531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_300</th>\n",
       "      <td>0.001530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_224</th>\n",
       "      <td>0.001530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_240</th>\n",
       "      <td>0.001529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_71</th>\n",
       "      <td>0.001527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_279</th>\n",
       "      <td>0.001526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_70</th>\n",
       "      <td>0.001524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_32</th>\n",
       "      <td>0.001521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_212</th>\n",
       "      <td>0.001520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_45</th>\n",
       "      <td>0.001510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_172</th>\n",
       "      <td>0.001502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_171</th>\n",
       "      <td>0.001499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_160</th>\n",
       "      <td>0.001497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_27</th>\n",
       "      <td>0.001496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_55</th>\n",
       "      <td>0.001492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_153</th>\n",
       "      <td>0.001491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_264</th>\n",
       "      <td>0.001487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_93</th>\n",
       "      <td>0.001485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_62</th>\n",
       "      <td>0.001480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_293</th>\n",
       "      <td>0.001475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_277</th>\n",
       "      <td>0.001474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_96</th>\n",
       "      <td>0.001468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_9</th>\n",
       "      <td>0.001467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_124</th>\n",
       "      <td>0.001461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_184</th>\n",
       "      <td>0.001456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_158</th>\n",
       "      <td>0.001451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_260</th>\n",
       "      <td>0.001451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_118</th>\n",
       "      <td>0.001448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_127</th>\n",
       "      <td>0.001438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_52</th>\n",
       "      <td>0.001437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_204</th>\n",
       "      <td>0.001434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_113</th>\n",
       "      <td>0.001432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_130</th>\n",
       "      <td>0.001424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_98</th>\n",
       "      <td>0.001420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_286</th>\n",
       "      <td>0.001419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_156</th>\n",
       "      <td>0.001419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_16</th>\n",
       "      <td>0.001417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_182</th>\n",
       "      <td>0.001410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_73</th>\n",
       "      <td>0.001409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_132</th>\n",
       "      <td>0.001408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_8</th>\n",
       "      <td>0.001407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_112</th>\n",
       "      <td>0.001406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_28</th>\n",
       "      <td>0.001404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_59</th>\n",
       "      <td>0.001402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_109</th>\n",
       "      <td>0.001401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_174</th>\n",
       "      <td>0.001398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_241</th>\n",
       "      <td>0.001398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_193</th>\n",
       "      <td>0.001397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_273</th>\n",
       "      <td>0.001394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_282</th>\n",
       "      <td>0.001393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_10</th>\n",
       "      <td>0.001389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_6</th>\n",
       "      <td>0.001386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_49</th>\n",
       "      <td>0.001384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_246</th>\n",
       "      <td>0.001383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_116</th>\n",
       "      <td>0.001380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_223</th>\n",
       "      <td>0.001374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_266</th>\n",
       "      <td>0.001371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_91</th>\n",
       "      <td>0.001371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_252</th>\n",
       "      <td>0.001371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_166</th>\n",
       "      <td>0.001370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_245</th>\n",
       "      <td>0.001370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_46</th>\n",
       "      <td>0.001364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_243</th>\n",
       "      <td>0.001363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_154</th>\n",
       "      <td>0.001361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_175</th>\n",
       "      <td>0.001355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_139</th>\n",
       "      <td>0.001355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_143</th>\n",
       "      <td>0.001354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_267</th>\n",
       "      <td>0.001351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_213</th>\n",
       "      <td>0.001351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_235</th>\n",
       "      <td>0.001350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_126</th>\n",
       "      <td>0.001349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_157</th>\n",
       "      <td>0.001340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_114</th>\n",
       "      <td>0.001339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_14</th>\n",
       "      <td>0.001331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_206</th>\n",
       "      <td>0.001330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_173</th>\n",
       "      <td>0.001325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_297</th>\n",
       "      <td>0.001321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_37</th>\n",
       "      <td>0.001317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_3</th>\n",
       "      <td>0.001314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_117</th>\n",
       "      <td>0.001314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_164</th>\n",
       "      <td>0.001310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_75</th>\n",
       "      <td>0.001305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_189</th>\n",
       "      <td>0.001302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_278</th>\n",
       "      <td>0.001302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_48</th>\n",
       "      <td>0.001289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_7</th>\n",
       "      <td>0.001278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_299</th>\n",
       "      <td>0.001272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_101</th>\n",
       "      <td>0.001270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_284</th>\n",
       "      <td>0.001264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_248</th>\n",
       "      <td>0.001257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_210</th>\n",
       "      <td>0.001255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_190</th>\n",
       "      <td>0.001254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_202</th>\n",
       "      <td>0.001249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_58</th>\n",
       "      <td>0.001249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_47</th>\n",
       "      <td>0.001244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_74</th>\n",
       "      <td>0.001241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_97</th>\n",
       "      <td>0.001227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_198</th>\n",
       "      <td>0.001222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_162</th>\n",
       "      <td>0.001209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_225</th>\n",
       "      <td>0.001189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_215</th>\n",
       "      <td>0.001185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_231</th>\n",
       "      <td>0.001182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_292</th>\n",
       "      <td>0.001181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_149</th>\n",
       "      <td>0.001169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_148</th>\n",
       "      <td>0.001160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_211</th>\n",
       "      <td>0.001135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_256</th>\n",
       "      <td>0.001133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_142</th>\n",
       "      <td>0.001128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_64</th>\n",
       "      <td>0.001127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_236</th>\n",
       "      <td>0.001105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_221</th>\n",
       "      <td>0.001097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_186</th>\n",
       "      <td>0.001083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v_181</th>\n",
       "      <td>0.001074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>published_on_day</th>\n",
       "      <td>0.000913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>av_claims_unknown</th>\n",
       "      <td>0.000564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video_count</th>\n",
       "      <td>0.000215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>av_claims_false</th>\n",
       "      <td>0.000202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>av_claims_true</th>\n",
       "      <td>0.000173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>av_claims_mixture</th>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>av_claims_mostly_true</th>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>av_claims_mostly_false</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        importance\n",
       "fb_ad_0_share_count       0.037344\n",
       "fb_ad_0_reaction_count    0.032782\n",
       "title_char_length         0.030757\n",
       "fb_ad_0_comment_count     0.026981\n",
       "content_word_count        0.025531\n",
       "fb_popularity_ad_0        0.024881\n",
       "title_word_count          0.021971\n",
       "media_count_total         0.021888\n",
       "image_count               0.021173\n",
       "fb_ad_1_reaction_count    0.020109\n",
       "content_char_length       0.019831\n",
       "fb_ad_1_share_count       0.019254\n",
       "fb_ad_1_comment_count     0.016520\n",
       "is_collective_author      0.014032\n",
       "d2v_187                   0.013095\n",
       "d2v_65                    0.012808\n",
       "fb_ad_3_share_count       0.011319\n",
       "fb_ad_3_reaction_count    0.009092\n",
       "fb_ad_3_comment_count     0.007162\n",
       "d2v_272                   0.006980\n",
       "d2v_57                    0.006657\n",
       "d2v_232                   0.006600\n",
       "d2v_119                   0.006544\n",
       "d2v_287                   0.006314\n",
       "d2v_285                   0.005826\n",
       "d2v_4                     0.005797\n",
       "d2v_72                    0.005489\n",
       "d2v_135                   0.005329\n",
       "d2v_44                    0.005037\n",
       "d2v_169                   0.004770\n",
       "d2v_33                    0.004689\n",
       "d2v_12                    0.004671\n",
       "d2v_20                    0.004647\n",
       "d2v_191                   0.004597\n",
       "d2v_276                   0.004386\n",
       "d2v_66                    0.004103\n",
       "d2v_77                    0.003998\n",
       "d2v_200                   0.003792\n",
       "d2v_122                   0.003702\n",
       "fb_popularity_ad_1        0.003615\n",
       "fb_popularity_ad_3        0.003585\n",
       "d2v_104                   0.003569\n",
       "d2v_39                    0.003528\n",
       "d2v_125                   0.003473\n",
       "d2v_40                    0.003463\n",
       "d2v_176                   0.003434\n",
       "d2v_259                   0.003307\n",
       "d2v_177                   0.003279\n",
       "d2v_110                   0.003170\n",
       "d2v_26                    0.003168\n",
       "d2v_214                   0.003146\n",
       "d2v_261                   0.003088\n",
       "d2v_283                   0.003056\n",
       "d2v_69                    0.003025\n",
       "d2v_222                   0.002953\n",
       "d2v_129                   0.002939\n",
       "d2v_265                   0.002912\n",
       "d2v_263                   0.002907\n",
       "d2v_24                    0.002895\n",
       "d2v_152                   0.002888\n",
       "d2v_51                    0.002874\n",
       "d2v_82                    0.002862\n",
       "d2v_258                   0.002848\n",
       "d2v_195                   0.002826\n",
       "d2v_34                    0.002759\n",
       "d2v_227                   0.002698\n",
       "d2v_254                   0.002694\n",
       "d2v_11                    0.002687\n",
       "d2v_203                   0.002657\n",
       "d2v_207                   0.002654\n",
       "d2v_25                    0.002558\n",
       "d2v_233                   0.002554\n",
       "d2v_168                   0.002539\n",
       "d2v_161                   0.002534\n",
       "d2v_88                    0.002523\n",
       "d2v_23                    0.002520\n",
       "d2v_209                   0.002519\n",
       "d2v_147                   0.002508\n",
       "d2v_138                   0.002498\n",
       "d2v_108                   0.002481\n",
       "d2v_131                   0.002413\n",
       "d2v_30                    0.002400\n",
       "d2v_196                   0.002397\n",
       "d2v_268                   0.002375\n",
       "d2v_275                   0.002366\n",
       "d2v_229                   0.002349\n",
       "d2v_99                    0.002317\n",
       "d2v_294                   0.002316\n",
       "d2v_85                    0.002300\n",
       "d2v_141                   0.002293\n",
       "d2v_38                    0.002290\n",
       "d2v_36                    0.002275\n",
       "d2v_163                   0.002264\n",
       "d2v_216                   0.002257\n",
       "d2v_197                   0.002245\n",
       "d2v_288                   0.002189\n",
       "d2v_242                   0.002183\n",
       "d2v_56                    0.002160\n",
       "d2v_134                   0.002149\n",
       "d2v_208                   0.002139\n",
       "d2v_230                   0.002138\n",
       "d2v_84                    0.002114\n",
       "d2v_15                    0.002113\n",
       "d2v_67                    0.002113\n",
       "d2v_80                    0.002105\n",
       "d2v_94                    0.002075\n",
       "d2v_226                   0.002074\n",
       "d2v_86                    0.002063\n",
       "d2v_92                    0.002062\n",
       "d2v_68                    0.002044\n",
       "d2v_106                   0.002039\n",
       "d2v_269                   0.002038\n",
       "d2v_250                   0.002035\n",
       "d2v_146                   0.002011\n",
       "d2v_54                    0.002011\n",
       "d2v_185                   0.002008\n",
       "d2v_180                   0.002007\n",
       "d2v_2                     0.001993\n",
       "d2v_274                   0.001976\n",
       "d2v_234                   0.001976\n",
       "d2v_18                    0.001939\n",
       "d2v_63                    0.001918\n",
       "d2v_22                    0.001917\n",
       "d2v_281                   0.001914\n",
       "d2v_53                    0.001909\n",
       "d2v_123                   0.001908\n",
       "d2v_280                   0.001895\n",
       "d2v_217                   0.001894\n",
       "d2v_76                    0.001887\n",
       "d2v_1                     0.001877\n",
       "d2v_102                   0.001874\n",
       "d2v_140                   0.001867\n",
       "d2v_205                   0.001865\n",
       "d2v_291                   0.001862\n",
       "d2v_29                    0.001858\n",
       "d2v_50                    0.001856\n",
       "d2v_87                    0.001833\n",
       "d2v_183                   0.001821\n",
       "d2v_31                    0.001819\n",
       "d2v_247                   0.001809\n",
       "d2v_253                   0.001804\n",
       "d2v_111                   0.001800\n",
       "d2v_107                   0.001794\n",
       "d2v_167                   0.001791\n",
       "d2v_192                   0.001789\n",
       "d2v_41                    0.001772\n",
       "d2v_121                   0.001760\n",
       "d2v_115                   0.001756\n",
       "d2v_103                   0.001756\n",
       "d2v_251                   0.001739\n",
       "d2v_188                   0.001736\n",
       "d2v_145                   0.001732\n",
       "d2v_178                   0.001732\n",
       "d2v_100                   0.001729\n",
       "d2v_83                    0.001725\n",
       "d2v_262                   0.001724\n",
       "d2v_165                   0.001723\n",
       "d2v_201                   0.001717\n",
       "d2v_237                   0.001712\n",
       "d2v_42                    0.001711\n",
       "d2v_5                     0.001710\n",
       "d2v_43                    0.001702\n",
       "d2v_136                   0.001700\n",
       "d2v_249                   0.001697\n",
       "d2v_290                   0.001695\n",
       "d2v_159                   0.001691\n",
       "d2v_170                   0.001691\n",
       "d2v_244                   0.001681\n",
       "d2v_219                   0.001673\n",
       "d2v_133                   0.001664\n",
       "d2v_120                   0.001664\n",
       "d2v_179                   0.001660\n",
       "d2v_61                    0.001659\n",
       "d2v_199                   0.001654\n",
       "d2v_60                    0.001646\n",
       "d2v_295                   0.001645\n",
       "d2v_128                   0.001642\n",
       "d2v_90                    0.001639\n",
       "d2v_257                   0.001636\n",
       "d2v_289                   0.001630\n",
       "d2v_95                    0.001630\n",
       "d2v_35                    0.001628\n",
       "d2v_79                    0.001628\n",
       "d2v_81                    0.001625\n",
       "d2v_137                   0.001619\n",
       "d2v_144                   0.001614\n",
       "d2v_150                   0.001611\n",
       "d2v_89                    0.001607\n",
       "d2v_270                   0.001606\n",
       "d2v_220                   0.001598\n",
       "d2v_19                    0.001598\n",
       "d2v_194                   0.001592\n",
       "d2v_296                   0.001590\n",
       "d2v_155                   0.001588\n",
       "d2v_105                   0.001587\n",
       "d2v_17                    0.001583\n",
       "d2v_228                   0.001581\n",
       "d2v_151                   0.001569\n",
       "d2v_21                    0.001565\n",
       "d2v_271                   0.001558\n",
       "d2v_218                   0.001553\n",
       "d2v_239                   0.001550\n",
       "d2v_255                   0.001546\n",
       "d2v_13                    0.001537\n",
       "d2v_238                   0.001533\n",
       "d2v_298                   0.001531\n",
       "d2v_78                    0.001531\n",
       "d2v_300                   0.001530\n",
       "d2v_224                   0.001530\n",
       "d2v_240                   0.001529\n",
       "d2v_71                    0.001527\n",
       "d2v_279                   0.001526\n",
       "d2v_70                    0.001524\n",
       "d2v_32                    0.001521\n",
       "d2v_212                   0.001520\n",
       "d2v_45                    0.001510\n",
       "d2v_172                   0.001502\n",
       "d2v_171                   0.001499\n",
       "d2v_160                   0.001497\n",
       "d2v_27                    0.001496\n",
       "d2v_55                    0.001492\n",
       "d2v_153                   0.001491\n",
       "d2v_264                   0.001487\n",
       "d2v_93                    0.001485\n",
       "d2v_62                    0.001480\n",
       "d2v_293                   0.001475\n",
       "d2v_277                   0.001474\n",
       "d2v_96                    0.001468\n",
       "d2v_9                     0.001467\n",
       "d2v_124                   0.001461\n",
       "d2v_184                   0.001456\n",
       "d2v_158                   0.001451\n",
       "d2v_260                   0.001451\n",
       "d2v_118                   0.001448\n",
       "d2v_127                   0.001438\n",
       "d2v_52                    0.001437\n",
       "d2v_204                   0.001434\n",
       "d2v_113                   0.001432\n",
       "d2v_130                   0.001424\n",
       "d2v_98                    0.001420\n",
       "d2v_286                   0.001419\n",
       "d2v_156                   0.001419\n",
       "d2v_16                    0.001417\n",
       "d2v_182                   0.001410\n",
       "d2v_73                    0.001409\n",
       "d2v_132                   0.001408\n",
       "d2v_8                     0.001407\n",
       "d2v_112                   0.001406\n",
       "d2v_28                    0.001404\n",
       "d2v_59                    0.001402\n",
       "d2v_109                   0.001401\n",
       "d2v_174                   0.001398\n",
       "d2v_241                   0.001398\n",
       "d2v_193                   0.001397\n",
       "d2v_273                   0.001394\n",
       "d2v_282                   0.001393\n",
       "d2v_10                    0.001389\n",
       "d2v_6                     0.001386\n",
       "d2v_49                    0.001384\n",
       "d2v_246                   0.001383\n",
       "d2v_116                   0.001380\n",
       "d2v_223                   0.001374\n",
       "d2v_266                   0.001371\n",
       "d2v_91                    0.001371\n",
       "d2v_252                   0.001371\n",
       "d2v_166                   0.001370\n",
       "d2v_245                   0.001370\n",
       "d2v_46                    0.001364\n",
       "d2v_243                   0.001363\n",
       "d2v_154                   0.001361\n",
       "d2v_175                   0.001355\n",
       "d2v_139                   0.001355\n",
       "d2v_143                   0.001354\n",
       "d2v_267                   0.001351\n",
       "d2v_213                   0.001351\n",
       "d2v_235                   0.001350\n",
       "d2v_126                   0.001349\n",
       "d2v_157                   0.001340\n",
       "d2v_114                   0.001339\n",
       "d2v_14                    0.001331\n",
       "d2v_206                   0.001330\n",
       "d2v_173                   0.001325\n",
       "d2v_297                   0.001321\n",
       "d2v_37                    0.001317\n",
       "d2v_3                     0.001314\n",
       "d2v_117                   0.001314\n",
       "d2v_164                   0.001310\n",
       "d2v_75                    0.001305\n",
       "d2v_189                   0.001302\n",
       "d2v_278                   0.001302\n",
       "d2v_48                    0.001289\n",
       "d2v_7                     0.001278\n",
       "d2v_299                   0.001272\n",
       "d2v_101                   0.001270\n",
       "d2v_284                   0.001264\n",
       "d2v_248                   0.001257\n",
       "d2v_210                   0.001255\n",
       "d2v_190                   0.001254\n",
       "d2v_202                   0.001249\n",
       "d2v_58                    0.001249\n",
       "d2v_47                    0.001244\n",
       "d2v_74                    0.001241\n",
       "d2v_97                    0.001227\n",
       "d2v_198                   0.001222\n",
       "d2v_162                   0.001209\n",
       "d2v_225                   0.001189\n",
       "d2v_215                   0.001185\n",
       "d2v_231                   0.001182\n",
       "d2v_292                   0.001181\n",
       "d2v_149                   0.001169\n",
       "d2v_148                   0.001160\n",
       "d2v_211                   0.001135\n",
       "d2v_256                   0.001133\n",
       "d2v_142                   0.001128\n",
       "d2v_64                    0.001127\n",
       "d2v_236                   0.001105\n",
       "d2v_221                   0.001097\n",
       "d2v_186                   0.001083\n",
       "d2v_181                   0.001074\n",
       "published_on_day          0.000913\n",
       "av_claims_unknown         0.000564\n",
       "video_count               0.000215\n",
       "av_claims_false           0.000202\n",
       "av_claims_true            0.000173\n",
       "av_claims_mixture         0.000010\n",
       "av_claims_mostly_true     0.000006\n",
       "av_claims_mostly_false    0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_all(pd.DataFrame((i for i in classifiers[0].feature_importances_), index=data.train.features.columns, columns=['importance']).sort_values(by=['importance'], ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train.y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
